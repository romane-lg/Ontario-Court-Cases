(Slip Opinion)            Cite as: 604 U. S. ____ (2025)                              1

                                     Per Curiam

       NOTICE: This opinion is subject to formal revision before publication in the
       United States Reports. Readers are requested to notify the Reporter of
       Decisions, Supreme Court of the United States, Washington, D. C. 20543,
       pio@supremecourt.gov, of any typographical or other formal errors.


SUPREME COURT OF THE UNITED STATES
                                     _________________

                             Nos. 24–656 and 24–657
                                     _________________


       TIKTOK INC., ET AL., PETITIONERS
24–656                 v.
   MERRICK B. GARLAND, ATTORNEY GENERAL

     BRIAN FIREBAUGH, ET AL., PETITIONERS
24–657              v.
   MERRICK B. GARLAND, ATTORNEY GENERAL
ON APPLICATIONS FOR INJUNCTION PENDING REVIEW TO THE
 UNITED STATES COURT OF APPEALS FOR THE DISTRICT OF
                  COLUMBIA CIRCUIT
                                 [January 17, 2025]

  PER CURIAM.
  As of January 19, the Protecting Americans from Foreign
Adversary Controlled Applications Act will make it unlaw-
ful for companies in the United States to provide services to
distribute, maintain, or update the social media platform
TikTok, unless U. S. operation of the platform is severed
from Chinese control. Petitioners are two TikTok operating
entities and a group of U. S. TikTok users. We consider
whether the Act, as applied to petitioners, violates the First
Amendment.
  In doing so, we are conscious that the cases before us in-
volve new technologies with transformative capabilities.
This challenging new context counsels caution on our part.
As Justice Frankfurter advised 80 years ago in considering
the application of established legal rules to the “totally new
problems” raised by the airplane and radio, we should take
2                     TIKTOK INC. v. GARLAND

                              Per Curiam

care not to “embarrass the future.” Northwest Airlines, Inc.
v. Minnesota, 322 U. S. 292, 300 (1944). That caution is
heightened in these cases, given the expedited time allowed
for our consideration.1 Our analysis must be understood to
be narrowly focused in light of these circumstances.
                              I
                              A
  TikTok is a social media platform that allows users to cre-
ate, publish, view, share, and interact with short videos
overlaid with audio and text. Since its launch in 2017, the
platform has accumulated over 170 million users in the
United States and more than one billion worldwide. Those
users are prolific content creators and viewers. In 2023,
U. S. TikTok users uploaded more than 5.5 billion videos,
which were in turn viewed more than 13 trillion times
around the world.
  Opening the TikTok application brings a user to the “For
You” page—a personalized content feed tailored to the
user’s interests. TikTok generates the feed using a propri-
etary algorithm that recommends videos to a user based on
the user’s interactions with the platform. Each interaction
a user has on TikTok—watching a video, following an ac-
count, leaving a comment—enables the recommendation
system to further tailor a personalized content feed.
  A TikTok user’s content feed is also shaped by content
moderation and filtering decisions. TikTok uses automated
and human processes to remove content that violates the
platform’s community guidelines. See 1 App. 493–497. Tik-
Tok also promotes or demotes certain content to advance its
business objectives and other goals. See id., at 499–501.
  TikTok is operated in the United States by TikTok Inc.,
——————
  1 Applications for an injunction pending review were filed on December

16, 2024; we construed the applications as petitions for a writ of certio-
rari and granted them on December 18, 2024; and oral argument was
held on January 10, 2025.
                 Cite as: 604 U. S. ____ (2025)            3

                          Per Curiam

an American company incorporated and headquartered in
California. TikTok Inc.’s ultimate parent company is
ByteDance Ltd., a privately held company that has opera-
tions in China. ByteDance Ltd. owns TikTok’s proprietary
algorithm, which is developed and maintained in China.
The company is also responsible for developing portions of
the source code that runs the TikTok platform. ByteDance
Ltd. is subject to Chinese laws that require it to “assist or
cooperate” with the Chinese Government’s “intelligence
work” and to ensure that the Chinese Government has “the
power to access and control private data” the company
holds. H. R. Rep. No. 118–417, p. 4 (2024) (H. R. Rep.); see
2 App. 673–676.
                               B
                               1
   In recent years, U. S. government officials have taken re-
peated actions to address national security concerns re-
garding the relationship between China and TikTok.
   In August 2020, President Trump issued an Executive
Order finding that “the spread in the United States of mo-
bile applications developed and owned by companies in
[China] continues to threaten the national security, foreign
policy, and economy of the United States.” Exec. Order
No. 13942, 3 CFR 412 (2021). President Trump determined
that TikTok raised particular concerns, noting that the
platform “automatically captures vast swaths of infor-
mation from its users” and is susceptible to being used to
further the interests of the Chinese Government. Ibid. The
President invoked his authority under the International
Emergency Economic Powers Act (IEEPA), 50 U. S. C.
§1701 et seq., and the National Emergencies Act, 50 U. S. C.
§1601 et seq., to prohibit certain “transactions” involving
ByteDance Ltd. or its subsidiaries, as identified by the Sec-
retary of Commerce. 3 CFR 413. The Secretary published
a list of prohibited transactions in September 2020. See 85
4                  TIKTOK INC. v. GARLAND

                          Per Curiam

Fed. Reg. 60061 (2020). But federal courts enjoined the pro-
hibitions before they took effect, finding that they exceeded
the Executive Branch’s authority under IEEPA. See gener-
ally TikTok Inc. v. Trump, 507 F. Supp. 3d 92 (DC 2020);
Marland v. Trump, 498 F. Supp. 3d 624 (ED Pa. 2020).
   Just days after issuing his initial Executive Order, Pres-
ident Trump ordered ByteDance Ltd. to divest all interests
and rights in any property “used to enable or support
ByteDance’s operation of the TikTok application in the
United States,” along with “any data obtained or derived
from” U. S. TikTok users. 85 Fed. Reg. 51297. ByteDance
Ltd. and TikTok Inc. filed suit in the D. C. Circuit, challeng-
ing the constitutionality of the order. In February 2021, the
D. C. Circuit placed the case in abeyance to permit the
Biden administration to review the matter and to enable
the parties to negotiate a non-divestiture remedy that
would address the Government’s national security con-
cerns. See Order in TikTok Inc. v. Committee on Foreign
Investment, No. 20–1444 (CADC, Feb. 19, 2021).
   Throughout 2021 and 2022, ByteDance Ltd. negotiated
with Executive Branch officials to develop a national secu-
rity agreement that would resolve those concerns. Execu-
tive Branch officials ultimately determined, however, that
ByteDance Ltd.’s proposed agreement did not adequately
“mitigate the risks posed to U. S. national security inter-
ests.” 2 App. 686. Negotiations stalled, and the parties
never finalized an agreement.
                               2
   Against this backdrop, Congress enacted the Protecting
Americans from Foreign Adversary Controlled Applications
Act. Pub. L. 118–50, div. H, 138 Stat. 955. The Act makes
it unlawful for any entity to provide certain services to “dis-
tribute, maintain, or update” a “foreign adversary con-
trolled application” in the United States. §2(a)(1). Entities
that violate this prohibition are subject to civil enforcement
                  Cite as: 604 U. S. ____ (2025)             5

                           Per Curiam

actions and hefty monetary penalties. See §§2(d)(1)(A),
(d)(2)(B).
   The Act provides two means by which an application may
be designated a “foreign adversary controlled application.”
First, the Act expressly designates any application that is
“operated, directly or indirectly,” by “ByteDance Ltd.” or
“TikTok,” or any subsidiary or successor thereof.
§2(g)(3)(A). Second, the Act establishes a general designa-
tion framework for any application that is both (1) operated
by a “covered company” that is “controlled by a foreign ad-
versary,” and (2) “determined by the President to present a
significant threat to the national security of the United
States,” following a public notice and reporting process.
§2(g)(3)(B). In broad terms, the Act defines “covered com-
pany” to include a company that operates an application
that enables users to generate, share, and view content and
has more than 1,000,000 monthly active users. §2(g)(2)(A).
The Act excludes from that definition a company that oper-
ates an application “whose primary purpose is to allow us-
ers to post product reviews, business reviews, or travel in-
formation and reviews.” §2(g)(2)(B).
   The Act’s prohibitions take effect 270 days after an appli-
cation is designated a foreign adversary controlled applica-
tion. §2(a)(2). Because the Act itself designates applica-
tions operated by “ByteDance, Ltd.” and “TikTok,”
prohibitions as to those applications take effect 270 days
after the Act’s enactment—January 19, 2025.
   The Act exempts a foreign adversary controlled applica-
tion from the prohibitions if the application undergoes a
“qualified divestiture.” §2(c)(1). A “qualified divestiture” is
one that the President determines will result in the appli-
cation “no longer being controlled by a foreign adversary.”
§2(g)(6)(A). The President must further determine that the
divestiture “precludes the establishment or maintenance of
any operational relationship between the United States op-
6                 TIKTOK INC. v. GARLAND

                         Per Curiam

erations of the [application] and any formerly affiliated en-
tities that are controlled by a foreign adversary, including
any cooperation with respect to the operation of a content
recommendation algorithm or an agreement with respect to
data sharing.” §2(g)(6)(B). The Act permits the President
to grant a one-time extension of no more than 90 days with
respect to the prohibitions’ 270-day effective date if the
President makes certain certifications to Congress regard-
ing progress toward a qualified divestiture. §2(a)(3).
                               C
   ByteDance Ltd. and TikTok Inc.—along with two sets of
TikTok users and creators (creator petitioners)—filed peti-
tions for review in the D. C. Circuit, challenging the consti-
tutionality of the Act. As relevant here, the petitioners ar-
gued that the Act’s prohibitions, TikTok-specific foreign
adversary controlled application designation, and divesti-
ture requirement violate the First Amendment.
   The D. C. Circuit consolidated and denied the petitions,
holding that the Act does not violate petitioners’ First
Amendment rights. 122 F. 4th 930, 940, 948–965 (CADC
2024). After first concluding that the Act was subject to
heightened scrutiny under the First Amendment, the court
assumed without deciding that strict, rather than interme-
diate, scrutiny applied. Id., at 948–952. The court held that
the Act satisfied that standard, finding that the Govern-
ment’s national security justifications—countering China’s
data collection and covert content manipulation efforts—
were compelling, and that the Act was narrowly tailored to
further those interests. Id., at 952–965.
   Chief Judge Srinivasan concurred in part and in the judg-
ment. Id., at 970. In his view, the Act was subject to inter-
mediate scrutiny, id., at 974–979, and was constitutional
under that standard, id., at 979–983.
   We granted certiorari to decide whether the Act, as ap-
plied to petitioners, violates the First Amendment. 604
                    Cite as: 604 U. S. ____ (2025)          7

                             Per Curiam

U. S. ___ (2024).
                               II
                               A
   At the threshold, we consider whether the challenged
provisions are subject to First Amendment scrutiny. Laws
that directly regulate expressive conduct can, but do not
necessarily, trigger such review. See R. A. V. v. St. Paul,
505 U. S. 377, 382–386 (1992). We have also applied First
Amendment scrutiny in “cases involving governmental reg-
ulation of conduct that has an expressive element,” and to
“some statutes which, although directed at activity with no
expressive component, impose a disproportionate burden
upon those engaged in protected First Amendment activi-
ties.” Arcara v. Cloud Books, Inc., 478 U. S. 697, 703–704
(1986).
   It is not clear that the Act itself directly regulates pro-
tected expressive activity, or conduct with an expressive
component. Indeed, the Act does not regulate the creator
petitioners at all. And it directly regulates ByteDance Ltd.
and TikTok Inc. only through the divestiture requirement.
See §2(c)(1). Petitioners, for their part, have not identified
any case in which this Court has treated a regulation of cor-
porate control as a direct regulation of expressive activity
or semi-expressive conduct. See Tr. of Oral Arg. 37–40. We
hesitate to break that new ground in this unique case.
   In any event, petitioners’ arguments more closely approx-
imate a claim that the Act’s prohibitions, TikTok-specific
designation, and divestiture requirement “impose a dispro-
portionate burden upon” their First Amendment activities.
Arcara, 478 U. S., at 704. Petitioners assert—and the Gov-
ernment does not contest—that, because it is commercially
infeasible for TikTok to be divested within the Act’s 270-day
timeframe, the Act effectively bans TikTok in the United
States. Petitioners argue that such a ban will burden vari-
8                     TIKTOK INC. v. GARLAND

                              Per Curiam

ous First Amendment activities, including content modera-
tion, content generation, access to a distinct medium for ex-
pression, association with another speaker or preferred ed-
itor, and receipt of information and ideas.
   We have recognized a number of these asserted First
Amendment interests. See Moody v. NetChoice, LLC, 603
U. S. 707, 731 (2024) (“An entity ‘exercising editorial discre-
tion in the selection and presentation’ of content is ‘engaged
in speech activity.’ ” (quoting Arkansas Ed. Television
Comm’n v. Forbes, 523 U. S. 666, 674 (1998); alteration
omitted)); City of Ladue v. Gilleo, 512 U. S. 43, 54–58 (1994)
(“Our prior decisions have voiced particular concern with
laws that foreclose an entire medium of expression.”);
Rumsfeld v. Forum for Academic and Institutional Rights,
Inc., 547 U. S. 47, 68 (2006) (“We have recognized a First
Amendment right to associate for the purpose of speaking,
which we have termed a ‘right of expressive association.’ ”);
Martin v. City of Struthers, 319 U. S. 141, 143 (1943) (“The
right of freedom of speech and press . . . embraces the right
to distribute literature and necessarily protects the right to
receive it.” (citation omitted)).2 And an effective ban on a
social media platform with 170 million U. S. users certainly
burdens those users’ expressive activity in a non-trivial
way.
   At the same time, a law targeting a foreign adversary’s
control over a communications platform is in many ways
different in kind from the regulations of non-expressive ac-
tivity that we have subjected to First Amendment scrutiny.
Those differences—the Act’s focus on a foreign government,
the congressionally determined adversary relationship be-
tween that foreign government and the United States, and
——————
  2 To the extent that ByteDance Ltd.’s asserted expressive activity oc-

curs abroad, that activity is not protected by the First Amendment. See
Agency for Int’l Development v. Alliance for Open Society Int’l Inc., 591
U. S. 430, 436 (2020) (“[F]oreign organizations operating abroad have no
First Amendment rights.”).
                 Cite as: 604 U. S. ____ (2025)            9

                          Per Curiam

the causal steps between the regulations and the alleged
burden on protected speech—may impact whether First
Amendment scrutiny applies.
  This Court has not articulated a clear framework for de-
termining whether a regulation of non-expressive activity
that disproportionately burdens those engaged in expres-
sive activity triggers heightened review. We need not do so
here. We assume without deciding that the challenged pro-
visions fall within this category and are subject to First
Amendment scrutiny.
                              B
                              1
   “At the heart of the First Amendment lies the principle
that each person should decide for himself or herself the
ideas and beliefs deserving of expression, consideration,
and adherence.” Turner Broadcasting System, Inc. v. FCC,
512 U. S. 622, 641 (1994) (Turner I ). Government action
that suppresses speech because of its message “contravenes
this essential right.” Ibid. “Content-based laws—those
that target speech based on its communicative content—are
presumptively unconstitutional and may be justified only if
the government proves that they are narrowly tailored to
serve compelling state interests.” Reed v. Town of Gilbert,
576 U. S. 155, 163 (2015). Content-neutral laws, in con-
trast, “are subject to an intermediate level of scrutiny be-
cause in most cases they pose a less substantial risk of ex-
cising certain ideas or viewpoints from the public dialogue.”
Turner I, 512 U. S., at 642 (citation omitted). Under that
standard, we will sustain a content-neutral law “if it ad-
vances important governmental interests unrelated to the
suppression of free speech and does not burden substan-
tially more speech than necessary to further those inter-
ests.” Turner Broadcasting System, Inc. v. FCC, 520 U. S.
180, 189 (1997) (Turner II ).
   We have identified two forms of content-based speech
10                 TIKTOK INC. v. GARLAND

                          Per Curiam

regulation. First, a law is content based on its face if it “ap-
plies to particular speech because of the topic discussed or
the idea or message expressed.” Reed, 576 U. S., at 163; see
id., at 163–164 (explaining that some facial distinctions de-
fine regulated speech by subject matter, others by the
speech’s function or purpose). Second, a facially content-
neutral law is nonetheless treated as a content-based regu-
lation of speech if it “cannot be ‘justified without reference
to the content of the regulated speech’ ” or was “adopted by
the government ‘because of disagreement with the message
the speech conveys.’ ” Id., at 164 (quoting Ward v. Rock
Against Racism, 491 U. S. 781, 791 (1989)).
   As applied to petitioners, the challenged provisions are
facially content neutral and are justified by a content-
neutral rationale.
                              a
   The challenged provisions are facially content neutral.
They impose TikTok-specific prohibitions due to a foreign
adversary’s control over the platform and make divestiture
a prerequisite for the platform’s continued operation in the
United States. They do not target particular speech based
upon its content, contrast, e.g., Carey v. Brown, 447 U. S.
455, 465 (1980) (statute prohibiting all residential picketing
except “peaceful labor picketing”), or regulate speech based
on its function or purpose, contrast, e.g., Holder v. Human-
itarian Law Project, 561 U. S. 1, 7, 27 (2010) (law prohibit-
ing providing material support to terrorists). Nor do they
impose a “restriction, penalty, or burden” by reason of con-
tent on TikTok—a conclusion confirmed by the fact that pe-
titioners “cannot avoid or mitigate” the effects of the Act by
altering their speech. Turner I, 512 U. S., at 644. As to
petitioners, the Act thus does not facially regulate “partic-
ular speech because of the topic discussed or the idea or
message expressed.” Reed, 576 U. S., at 163.
   Petitioners argue that the Act is content based on its face
                   Cite as: 604 U. S. ____ (2025)             11

                            Per Curiam

because it excludes from the definition of “covered com-
pany” any company that operates an application “whose
primary purpose is to allow users to post product reviews,
business reviews, or travel information and reviews.”
§2(g)(2)(B); see Brief for Petitioners in No. 24–656, pp. 26–
27 (Brief for TikTok); Brief for Petitioners in No. 24–657,
p. 26 (Brief for Creator Petitioners). We need not decide
whether that exclusion is content based. The question be-
fore the Court is whether the Act violates the First Amend-
ment as applied to petitioners. To answer that question, we
look to the provisions of the Act that give rise to the effective
TikTok ban that petitioners argue burdens their First
Amendment rights. The exclusion for certain review plat-
forms, however, applies only to the general framework for
designating applications controlled by “covered com-
pan[ies],” not to the TikTok-specific designation.
§§2(g)(3)(A)–(B). As such, the exclusion is not within the
scope of petitioners’ as-applied challenge.
                              b
  The Government also supports the challenged provisions
with a content-neutral justification: preventing China from
collecting vast amounts of sensitive data from 170 million
U. S. TikTok users. 2 App. 628. That rationale is decidedly
content agnostic. It neither references the content of speech
on TikTok nor reflects disagreement with the message such
speech conveys. Cf. Ward, 491 U. S., at 792–793 (holding
noise control and sound quality justifications behind city
sound amplification guideline were content neutral).
  Because the data collection justification reflects a “pur-
pos[e] unrelated to the content of expression,” it is content
neutral. Id., at 791.
                              2
   The Act’s TikTok-specific distinctions, moreover, do not
trigger strict scrutiny. See Brief for TikTok 26–27; Brief for
12                 TIKTOK INC. v. GARLAND

                          Per Curiam

Creator Petitioners 24–26. It is true that “[s]peech re-
strictions based on the identity of the speaker are all too
often simply a means to control content.” Citizens United
v. Federal Election Comm’n, 558 U. S. 310, 340 (2010). For
that reason, “[r]egulations that discriminate among media,
or among different speakers within a single medium, often
present serious First Amendment concerns.” Turner I, 512
U. S., at 659. But while “laws favoring some speakers over
others demand strict scrutiny when the legislature’s
speaker preference reflects a content preference,” id., at
658, such scrutiny “is unwarranted when the differential
treatment is ‘justified by some special characteristic of ’ the
particular [speaker] being regulated,” id., at 660–661 (quot-
ing Minneapolis Star & Tribune Co. v. Minnesota Comm’r
of Revenue, 460 U. S. 575, 585 (1983)).
   For the reasons we have explained, requiring divestiture
for the purpose of preventing a foreign adversary from ac-
cessing the sensitive data of 170 million U. S. TikTok users
is not “a subtle means of exercising a content
preference.” Turner I, 512 U. S., at 645. The prohibitions,
TikTok-specific designation, and divestiture requirement
regulate TikTok based on a content-neutral data collection
interest. And TikTok has special characteristics—a foreign
adversary’s ability to leverage its control over the platform
to collect vast amounts of personal data from 170 million
U. S. users—that justify this differential treatment.
“[S]peaker distinctions of this nature are not presumed in-
valid under the First Amendment.” Ibid.
   While we find that differential treatment was justified
here, however, we emphasize the inherent narrowness of
our holding. Data collection and analysis is a common prac-
tice in this digital age. But TikTok’s scale and susceptibil-
ity to foreign adversary control, together with the vast
swaths of sensitive data the platform collects, justify differ-
ential treatment to address the Government’s national se-
curity concerns. A law targeting any other speaker would
                     Cite as: 604 U. S. ____ (2025)                   13

                              Per Curiam

by necessity entail a distinct inquiry and separate consid-
erations.
  On this understanding, we cannot accept petitioners’ call
for strict scrutiny. No more than intermediate scrutiny is
in order.
                             C
  As applied to petitioners, the Act satisfies intermediate
scrutiny. The challenged provisions further an important
Government interest unrelated to the suppression of free
expression and do not burden substantially more speech
than necessary to further that interest.3
                              1
  The Act’s prohibitions and divestiture requirement are
designed to prevent China—a designated foreign adver-
sary—from leveraging its control over ByteDance Ltd. to
capture the personal data of U. S. TikTok users. This ob-
jective qualifies as an important Government interest un-
der intermediate scrutiny.
  Petitioners do not dispute that the Government has an
important and well-grounded interest in preventing China
from collecting the personal data of tens of millions of U. S.
TikTok users. Nor could they. The platform collects exten-
sive personal information from and about its users. See
H. R. Rep., at 3 (Public reporting has suggested that Tik-
Tok’s “data collection practices extend to age, phone num-
ber, precise location, internet address, device used, phone
contacts, social network connections, the content of private
messages sent through the application, and videos
watched.”); 1 App. 241 (Draft National Security Agreement
noting that TikTok collects user data, user content, behav-
ioral data (including “keystroke patterns and rhythms”),
and device and network data (including device contacts and
——————
  3 Our holding and analysis are based on the public record, without ref-

erence to the classified evidence the Government filed below.
14                TIKTOK INC. v. GARLAND

                         Per Curiam

calendars)). If, for example, a user allows TikTok access to
the user’s phone contact list to connect with others on the
platform, TikTok can access “any data stored in the user’s
contact list,” including names, contact information, contact
photos, job titles, and notes. 2 id., at 659. Access to such
detailed information about U. S. users, the Government
worries, may enable “China to track the locations of Federal
employees and contractors, build dossiers of personal infor-
mation for blackmail, and conduct corporate espionage.” 3
CFR 412. And Chinese law enables China to require com-
panies to surrender data to the government, “making com-
panies headquartered there an espionage tool” of China.
H. R. Rep., at 4.
   Rather than meaningfully dispute the scope of the data
TikTok collects or the ends to which it may be used, peti-
tioners contest probability, asserting that it is “unlikely”
that China would “compel TikTok to turn over user data for
intelligence-gathering purposes, since China has more ef-
fective and efficient means of obtaining relevant infor-
mation.” Brief for TikTok 50 (internal quotation marks
omitted). In reviewing the constitutionality of the Act, how-
ever, we “must accord substantial deference to the predic-
tive judgments of Congress.” Turner I, 512 U. S., at 665
(opinion of Kennedy, J.). “Sound policymaking often re-
quires legislators to forecast future events and to anticipate
the likely impact of these events based on deductions and
inferences for which complete empirical support may be un-
available.” Ibid. Here, the Government’s TikTok-related
data collection concerns do not exist in isolation. The record
reflects that China “has engaged in extensive and years-
long efforts to accumulate structured datasets, in particular
on U. S. persons, to support its intelligence and counterin-
telligence operations.” 2 App. 634.
   Even if China has not yet leveraged its relationship with
ByteDance Ltd. to access U. S. TikTok users’ data, petition-
                  Cite as: 604 U. S. ____ (2025)           15

                           Per Curiam

ers offer no basis for concluding that the Government’s de-
termination that China might do so is not at least a “rea-
sonable inferenc[e] based on substantial evidence.” Turner
II, 520 U. S., at 195. We are mindful that this law arises in
a context in which “national security and foreign policy con-
cerns arise in connection with efforts to confront evolving
threats in an area where information can be difficult to ob-
tain and the impact of certain conduct difficult to assess.”
Humanitarian Law Project, 561 U. S., at 34. We thus afford
the Government’s “informed judgment” substantial respect
here. Ibid.
   Petitioners further argue that the Act is underinclusive
as to the Government’s data protection concern, raising
doubts as to whether the Government is actually pursuing
that interest. In particular, petitioners argue that the Act’s
focus on applications with user-generated and user-shared
content, along with its exclusion for certain review plat-
forms, exempts from regulation applications that are “as ca-
pable as TikTok of collecting Americans’ data.” Brief for
TikTok 43; see Brief for Creator Petitioners 48–49. But “the
First Amendment imposes no freestanding underinclusive-
ness limitation,” and the Government “need not address all
aspects of a problem in one fell swoop.” Williams-Yulee v.
Florida Bar, 575 U. S. 433, 449 (2015) (internal quotation
marks omitted). Furthermore, as we have already con-
cluded, the Government had good reason to single out Tik-
Tok for special treatment. Contrast Brown v. Entertain-
ment Merchants Assn., 564 U. S. 786, 802 (2011) (singling
out purveyors of video games for disfavored treatment with-
out a persuasive reason “raise[d] serious doubts about
whether the government [wa]s in fact pursuing the interest
it invoke[d], rather than disfavoring a particular speaker or
viewpoint”). On this record, Congress was justified in spe-
cifically addressing its TikTok-related national security
concerns.
16                TIKTOK INC. v. GARLAND

                         Per Curiam

                               2
   As applied to petitioners, the Act is sufficiently tailored
to address the Government’s interest in preventing a for-
eign adversary from collecting vast swaths of sensitive data
about the 170 million U. S. persons who use TikTok. To
survive intermediate scrutiny, “a regulation need not be the
least speech-restrictive means of advancing the Govern-
ment’s interests.” Turner I, 512 U. S., at 662. Rather, the
standard “is satisfied ‘so long as the regulation promotes a
substantial government interest that would be achieved
less effectively absent the regulation’ ” and does not “burden
substantially more speech than is necessary” to further that
interest. Ward, 491 U. S., at 799 (quoting United States v.
Albertini, 472 U. S. 675, 689 (1985); alteration omitted).
   The challenged provisions meet this standard. The pro-
visions clearly serve the Government’s data collection inter-
est “in a direct and effective way.” Ward, 491 U. S., at 800.
The prohibitions account for the fact that, absent a quali-
fied divestiture, TikTok’s very operation in the United
States implicates the Government’s data collection con-
cerns, while the requirements that make a divestiture
“qualified” ensure that those concerns are addressed before
TikTok resumes U. S. operations. Neither the prohibitions
nor the divestiture requirement, moreover, is “substantially
broader than necessary to achieve” this national security
objective. Ibid. Rather than ban TikTok outright, the Act
imposes a conditional ban. The prohibitions prevent China
from gathering data from U. S. TikTok users unless and un-
til a qualified divestiture severs China’s control.
   Petitioners parade a series of alternatives—disclosure re-
quirements, data sharing restrictions, the proposed na-
tional security agreement, the general designation provi-
sion—that they assert would address the Government’s
data collection interest in equal measure to a conditional
TikTok ban. Those alternatives do not alter our tailoring
analysis.
                  Cite as: 604 U. S. ____ (2025)           17

                           Per Curiam

   Petitioners’ proposed alternatives ignore the “latitude”
we afford the Government to design regulatory solutions to
address content-neutral interests. Turner II, 520 U. S., at
213. “So long as the means chosen are not substantially
broader than necessary to achieve the government’s inter-
est, . . . the regulation will not be invalid simply because a
court concludes that the government’s interest could be ad-
equately served by some less-speech-restrictive alterna-
tive.” Ward, 491 U. S., at 800; see ibid. (regulation valid
despite availability of less restrictive “alternative regula-
tory methods”); Albertini, 472 U. S., at 689; Clark v. Com-
munity for Creative Non-Violence, 468 U. S. 288, 299 (1984);
Members of City Council of Los Angeles v. Taxpayers for
Vincent, 466 U. S. 789, 815–816 (1984). For the reasons we
have explained, the challenged provisions are “not substan-
tially broader than necessary” to address the Government’s
data collection concerns. Ward, 491 U. S., at 800. Nor did
the Government ignore less restrictive approaches already
proven effective. Contrast McCullen v. Coakley, 573 U. S.
464, 490–494 (2014) (state law burdened substantially
more speech than necessary where State had not consid-
ered less restrictive measures successfully adopted by other
jurisdictions). The validity of the challenged provisions
does not turn on whether we agree with the Government’s
conclusion that its chosen regulatory path is best or “most
appropriate.” Albertini, 472 U. S., at 689. “We cannot dis-
place [the Government’s] judgment respecting content-
neutral regulations with our own, so long as its policy is
grounded on reasonable factual findings supported by evi-
dence that is substantial for a legislative determination.”
Turner II, 520 U. S., at 224. Those requirements are met
here.
                          D
  In addition to the data collection concerns addressed
above, the Government asserts an interest in preventing a
18                TIKTOK INC. v. GARLAND

                         Per Curiam

foreign adversary from having control over the recommen-
dation algorithm that runs a widely used U. S. communica-
tions platform, and from being able to wield that control to
alter the content on the platform in an undetectable man-
ner. See 2 App. 628. In petitioners’ view, that rationale is
a content-based justification that “taint[s]” the Govern-
ment’s data collection interest and triggers strict scrutiny.
Brief for TikTok 41.
   Petitioners have not pointed to any case in which this
Court has assessed the appropriate level of First Amend-
ment scrutiny for an Act of Congress justified on both
content-neutral and content-based grounds. They assert,
however, that the challenged provisions are subject to—and
fail—strict scrutiny because Congress would not have
passed the provisions absent the foreign adversary control
rationale. See Brief for TikTok 41–42; Brief for Creator Pe-
titioners 47–50. We need not determine the proper stand-
ard for mixed-justification cases or decide whether the Gov-
ernment’s foreign adversary control justification is content
neutral. Even assuming that rationale turns on content,
petitioners’ argument fails under the counterfactual analy-
sis they propose: The record before us adequately supports
the conclusion that Congress would have passed the chal-
lenged provisions based on the data collection justification
alone.
   To start, the House Report focuses overwhelmingly on the
Government’s data collection concerns, noting the
“breadth” of TikTok’s data collection, “the difficulty in as-
sessing precisely which categories of data” the platform col-
lects, the “tight interlinkages” between TikTok and the Chi-
nese Government, and the Chinese Government’s ability to
“coerc[e]” companies in China to “provid[e] data.” H. R.
Rep., at 3; see id., at 5–12 (recounting a five-year record of
Government actions raising and attempting to address
those very concerns). Indeed, it does not appear that any
legislator disputed the national security risks associated
                 Cite as: 604 U. S. ____ (2025)           19

                          Per Curiam

with TikTok’s data collection practices, and nothing in the
legislative record suggests that data collection was any-
thing but an overriding congressional concern. We are es-
pecially wary of parsing Congress’s motives on this record
with regard to an Act passed with striking bipartisan sup-
port. See 170 Cong. Rec. H1170 (Mar. 13, 2024) (352–65);
170 Cong. Rec. S2992 (Apr. 23, 2024) (79–18).
   Petitioners assert that the text of the Act itself under-
mines this conclusion. In particular, they argue that the
Government’s data collection rationale cannot justify the
requirement that a qualified divestiture preclude “any op-
erational relationship” that allows for “cooperation with re-
spect to the operation of a content recommendation algo-
rithm or an agreement with respect to data sharing.”
§2(g)(6)(B); see Brief for Creator Petitioners 48–49. We dis-
agree. The Government has explained that ByteDance Ltd.
uses the data it collects to train the TikTok recommenda-
tion algorithm, which is developed and maintained in
China. According to the Government, ByteDance Ltd. has
previously declined to agree to stop collecting U. S. user
data or sending that data to China to train the algorithm.
See 2 App. 705–706. The Government has further noted the
difficulties associated with monitoring data sharing be-
tween ByteDance Ltd. and TikTok Inc. See id., at 692–697.
Under these circumstances, we find the Government’s data
collection justification sufficient to sustain the challenged
provisions.
                       *      *   *
  There is no doubt that, for more than 170 million Ameri-
cans, TikTok offers a distinctive and expansive outlet for
expression, means of engagement, and source of commu-
nity. But Congress has determined that divestiture is nec-
essary to address its well-supported national security con-
cerns regarding TikTok’s data collection practices and
relationship with a foreign adversary. For the foregoing
20               TIKTOK INC. v. GARLAND

                        Per Curiam

reasons, we conclude that the challenged provisions do not
violate petitioners’ First Amendment rights.
  The judgment of the United States Court of Appeals for
the District of Columbia Circuit is affirmed.

                                          It is so ordered.
                  Cite as: 604 U. S. ____ (2025)            1

                    Opinion of SOTOMAYOR, J.

SUPREME COURT OF THE UNITED STATES
                          _________________

                    Nos. 24–656 and 24–657
                          _________________


       TIKTOK INC., ET AL., PETITIONERS
24–656                 v.
   MERRICK B. GARLAND, ATTORNEY GENERAL

     BRIAN FIREBAUGH, ET AL., PETITIONERS
24–657              v.
   MERRICK B. GARLAND, ATTORNEY GENERAL
ON APPLICATIONS FOR INJUNCTION PENDING REVIEW TO THE
 UNITED STATES COURT OF APPEALS FOR THE DISTRICT OF
                  COLUMBIA CIRCUIT
                       [January 17, 2025]

   JUSTICE SOTOMAYOR, concurring in part and concurring
in the judgment.
   I join all but Part II.A of the Court’s per curiam opinion.
I see no reason to assume without deciding that the Act im-
plicates the First Amendment because our precedent leaves
no doubt that it does.
   TikTok engages in expressive activity by “compiling and
curating” material on its platform. Moody v. NetChoice,
LLC, 603 U. S. 707, 731 (2024). Laws that “impose a dis-
proportionate burden” upon those engaged in expressive ac-
tivity are subject to heightened scrutiny under the First
Amendment. Arcara v. Cloud Books, Inc., 478 U. S. 697,
704 (1986); see Minneapolis Star & Tribune Co. v. Minne-
sota Comm’r of Revenue, 460 U. S. 575, 581–585 (1983).
The challenged Act plainly imposes such a burden: It bars
any entity from distributing TikTok’s speech in the United
States, unless TikTok undergoes a qualified divestiture.
The Act, moreover, effectively prohibits TikTok from collab-
2                 TIKTOK INC. v. GARLAND

                   Opinion of SOTOMAYOR, J.

orating with certain entities regarding its “content recom-
mendation algorithm” even following a qualified divesti-
ture. §2(g)(6)(B), 138 Stat. 959. And the Act implicates con-
tent creators’ “right to associate” with their preferred
publisher “for the purpose of speaking.” Rumsfeld v. Forum
for Academic and Institutional Rights, Inc., 547 U. S. 47, 68
(2006). That, too, calls for First Amendment scrutiny.
  As to the remainder of the per curiam opinion, I agree
that the Act survives petitioners’ First Amendment chal-
lenge.
                 Cite as: 604 U. S. ____ (2025)            1

              GORSUCH, J., concurring in judgment

SUPREME COURT OF THE UNITED STATES
                         _________________

                   Nos. 24–656 and 24–657
                         _________________


       TIKTOK INC., ET AL., PETITIONERS
24–656                 v.
   MERRICK B. GARLAND, ATTORNEY GENERAL

     BRIAN FIREBAUGH, ET AL., PETITIONERS
24–657              v.
   MERRICK B. GARLAND, ATTORNEY GENERAL
ON APPLICATIONS FOR INJUNCTION PENDING REVIEW TO THE
 UNITED STATES COURT OF APPEALS FOR THE DISTRICT OF
                  COLUMBIA CIRCUIT
                      [January 17, 2025]

   JUSTICE GORSUCH, concurring in judgment.
   We have had a fortnight to resolve, finally and on the
merits, a major First Amendment dispute affecting more
than 170 million Americans. Briefing finished on January
3, argument took place on January 10, and our opinions is-
sue on January 17, 2025. Given those conditions, I can
sketch out only a few, and admittedly tentative, observa-
tions.
   First, the Court rightly refrains from endorsing the gov-
ernment’s asserted interest in preventing “the covert ma-
nipulation of content” as a justification for the law before
us. Brief for Respondent 37. One man’s “covert content
manipulation” is another’s “editorial discretion.” Journal-
ists, publishers, and speakers of all kinds routinely make
less-than-transparent judgments about what stories to tell
and how to tell them. Without question, the First Amend-
ment has much to say about the right to make those choices.
It makes no difference that Americans (like TikTok Inc. and
many of its users) may wish to make decisions about what
2                  TIKTOK INC. v. GARLAND

               GORSUCH, J., concurring in judgment

they say in concert with a foreign adversary. “Those who
won our independence” knew the vital importance of the
“freedom to think as you will and to speak as you think,” as
well as the dangers that come with repressing the free flow
of ideas. Whitney v. California, 274 U. S. 357, 375 (1927)
(Brandeis, J., concurring). They knew, too, that except in
the most extreme situations, “the fitting remedy for evil
counsels is good ones.” Ibid. Too often in recent years, the
government has sought to censor disfavored speech online,
as if the internet were somehow exempt from the full sweep
of the First Amendment. See, e.g., Murthy v. Missouri, 603
U. S. 43, 76–78 (2024) (ALITO, J., dissenting). But even as
times and technologies change, “the principle of the right to
free speech is always the same.” Abrams v. United States,
250 U. S. 616, 628 (1919) (Holmes, J., dissenting).
   Second, I am pleased that the Court declines to consider
the classified evidence the government has submitted to us
but shielded from petitioners and their counsel. Ante, at 13,
n. 3. Efforts to inject secret evidence into judicial proceed-
ings present obvious constitutional concerns. Usually, “the
evidence used to prove the Government’s case must be dis-
closed to the individual so that he has an opportunity to
show that it is untrue.” Greene v. McElroy, 360 U. S. 474,
496 (1959). Maybe there is a way to handle classified evi-
dence that would afford a similar opportunity in cases like
these. Maybe, too, Congress or even the Standing Commit-
tee on Rules of Practice and Procedure would profit from
considering the question. Cf. United States v. Zubaydah,
595 U. S. 195, 245 (2022) (GORSUCH, J., dissenting). But as
the Court recognizes, we have no business considering the
government’s secret evidence here.
   Third, I harbor serious reservations about whether the
law before us is “content neutral” and thus escapes “strict
scrutiny.” See ante, at 9–12; Brief for Petitioners in No. 24–
656, pp. 25–31; Brief for Petitioners in No. 24–657, pp. 24–
26; Reply Brief in No. 24–656, pp. 10–12; Reply Brief in No.
                  Cite as: 604 U. S. ____ (2025)              3

               GORSUCH, J., concurring in judgment

24–657, pp. 8–11. More than that, while I do not doubt that
the various “tiers of scrutiny” discussed in our case law—
“rational basis, strict scrutiny, something(s) in between”—
can help focus our analysis, I worry that litigation over
them can sometimes take on a life of its own and do more to
obscure than to clarify the ultimate constitutional ques-
tions. Riddle v. Hickenlooper, 742 F. 3d 922, 932 (CA10
2014) (Gorsuch, J., concurring).
   Fourth, whatever the appropriate tier of scrutiny, I am
persuaded that the law before us seeks to serve a compel-
ling interest: preventing a foreign country, designated by
Congress and the President as an adversary of our Nation,
from harvesting vast troves of personal information about
tens of millions of Americans. The record before us estab-
lishes that TikTok mines data both from TikTok users and
about millions of others who do not consent to share their
information. 2 App. 659. According to the Federal Bureau
of Investigation, TikTok can access “any data” stored in a
consenting user’s “contact list”—including names, photos,
and other personal information about unconsenting third
parties. Ibid. (emphasis added). And because the record
shows that the People’s Republic of China (PRC) can re-
quire TikTok’s parent company “to cooperate with [its] ef-
forts to obtain personal data,” there is little to stop all that
information from ending up in the hands of a designated
foreign adversary. Id., at 696; see id., at 673–676; ante, at
3. The PRC may then use that information to “build dossi-
ers . . . for blackmail,” “conduct corporate espionage,” or ad-
vance intelligence operations. 1 App. 215; see 2 App. 659.
To be sure, assessing exactly what a foreign adversary may
do in the future implicates “delicate” and “complex” judg-
ments about foreign affairs and requires “large elements of
prophecy.” Chicago & Southern Air Lines, Inc. v. Waterman
S. S. Corp., 333 U. S. 103, 111 (1948) (Jackson, J., for the
Court). But the record the government has amassed in
these cases after years of study supplies compelling reason
4                  TIKTOK INC. v. GARLAND

               GORSUCH, J., concurring in judgment

for concern.
   Finally, the law before us also appears appropriately tai-
lored to the problem it seeks to address. Without doubt, the
remedy Congress and the President chose here is dramatic.
The law may require TikTok’s parent company to divest or
(effectively) shutter its U. S. operations. But before seeking
to impose that remedy, the coordinate branches spent years
in negotiations with TikTok exploring alternatives and ul-
timately found them wanting. Ante, at 4. And from what I
can glean from the record, that judgment was well founded.
   Consider some of the alternatives. Start with our usual
and preferred remedy under the First Amendment: more
speech. Supra, at 2. However helpful that might be, the
record shows that warning users of the risks associated
with giving their data to a foreign-adversary-controlled ap-
plication would do nothing to protect nonusers’ data. 2 App.
659–660; supra, at 3. Forbidding TikTok’s domestic opera-
tions from sending sensitive data abroad might seem an-
other option. But even if Congress were to impose serious
criminal penalties on domestic TikTok employees who vio-
late a data-sharing ban, the record suggests that would do
little to deter the PRC from exploiting TikTok to steal
Americans’ data. See 1 App. 214 (noting threats from “ma-
licious code, backdoor vulnerabilities, surreptitious surveil-
lance, and other problematic activities tied to source code
development” in the PRC); 2 App. 702 (“[A]gents of the PRC
would not fear monetary or criminal penalties in the United
States”). The record also indicates that the “size” and “com-
plexity” of TikTok’s “underlying software” may make it im-
possible for law enforcement to detect violations. Id., at
688–689; see also id., at 662. Even setting all these chal-
lenges aside, any new compliance regime could raise sepa-
rate constitutional concerns—for instance, by requiring the
government to surveil Americans’ data to ensure that it
isn’t illicitly flowing overseas. Id., at 687 (suggesting that
effective enforcement of a data-export ban might involve
                  Cite as: 604 U. S. ____ (2025)            5

               GORSUCH, J., concurring in judgment

“direct U. S. government monitoring” of the “flow of U. S.
user data”).
  Whether this law will succeed in achieving its ends, I do
not know. A determined foreign adversary may just seek to
replace one lost surveillance application with another. As
time passes and threats evolve, less dramatic and more ef-
fective solutions may emerge. Even what might happen
next to TikTok remains unclear. See Tr. of Oral Arg. 146–
147. But the question we face today is not the law’s wisdom,
only its constitutionality. Given just a handful of days after
oral argument to issue an opinion, I cannot profess the kind
of certainty I would like to have about the arguments and
record before us. All I can say is that, at this time and un-
der these constraints, the problem appears real and the re-
sponse to it not unconstitutional. As persuaded as I am of
the wisdom of Justice Brandeis in Whitney and Justice
Holmes in Abrams, their cases are not ours. See supra, at
2. Speaking with and in favor of a foreign adversary is one
thing. Allowing a foreign adversary to spy on Americans is
another.