(Slip Opinion)              OCTOBER TERM, 2023                                       1

                                       Syllabus

         NOTE: Where it is feasible, a syllabus (headnote) will be released, as is
       being done in connection with this case, at the time the opinion is issued.
       The syllabus constitutes no part of the opinion of the Court but has been
       prepared by the Reporter of Decisions for the convenience of the reader.
       See United States v. Detroit Timber & Lumber Co., 200 U. S. 321, 337.


SUPREME COURT OF THE UNITED STATES

                                       Syllabus

MOODY, ATTORNEY GENERAL OF FLORIDA, ET AL. v.
   NETCHOICE, LLC, DBA NETCHOICE, ET AL.

CERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR
                THE ELEVENTH CIRCUIT

    No. 22–277.      Argued February 26, 2024—Decided July 1, 2024*


In 2021, Florida and Texas enacted statutes regulating large social-me-
  dia companies and other internet platforms. The States’ laws differ in
  the entities they cover and the activities they limit. But both curtail
  the platforms’ capacity to engage in content moderation—to filter, pri-
  oritize, and label the varied third-party messages, videos, and other
  content their users wish to post. Both laws also include individualized-
  explanation provisions, requiring a platform to give reasons to a user
  if it removes or alters her posts.
     NetChoice LLC and the Computer & Communications Industry As-
  sociation (collectively, NetChoice)—trade associations whose members
  include Facebook and YouTube—brought facial First Amendment
  challenges against the two laws. District courts in both States entered
  preliminary injunctions.
     The Eleventh Circuit upheld the injunction of Florida’s law, as to all
  provisions relevant here. The court held that the State’s restrictions
  on content moderation trigger First Amendment scrutiny under this
  Court’s cases protecting “editorial discretion.” 34 F. 4th 1196, 1209,
  1216. The court then concluded that the content-moderation provi-
  sions are unlikely to survive heightened scrutiny. Id., at 1227–1228.
  Similarly, the Eleventh Circuit thought the statute’s individualized-
  explanation requirements likely to fall. Relying on Zauderer v. Office
  of Disciplinary Counsel of Supreme Court of Ohio, 471 U. S. 626, the
——————
  *Together with No. 22–555, NetChoice, LLC, dba NetChoice, et al. v.
Paxton, Attorney General of Texas, on certiorari to the United States
Court of Appeals for the Fifth Circuit.
2                     MOODY v. NETCHOICE, LLC

                                  Syllabus

    court held that the obligation to explain “millions of [decisions] per
    day” is “unduly burdensome and likely to chill platforms’ protected
    speech.” 34 F. 4th, at 1230.
       The Fifth Circuit disagreed across the board, and so reversed the
    preliminary injunction of the Texas law. In that court’s view, the plat-
    forms’ content-moderation activities are “not speech” at all, and so do
    not implicate the First Amendment. 49 F. 4th 439, 466, 494. But even
    if those activities were expressive, the court determined the State
    could regulate them to advance its interest in “protecting a diversity
    of ideas.” Id., at 482. The court further held that the statute’s indi-
    vidualized-explanation provisions would likely survive, even assuming
    the platforms were engaged in speech. It found no undue burden un-
    der Zauderer because the platforms needed only to “scale up” a “com-
    plaint-and-appeal process” they already used. 49 F. 4th, at 487.
Held: The judgments are vacated, and the cases are remanded, because
 neither the Eleventh Circuit nor the Fifth Circuit conducted a proper
 analysis of the facial First Amendment challenges to Florida and
 Texas laws regulating large internet platforms. Pp. 9–31.
    (a) NetChoice’s decision to litigate these cases as facial challenges
 comes at a cost. The Court has made facial challenges hard to win. In
 the First Amendment context, a plaintiff must show that “a substan-
 tial number of [the law’s] applications are unconstitutional, judged in
 relation to the statute’s plainly legitimate sweep.” Americans for Pros-
 perity Foundation v. Bonta, 594 U. S. 595, 615.
    So far in these cases, no one has paid much attention to that issue.
 Analysis and arguments below focused mainly on how the laws applied
 to the content-moderation practices that giant social-media platforms
 use on their best-known services to filter, alter, or label their users’
 posts, i.e., on how the laws applied to the likes of Facebook’s News Feed
 and YouTube’s homepage. They did not address the full range of ac-
 tivities the laws cover, and measure the constitutional against the un-
 constitutional applications.
    The proper analysis begins with an assessment of the state laws’
 scope. The laws appear to apply beyond Facebook’s News Feed and its
 ilk. But it’s not clear to what extent, if at all, they affect social-media
 giants’ other services, like direct messaging, or what they have to say
 about other platforms and functions. And before a court can do any-
 thing else with these facial challenges, it must “determine what [the
 law] covers.” United States v. Hansen, 599 U. S. 762, 770.
    The next order of business is to decide which of the laws’ applications
 violate the First Amendment, and to measure them against the rest.
 For the content-moderation provisions, that means asking, as to every
 covered platform or function, whether there is an intrusion on pro-
                    Cite as: 603 U. S. ____ (2024)                      3

                               Syllabus

tected editorial discretion. And for the individualized-explanation pro-
visions, it means asking, again as to each thing covered, whether the
required disclosures unduly burden expression. See Zauderer, 471
U. S., at 651.
   Because this is “a court of review, not of first view,” Cutter v. Wil-
kinson, 544 U. S. 709, 718, n. 7, this Court cannot undertake the
needed inquiries. And because neither the Eleventh nor the Fifth Cir-
cuit performed the facial analysis in the way described above, their
decisions must be vacated and the cases remanded. Pp. 9–12.
   (b) It is necessary to say more about how the First Amendment re-
lates to the laws’ content-moderation provisions, to ensure that the fa-
cial analysis proceeds on the right path in the courts below. That need
is especially stark for the Fifth Circuit, whose decision rested on a se-
rious misunderstanding of First Amendment precedent and principle.
Pp. 12–29.
     (1) The Court has repeatedly held that ordering a party to provide
a forum for someone else’s views implicates the First Amendment if,
though only if, the regulated party is engaged in its own expressive
activity, which the mandated access would alter or disrupt. First, in
Miami Herald Publishing Co. v. Tornillo, 418 U. S. 241, the Court held
that a Florida law requiring a newspaper to give a political candidate
a right to reply to critical coverage interfered with the newspaper’s
“exercise of editorial control and judgment.” Id., at 243, 258. Florida
could not, the Court explained, override the newspaper’s decisions
about the “content of the paper” and “[t]he choice of material to go into”
it, because that would substitute “governmental regulation” for the
“crucial process” of editorial choice. Id., at 258. The next case, Pacific
Gas & Elec. Co. v. Public Util. Comm’n of Cal., 475 U. S. 1, involved
California’s attempt to force a private utility to include material from
a certain consumer-advocacy group in its regular newsletter to con-
sumers. The Court held that an interest in “offer[ing] the public a
greater variety of views” could not justify compelling the utility “to
carry speech with which it disagreed” and thus to “alter its own mes-
sage.” Id., at 11, n. 7, 12, 16. Then in Turner Broadcasting System,
Inc. v. FCC, 512 U. S. 622, the Court considered federal “must-carry”
rules, which required cable operators to allocate certain channels to
local broadcast stations. The Court had no doubt the First Amend-
ment was implicated, because the rules “interfere[d]” with the cable
operators’ “editorial discretion over which stations or programs to in-
clude in [their] repertoire.” Id., at 636, 643–644. The capstone of this
line of precedents, Hurley v. Irish-American Gay, Lesbian and Bisex-
ual Group of Boston, Inc., 515 U. S. 557, held that the First Amend-
ment prevented Massachusetts from compelling parade organizers to
admit as a participant a gay and lesbian group seeking to convey a
4                      MOODY v. NETCHOICE, LLC

                                   Syllabus

    message of “pride.” Id., at 561. It held that ordering the group’s ad-
    mittance would “alter the expressive content of the[ ] parade,” and that
    the decision to exclude the group’s message was the organizers’ alone.
    Id., at 572–574.
       From that slew of individual cases, three general points emerge.
    First, the First Amendment offers protection when an entity engaged
    in compiling and curating others’ speech into an expressive product of
    its own is directed to accommodate messages it would prefer to ex-
    clude. Second, none of that changes just because a compiler includes
    most items and excludes just a few. It “is enough” for the compiler to
    exclude the handful of messages it most “disfavor[s].” Hurley, 515
    U. S., at 574. Third, the government cannot get its way just by assert-
    ing an interest in better balancing the marketplace of ideas. In case
    after case, the Court has barred the government from forcing a private
    speaker to present views it wished to spurn in order to rejigger the
    expressive realm. Pp. 13–19.
         (2) “[W]hatever the challenges of applying the Constitution to
    ever-advancing technology, the basic principles” of the First Amend-
    ment “do not vary.” Brown v. Entertainment Merchants Assn., 564
    U. S. 786, 790. And the principles elaborated in the above-summarized
    decisions establish that Texas is not likely to succeed in enforcing its
    law against the platforms’ application of their content-moderation pol-
    icies to their main feeds.
       Facebook’s News Feed and YouTube’s homepage present users with
    a continually updating, personalized stream of other users’ posts. The
    key to the scheme is prioritization of content, achieved through algo-
    rithms. The selection and ranking is most often based on a user’s ex-
    pressed interests and past activities, but it may also be based on other
    factors, including the platform’s preferences. Facebook’s Community
    Standards and YouTube’s Community Guidelines detail the messages
    and videos that the platforms disfavor. The platforms write algo-
    rithms to implement those standards—for example, to prefer content
    deemed particularly trustworthy or to suppress content viewed as de-
    ceptive. Beyond ranking content, platforms may add labels, to give
    users additional context. And they also remove posts entirely that con-
    tain prohibited subjects or messages, such as pornography, hate
    speech, and misinformation on certain topics. The platforms thus un-
    abashedly control the content that will appear to users.
       Texas’s law, though, limits their power to do so. Its central provision
    prohibits covered platforms from “censor[ing]” a “user’s expression”
    based on the “viewpoint” it contains. Tex. Civ. Prac. & Rem. Code Ann.
    §143A.002(a)(2). The platforms thus cannot do any of the things they
    typically do (on their main feeds) to posts they disapprove—cannot de-
    mote, label, or remove them—whenever the action is based on the
                      Cite as: 603 U. S. ____ (2024)                      5

                                 Syllabus

  post’s viewpoint. That limitation profoundly alters the platforms’
  choices about the views they convey.
     The Court has repeatedly held that type of regulation to interfere
  with protected speech. Like the editors, cable operators, and parade
  organizers this Court has previously considered, the major social-me-
  dia platforms curate their feeds by combining “multifarious voices” to
  create a distinctive expressive offering. Hurley, 515 U. S., at 569.
  Their choices about which messages are appropriate give the feed a
  particular expressive quality and “constitute the exercise” of protected
  “editorial control.” Tornillo, 418 U. S., at 258. And the Texas law tar-
  gets those expressive choices by forcing the platforms to present and
  promote content on their feeds that they regard as objectionable.
     That those platforms happily convey the lion’s share of posts sub-
  mitted to them makes no significant First Amendment difference. In
  Hurley, the Court held that the parade organizers’ “lenient” admis-
  sions policy did “not forfeit” their right to reject the few messages they
  found harmful or offensive. 515 U. S., at 569. Similarly here, that
  Facebook and YouTube convey a mass of messages does not license
  Texas to prohibit them from deleting posts they disfavor. Pp. 19–26.
        (3) The interest Texas relies on cannot sustain its law. In the
  usual First Amendment case, the Court must decide whether to apply
  strict or intermediate scrutiny. But here, Texas’s law does not pass
  even the less stringent form of review. Under that standard, a law
  must further a “substantial governmental interest” that is “unrelated
  to the suppression of free expression.” United States v. O’Brien, 391
  U. S. 367, 377. Many possible interests relating to social media can
  meet that test. But Texas’s asserted interest relates to the suppression
  of free expression, and it is not valid, let alone substantial.
     Texas has never been shy, and always been consistent, about its in-
  terest: The objective is to correct the mix of viewpoints that major plat-
  forms present. But a State may not interfere with private actors’
  speech to advance its own vision of ideological balance. States (and
  their citizens) are of course right to want an expressive realm in which
  the public has access to a wide range of views. But the way the First
  Amendment achieves that goal is by preventing the government from
  “tilt[ing] public debate in a preferred direction,” Sorrell v. IMS Health
  Inc., 564 U. S. 552, 578–579, not by licensing the government to stop
  private actors from speaking as they wish and preferring some views
  over others. A State cannot prohibit speech to rebalance the speech
  market. That unadorned interest is not “unrelated to the suppression
  of free expression.” And Texas may not pursue it consistent with the
  First Amendment. Pp. 26–29.
No. 22–277, 34 F. 4th 1196; No. 22–555, 49 F. 4th 439; vacated and re-
 manded.
6                    MOODY v. NETCHOICE, LLC

                                Syllabus

  KAGAN, J., delivered the opinion of the Court, in which ROBERTS, C. J.,
and SOTOMAYOR, KAVANAUGH, and BARRETT, JJ., joined in full, and in
which JACKSON, J., joined as to Parts I, II and III–A. BARRETT, J., filed a
concurring opinion. JACKSON, J., filed an opinion concurring in part and
concurring in the judgment. THOMAS, J., filed an opinion concurring in
the judgment. ALITO, J., filed an opinion concurring in the judgment, in
which THOMAS and GORSUCH, JJ., joined.
                         Cite as: 603 U. S. ____ (2024)                              1

                              Opinion of the Court

      NOTICE: This opinion is subject to formal revision before publication in the
      United States Reports. Readers are requested to notify the Reporter of
      Decisions, Supreme Court of the United States, Washington, D. C. 20543,
      pio@supremecourt.gov, of any typographical or other formal errors.


SUPREME COURT OF THE UNITED STATES
                                    _________________

                            Nos. 22–277 and 22–555
                                    _________________


     ASHLEY MOODY, ATTORNEY GENERAL OF
         FLORIDA, ET AL., PETITIONERS
22–277                v.
     NETCHOICE, LLC, DBA NETCHOICE, ET AL.
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
          APPEALS FOR THE ELEVENTH CIRCUIT



     NETCHOICE, LLC, DBA NETCHOICE, ET AL.,
                 PETITIONERS
22–555                v.
   KEN PAXTON, ATTORNEY GENERAL OF TEXAS
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
            APPEALS FOR THE FIFTH CIRCUIT
                                   [July 1, 2024]

  JUSTICE KAGAN delivered the opinion of the Court.*
  Not even thirty years ago, this Court felt the need to ex-
plain to the opinion-reading public that the “Internet is an
international network of interconnected computers.” Reno
v. American Civil Liberties Union, 521 U. S. 844, 849
(1997). Things have changed since then. At the time, only
40 million people used the internet. See id., at 850. Today,
Facebook and YouTube alone have over two billion users
each. See App. in No. 22–555, p. 67a. And the public likely
no longer needs this Court to define the internet.
——————
 *JUSTICE JACKSON joins Parts I, II, and III–A of this opinion.
2                MOODY v. NETCHOICE, LLC

                      Opinion of the Court

   These years have brought a dizzying transformation in
how people communicate, and with it a raft of public policy
issues. Social-media platforms, as well as other websites,
have gone from unheard-of to inescapable. They structure
how we relate to family and friends, as well as to busi-
nesses, civic organizations, and governments. The novel
services they offer make our lives better, and make them
worse—create unparalleled opportunities and unprece-
dented dangers. The questions of whether, when, and how
to regulate online entities, and in particular the social-media
giants, are understandably on the front-burner of many leg-
islatures and agencies. And those government actors will
generally be better positioned than courts to respond to the
emerging challenges social-media entities pose.
   But courts still have a necessary role in protecting those
entities’ rights of speech, as courts have historically pro-
tected traditional media’s rights. To the extent that social-
media platforms create expressive products, they receive
the First Amendment’s protection. And although these
cases are here in a preliminary posture, the current record
suggests that some platforms, in at least some functions,
are indeed engaged in expression. In constructing certain
feeds, those platforms make choices about what third-party
speech to display and how to display it. They include and
exclude, organize and prioritize—and in making millions of
those decisions each day, produce their own distinctive com-
pilations of expression. And while much about social media
is new, the essence of that project is something this Court
has seen before. Traditional publishers and editors also se-
lect and shape other parties’ expression into their own cu-
rated speech products. And we have repeatedly held that
laws curtailing their editorial choices must meet the First
Amendment’s requirements. The principle does not change
because the curated compilation has gone from the physical
to the virtual world. In the latter, as in the former, govern-
ment efforts to alter an edited compilation of third-party
                  Cite as: 603 U. S. ____ (2024)            3

                      Opinion of the Court

expression are subject to judicial review for compliance
with the First Amendment.
  Today, we consider whether two state laws regulating social-
media platforms and other websites facially violate the
First Amendment. The laws, from Florida and Texas, re-
strict the ability of social-media platforms to control
whether and how third-party posts are presented to other
users. Or otherwise put, the laws limit the platforms’ ca-
pacity to engage in content moderation—to filter, prioritize,
and label the varied messages, videos, and other content
their users wish to post. In addition, though far less ad-
dressed in this Court, the laws require a platform to provide
an individualized explanation to a user if it removes or al-
ters her posts. NetChoice, an internet trade association,
challenged both laws on their face—as a whole, rather than
as to particular applications. The cases come to us at an
early stage, on review of preliminary injunctions. The
Court of Appeals for the Eleventh Circuit upheld such an
injunction, finding that the Florida law was not likely to
survive First Amendment review. The Court of Appeals for
the Fifth Circuit reversed a similar injunction, primarily
reasoning that the Texas law does not regulate any speech
and so does not implicate the First Amendment.
  Today, we vacate both decisions for reasons separate
from the First Amendment merits, because neither Court of
Appeals properly considered the facial nature of
NetChoice’s challenge. The courts mainly addressed what
the parties had focused on. And the parties mainly argued
these cases as if the laws applied only to the curated feeds
offered by the largest and most paradigmatic social-media
platforms—as if, say, each case presented an as-applied
challenge brought by Facebook protesting its loss of control
over the content of its News Feed. But argument in this
Court revealed that the laws might apply to, and differently
affect, other kinds of websites and apps. In a facial chal-
lenge, that could well matter, even when the challenge is
4                MOODY v. NETCHOICE, LLC

                      Opinion of the Court

brought under the First Amendment. As explained below,
the question in such a case is whether a law’s unconstitu-
tional applications are substantial compared to its constitu-
tional ones. To make that judgment, a court must deter-
mine a law’s full set of applications, evaluate which are
constitutional and which are not, and compare the one to
the other. Neither court performed that necessary inquiry.
   To do that right, of course, a court must understand what
kind of government actions the First Amendment prohibits.
We therefore set out the relevant constitutional principles,
and explain how one of the Courts of Appeals failed to follow
them. Contrary to what the Fifth Circuit thought, the cur-
rent record indicates that the Texas law does regulate
speech when applied in the way the parties focused on be-
low—when applied, that is, to prevent Facebook (or
YouTube) from using its content-moderation standards to
remove, alter, organize, prioritize, or disclaim posts in its
News Feed (or homepage). The law then prevents exactly
the kind of editorial judgments this Court has previously
held to receive First Amendment protection. It prevents a
platform from compiling the third-party speech it wants in
the way it wants, and thus from offering the expressive
product that most reflects its own views and priorities. Still
more, the law—again, in that specific application—is un-
likely to withstand First Amendment scrutiny. Texas has
thus far justified the law as necessary to balance the mix of
speech on Facebook’s News Feed and similar platforms; and
the record reflects that Texas officials passed it because
they thought those feeds skewed against politically con-
servative voices. But this Court has many times held, in
many contexts, that it is no job for government to decide
what counts as the right balance of private expression—to
“un-bias” what it thinks biased, rather than to leave such
judgments to speakers and their audiences. That principle
works for social-media platforms as it does for others.
   In sum, there is much work to do below on both these
                 Cite as: 603 U. S. ____ (2024)           5

                     Opinion of the Court

cases, given the facial nature of NetChoice’s challenges.
But that work must be done consistent with the First
Amendment, which does not go on leave when social media
are involved.
                              I
   As commonly understood, the term “social media plat-
forms” typically refers to websites and mobile apps that al-
low users to upload content—messages, pictures, videos,
and so on—to share with others. Those viewing the content
can then react to it, comment on it, or share it themselves.
The biggest social-media companies—entities like Face-
book and YouTube—host a staggering amount of content.
Facebook users, for example, share more than 100 billion
messages every day. See App. in No. 22–555, at 67a. And
YouTube sees more than 500 hours of video uploaded every
minute. See ibid.
   In the face of that deluge, the major platforms cull and
organize uploaded posts in a variety of ways. A user does
not see everything—even everything from the people she
follows—in reverse-chronological order. The platforms will
have removed some content entirely; ranked or otherwise
prioritized what remains; and sometimes added warnings
or labels. Of particular relevance here, Facebook and
YouTube make some of those decisions in conformity with
content-moderation policies they call Community Stand-
ards and Community Guidelines. Those rules list the sub-
jects or messages the platform prohibits or discourages—
say, pornography, hate speech, or misinformation on select
topics. The rules thus lead Facebook and YouTube to re-
move, disfavor, or label various posts based on their con-
tent.
   In 2021, Florida and Texas enacted statutes regulating
internet platforms, including the large social-media compa-
nies just mentioned. The States’ laws differ in the entities
they cover and the activities they limit. But both contain
6                    MOODY v. NETCHOICE, LLC

                          Opinion of the Court

content-moderation provisions, restricting covered plat-
forms’ choices about whether and how to display user-
generated content to the public.         And both include
individualized-explanation provisions, requiring platforms
to give reasons for particular content-moderation choices.
   Florida’s law regulates “social media platforms,” as de-
fined expansively, that have annual gross revenue of over
$100 million or more than 100 million monthly active users.
Fla. Stat. §501.2041(1)(g) (2023).1 The statute restricts var-
ied ways of “censor[ing]” or otherwise disfavoring posts—
including deleting, altering, labeling, or deprioritizing
them—based on their content or source. §501.2041(1)(b).
For example, the law prohibits a platform from taking those
actions against “a journalistic enterprise based on the con-
tent of its publication or broadcast.” §501.2041(2)(j). Simi-
larly, the law prevents deprioritizing posts by or about po-
litical candidates. See §501.2041(2)(h). And the law
requires platforms to apply their content-moderation prac-
tices to users “in a consistent manner.” §501.2041(2)(b).
   In addition, the Florida law mandates that a platform
provide an explanation to a user any time it removes or al-
ters any of her posts. See §501.2041(2)(d)(1). The requisite
notice must be delivered within seven days, and contain
both a “thorough rationale” for the action and an account of
how the platform became aware of the targeted material.
§501.2041(3).
   The Texas law regulates any social-media platform, hav-
ing over 50 million monthly active users, that allows its us-
ers “to communicate with other users for the primary pur-
pose of posting information, comments, messages, or
images.” Tex. Bus. & Com. Code Ann. §§120.001(1),
——————
  1 The definition of “social-media platforms” covers “any information

service, system, Internet search engine, or access software provider” that
“[p]rovides or enables computer access by multiple users to a computer
server, including an Internet platform or a social media site.” Fla. Stat.
§501.2041(1)(g)(1).
                     Cite as: 603 U. S. ____ (2024)                     7

                          Opinion of the Court

120.002(b) (West Cum. Supp. 2023).2 With several excep-
tions, the statute prevents platforms from “censor[ing]” a
user or a user’s expression based on viewpoint. Tex. Civ.
Prac. & Rem. Code Ann. §§143A.002(a), 143A.006 (West
Cum. Supp. 2023). That ban on “censor[ing]” covers any
action to “block, ban, remove, deplatform, demonetize, de-
boost, restrict, deny equal access or visibility to, or other-
wise discriminate against expression.” §143A.001(1). The
statute also requires that “concurrently with the removal”
of user content, the platform shall “notify the user” and “ex-
plain the reason the content was removed.” §120.103(a)(1).
The user gets a right of appeal, and the platform must ad-
dress an appeal within 14 days. See §§120.103(a)(2),
120.104.
   Soon after Florida and Texas enacted those statutes,
NetChoice LLC and the Computer & Communications In-
dustry Association (collectively, NetChoice)—trade associa-
tions whose members include Facebook and YouTube—
brought facial First Amendment challenges against the two
laws. District courts in both States entered preliminary in-
junctions, halting the laws’ enforcement. See 546 F. Supp.
3d 1082, 1096 (ND Fla. 2021); 573 F. Supp. 3d 1092, 1117
(WD Tex. 2021). Each court held that the suit before it is
likely to succeed because the statute infringes on the con-
stitutionally protected “editorial judgment” of NetChoice’s
members about what material they will display. See 546
F. Supp. 3d, at 1090; 573 F. Supp. 3d, at 1107.
   The Eleventh Circuit upheld the injunction of Florida’s
law, as to all provisions relevant here. The court held that
the State’s restrictions on content moderation trigger First
Amendment scrutiny under this Court’s cases protecting
——————
  2 The statute further clarifies that it does not cover internet service

providers, email providers, and any online service, website, or app con-
sisting “primarily of news, sports, entertainment, or other information
or content that is not user generated but is preselected by the provider.”
§120.001(1).
8                MOODY v. NETCHOICE, LLC

                      Opinion of the Court

“editorial discretion.” 34 F. 4th 1196, 1209, 1216 (2022).
When a social-media platform “removes or deprioritizes a
user or post,” the court explained, it makes a “judgment
rooted in the platform’s own views about the sorts of content
and viewpoints that are valuable and appropriate for dis-
semination.” Id., at 1210. The court concluded that the
content-moderation provisions are unlikely to survive “in-
termediate—let alone strict—scrutiny,” because a State has
no legitimate interest in counteracting “private ‘censor-
ship’ ” by “tilt[ing] public debate in a preferred direction.”
Id., at 1227–1228. Similarly, the Eleventh Circuit thought
the statute’s individualized-explanation requirements
likely to fall. Applying the standard from Zauderer v. Office
of Disciplinary Counsel of Supreme Court of Ohio, 471 U. S.
626 (1985), the court held that the obligation to explain
“millions of [decisions] per day” is “unduly burdensome and
likely to chill platforms’ protected speech.” 34 F. 4th, at
1230.
   The Fifth Circuit disagreed across the board, and so re-
versed the preliminary injunction before it. In that court’s
view, the platforms’ content-moderation activities are “not
speech” at all, and so do not implicate the First Amend-
ment. 49 F. 4th 439, 466, 494 (2022). But even if those ac-
tivities were expressive, the court continued, the State
could regulate them to advance its interest in “protecting a
diversity of ideas.” Id., at 482 (emphasis deleted). The
court further held that the statute’s individualized-
explanation provisions would likely survive, again even as-
suming that the platforms were engaged in speech. Those
requirements, the court maintained, are not unduly bur-
densome under Zauderer because the platforms needed
only to “scale up” a “complaint-and-appeal process” they al-
ready used. 49 F. 4th, at 487.
   We granted certiorari to resolve the split between the
Fifth and Eleventh Circuits. 600 U. S. ___ (2023).
                  Cite as: 603 U. S. ____ (2024)              9

                      Opinion of the Court

                              II
   NetChoice chose to litigate these cases as facial chal-
lenges, and that decision comes at a cost. For a host of good
reasons, courts usually handle constitutional claims case by
case, not en masse. See Washington State Grange v. Wash-
ington State Republican Party, 552 U. S. 442, 450–451
(2008). “Claims of facial invalidity often rest on specula-
tion” about the law’s coverage and its future enforcement.
Id., at 450. And “facial challenges threaten to short circuit
the democratic process” by preventing duly enacted laws
from being implemented in constitutional ways. Id., at 451.
This Court has therefore made facial challenges hard to
win.
   That is true even when a facial suit is based on the First
Amendment, although then a different standard applies. In
other cases, a plaintiff cannot succeed on a facial challenge
unless he “establish[es] that no set of circumstances exists
under which the [law] would be valid,” or he shows that the
law lacks a “plainly legitimate sweep.” United States v. Sa-
lerno, 481 U. S. 739, 745 (1987); Washington State Grange,
552 U. S., at 449. In First Amendment cases, however, this
Court has lowered that very high bar. To “provide[ ] breath-
ing room for free expression,” we have substituted a less de-
manding though still rigorous standard. United States v.
Hansen, 599 U. S. 762, 769 (2023). The question is whether
“a substantial number of [the law’s] applications are uncon-
stitutional, judged in relation to the statute’s plainly legiti-
mate sweep.” Americans for Prosperity Foundation v.
Bonta, 594 U. S. 595, 615 (2021); see Hansen, 599 U. S., at
770 (likewise asking whether the law “prohibits a substan-
tial amount of protected speech relative to its plainly legit-
imate sweep”). So in this singular context, even a law with
“a plainly legitimate sweep” may be struck down in its en-
tirety. But that is so only if the law’s unconstitutional ap-
plications substantially outweigh its constitutional ones.
   So far in these cases, no one has paid much attention to
10                MOODY v. NETCHOICE, LLC

                      Opinion of the Court

that issue. In the lower courts, NetChoice and the States
alike treated the laws as having certain heartland applica-
tions, and mostly confined their battle to that terrain. More
specifically, the focus was on how the laws applied to the
content-moderation practices that giant social-media plat-
forms use on their best-known services to filter, alter, or la-
bel their users’ posts. Or more specifically still, the focus
was on how the laws applied to Facebook’s News Feed and
YouTube’s homepage. Reflecting the parties’ arguments,
the Eleventh and Fifth Circuits also mostly confined their
analysis in that way. See 34 F. 4th, at 1210, 1213 (consid-
ering “platforms like Facebook, Twitter, YouTube, and Tik-
Tok” and content moderation in “viewers’ feeds”); 49 F. 4th,
at 445, 460, 478, 492 (considering platforms “such as Face-
book, Twitter, and YouTube” and referencing users’ feeds);
see also id., at 501 (Southwick, J., concurring in part and
dissenting in part) (analyzing a curated feed). On their way
to opposing conclusions, they concentrated on the same is-
sue: whether a state law can regulate the content-moderation
practices used in Facebook’s News Feed (or near equiva-
lents). They did not address the full range of activities the
laws cover, and measure the constitutional against the un-
constitutional applications. In short, they treated these
cases more like as-applied claims than like facial ones.
   The first step in the proper facial analysis is to assess the
state laws’ scope. What activities, by what actors, do the
laws prohibit or otherwise regulate? The laws of course dif-
fer one from the other. But both, at least on their face, ap-
pear to apply beyond Facebook’s News Feed and its ilk.
Members of this Court asked some of the relevant questions
at oral argument. Starting with Facebook and the other
giants: To what extent, if at all, do the laws affect their
other services, like direct messaging or events manage-
ment? See Tr. of Oral Arg. in No. 22–555, pp. 62–63; Tr. of
Oral Arg. in No. 22–277, pp. 24–25; App. in No. 22–277,
pp. 129, 159. And beyond those social-media entities, what
                  Cite as: 603 U. S. ____ (2024)             11

                      Opinion of the Court

do the laws have to say, if anything, about how an email
provider like Gmail filters incoming messages, how an
online marketplace like Etsy displays customer reviews,
how a payment service like Venmo manages friends’ finan-
cial exchanges, or how a ride-sharing service like Uber
runs? See Tr. of Oral Arg. in No. 22–277, at 74–79, 95–98;
see also id., at 153 (Solicitor General) (“I have some sympa-
thy [for the Court] here. In preparation for this argument,
I’ve been working with my team to say, does this even cover
direct messaging? Does this even cover Gmail?”). Those
are examples only. The online world is variegated and com-
plex, encompassing an ever-growing number of apps, ser-
vices, functionalities, and methods for communication and
connection. Each might (or might not) have to change be-
cause of the provisions, as to either content moderation or
individualized explanation, in Florida’s or Texas’s law. Be-
fore a court can do anything else with these facial chal-
lenges, it must address that set of issues—in short, must
“determine what [the law] covers.” Hansen, 599 U. S., at
770.
   The next order of business is to decide which of the laws’
applications violate the First Amendment, and to measure
them against the rest. For the content-moderation provi-
sions, that means asking, as to every covered platform or
function, whether there is an intrusion on protected
editorial discretion. See infra, at 13–19. And for the
individualized-explanation provisions, it means asking,
again as to each thing covered, whether the required disclo-
sures unduly burden expression. See Zauderer, 471 U. S.,
at 651. Even on a preliminary record, it is not hard to see
how the answers might differ as between regulation of Fa-
cebook’s News Feed (considered in the courts below) and,
say, its direct messaging service (not so considered). Curat-
ing a feed and transmitting direct messages, one might
think, involve different levels of editorial choice, so that the
one creates an expressive product and the other does not.
12                MOODY v. NETCHOICE, LLC

                      Opinion of the Court

If so, regulation of those diverse activities could well fall on
different sides of the constitutional line. To decide the fa-
cial challenges here, the courts below must explore the laws’
full range of applications—the constitutionally impermissi-
ble and permissible both—and compare the two sets.
Maybe the parties treated the content-moderation choices
reflected in Facebook’s News Feed and YouTube’s homep-
age as the laws’ heartland applications because they are the
principal things regulated, and should have just that
weight in the facial analysis. Or maybe not: Maybe the par-
ties’ focus had all to do with litigation strategy, and there is
a sphere of other applications—and constitutional ones—
that would prevent the laws’ facial invalidation.
   The problem for this Court is that it cannot undertake
the needed inquiries. “[W]e are a court of review, not of first
view.” Cutter v. Wilkinson, 544 U. S. 709, 718, n. 7 (2005).
Neither the Eleventh Circuit nor the Fifth Circuit per-
formed the facial analysis in the way just described. And
even were we to ignore the value of other courts going first,
we could not proceed very far. The parties have not briefed
the critical issues here, and the record is underdeveloped.
So we vacate the decisions below and remand these cases.
That will enable the lower courts to consider the scope of
the laws’ applications, and weigh the unconstitutional as
against the constitutional ones.
                              III
  But it is necessary to say more about how the First
Amendment relates to the laws’ content-moderation provi-
sions, to ensure that the facial analysis proceeds on the
right path in the courts below. That need is especially stark
for the Fifth Circuit. Recall that it held that the content
choices the major platforms make for their main feeds are
“not speech” at all, so States may regulate them free of the
First Amendment’s restraints. 49 F. 4th, at 494; see supra,
at 8. And even if those activities were expressive, the court
                     Cite as: 603 U. S. ____ (2024)                   13

                          Opinion of the Court

held, Texas’s interest in better balancing the marketplace
of ideas would satisfy First Amendment scrutiny. See 49
F. 4th, at 482. If we said nothing about those views, the
court presumably would repeat them when it next considers
NetChoice’s challenge. It would thus find that significant
applications of the Texas law—and so significant inputs
into the appropriate facial analysis—raise no First Amend-
ment difficulties. But that conclusion would rest on a seri-
ous misunderstanding of First Amendment precedent and
principle. The Fifth Circuit was wrong in concluding that
Texas’s restrictions on the platforms’ selection, ordering,
and labeling of third-party posts do not interfere with ex-
pression. And the court was wrong to treat as valid Texas’s
interest in changing the content of the platforms’ feeds. Ex-
plaining why that is so will prevent the Fifth Circuit from
repeating its errors as to Facebook’s and YouTube’s main
feeds. (And our analysis of Texas’s law may also aid the
Eleventh Circuit, which saw the First Amendment issues
much as we do, when next considering NetChoice’s facial
challenge.) But a caveat: Nothing said here addresses any
of the laws’ other applications, which may or may not share
the First Amendment problems described below.3
                             A
   Despite the relative novelty of the technology before us,
the main problem in this case—and the inquiry it calls for—
is not new. At bottom, Texas’s law requires the platforms
to carry and promote user speech that they would rather
——————
  3 Although the discussion below focuses on Texas’s content-moderation

provisions, it also bears on how the lower courts should address the
individualized-explanation provisions in the upcoming facial inquiry. As
noted, requirements of that kind violate the First Amendment if they
unduly burden expressive activity. See Zauderer v. Office of Disciplinary
Counsel of Supreme Court of Ohio, 471 U. S. 626, 651 (1985); supra, at
11. So our explanation of why Facebook and YouTube are engaged in
expression when they make content-moderation choices in their main
feeds should inform the courts’ further consideration of that issue.
14               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

discard or downplay. The platforms object that the law thus
forces them to alter the content of their expression—a par-
ticular edited compilation of third-party speech. See Brief
for NetChoice in No. 22–555, pp. 18–34. That controversy
sounds a familiar note. We have repeatedly faced the ques-
tion whether ordering a party to provide a forum for some-
one else’s views implicates the First Amendment. And we
have repeatedly held that it does so if, though only if, the
regulated party is engaged in its own expressive activity,
which the mandated access would alter or disrupt. So too
we have held, when applying that principle, that expressive
activity includes presenting a curated compilation of speech
originally created by others. A review of the relevant prec-
edents will help resolve the question here.
   The seminal case is Miami Herald Publishing Co. v.
Tornillo, 418 U. S. 241 (1974). There, a Florida law re-
quired a newspaper to give a political candidate a right to
reply when it published “criticism and attacks on his rec-
ord.” Id., at 243. The Court held the law to violate the First
Amendment because it interfered with the newspaper’s “ex-
ercise of editorial control and judgment.” Id., at 258. Forc-
ing the paper to print what “it would not otherwise print,”
the Court explained, “intru[ded] into the function of edi-
tors.” Id., at 256, 258. For that function was, first and fore-
most, to make decisions about the “content of the paper”
and “[t]he choice of material to go into” it. Id., at 258. In
protecting that right of editorial control, the Court recog-
nized a possible downside. It noted the access advocates’
view (similar to the States’ view here) that “modern media
empires” had gained ever greater capacity to “shape” and
even “manipulate popular opinion.” Id., at 249–250. And
the Court expressed some sympathy with that diagnosis.
See id., at 254. But the cure proposed, it concluded, collided
with the First Amendment’s antipathy to state manipula-
tion of the speech market. Florida, the Court explained,
                  Cite as: 603 U. S. ____ (2024)            15

                      Opinion of the Court

could not substitute “governmental regulation” for the “cru-
cial process” of editorial choice. Id., at 258.
   Next up was Pacific Gas & Elec. Co. v. Public Util.
Comm’n of Cal., 475 U. S. 1 (1986) (PG&E), which the Court
thought to follow naturally from Tornillo. See 475 U. S., at
9–12 (plurality opinion); id., at 21 (Burger, C. J., concur-
ring). A private utility in California regularly put a news-
letter in its billing envelopes expressing its views of energy
policy. The State directed it to include as well material
from a consumer-advocacy group giving a different perspec-
tive. The utility objected, and the Court held again that the
interest in “offer[ing] the public a greater variety of views”
could not justify the regulation. Id., at 12. California was
compelling the utility (as Florida had compelled a newspa-
per) “to carry speech with which it disagreed” and thus to
“alter its own message.” Id., at 11, n. 7, 16.
   In Turner Broadcasting System, Inc. v. FCC, 512 U. S.
622 (1994) (Turner I ), the Court further underscored the
constitutional protection given to editorial choice. At issue
were federal “must-carry” rules, requiring cable operators
to allocate some of their channels to local broadcast sta-
tions. The Court had no doubt that the First Amendment
was implicated, because the operators were engaging in ex-
pressive activity. They were, the Court explained, “exercis-
ing editorial discretion over which stations or programs to
include in [their] repertoire.” Id., at 636. And the rules
“interfere[d]” with that discretion by forcing the operators
to carry stations they would not otherwise have chosen. Id.,
at 643–644. In a later decision, the Court ruled that the
regulation survived First Amendment review because it
was necessary to prevent the demise of local broadcasting.
See Turner Broadcasting System, Inc. v. FCC, 520 U. S.
180, 185, 189–190 (1997) (Turner II ); see infra, at 28, n. 10.
But for purposes of today’s cases, the takeaway of Turner is
this holding: A private party’s collection of third-party con-
tent into a single speech product (the operators’ “repertoire”
16               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

of programming) is itself expressive, and intrusion into that
activity must be specially justified under the First Amend-
ment.
   The capstone of those precedents came in Hurley v. Irish-
American Gay, Lesbian and Bisexual Group of Boston, Inc.,
515 U. S. 557 (1995), when the Court considered (of all
things) a parade. The question was whether Massachusetts
could require the organizers of a St. Patrick’s Day parade
to admit as a participant a gay and lesbian group seeking
to convey a message of “pride.” Id., at 561. The Court held
unanimously that the First Amendment precluded that
compulsion. The “selection of contingents to make a pa-
rade,” it explained, is entitled to First Amendment protec-
tion, no less than a newspaper’s “presentation of an edited
compilation of [other persons’] speech.” Id., at 570 (citing
Tornillo, 418 U. S., at 258). And that meant the State could
not tell the parade organizers whom to include. Because
“every participating unit affects the message,” said the
Court, ordering the group’s admittance would “alter the ex-
pressive content of the[ ] parade.” Hurley, 515 U. S., at 572–
573. The parade’s organizers had “decided to exclude a
message [they] did not like from the communication [they]
chose to make,” and that was their decision alone. Id., at
574.
   On two other occasions, the Court distinguished Tornillo
and its progeny for the flip-side reason—because in those
cases the compelled access did not affect the complaining
party’s own expression. First, in PruneYard Shopping Cen-
ter v. Robins, 447 U. S. 74 (1980), the Court rejected a shop-
ping mall’s First Amendment challenge to a California law
requiring it to allow members of the public to distribute
handbills on its property. The mall owner did not claim
that he (or the mall) was engaged in any expressive activity.
Indeed, as the PG&E Court later noted, he “did not even
allege that he objected to the content of the pamphlets”
passed out at the mall. 475 U. S., at 12. Similarly, in
                  Cite as: 603 U. S. ____ (2024)            17

                      Opinion of the Court

Rumsfeld v. Forum for Academic and Institutional Rights,
Inc., 547 U. S. 47 (2006) (FAIR), the Court reiterated that a
First Amendment claim will not succeed when the entity
objecting to hosting third-party speech is not itself engaged
in expression. The statute at issue required law schools to
allow the military to participate in on-campus recruiting.
The Court held that the schools had no First Amendment
right to exclude the military based on its hiring policies, be-
cause the schools “are not speaking when they host inter-
views.” Id., at 64. Or stated again, with reference to the
just-described precedents: Because a “law school’s recruit-
ing services lack the expressive quality of a parade, a news-
letter, or the editorial page of a newspaper,” the required
“accommodation of a military recruiter[ ]” did not “interfere
with any message of the school.” Ibid.
   That is a slew of individual cases, so consider three gen-
eral points to wrap up. Not coincidentally, they will figure
in the upcoming discussion of the First Amendment prob-
lems the statutes at issue here likely present as to Face-
book’s News Feed and similar products.
   First, the First Amendment offers protection when an en-
tity engaging in expressive activity, including compiling
and curating others’ speech, is directed to accommodate
messages it would prefer to exclude. “[T]he editorial func-
tion itself is an aspect of speech.” Denver Area Ed. Telecom-
munications Consortium, Inc. v. FCC, 518 U. S. 727, 737
(1996) (plurality opinion). Or said just a bit differently: An
entity “exercis[ing] editorial discretion in the selection and
presentation” of content is “engage[d] in speech activity.”
Arkansas Ed. Television Comm’n v. Forbes, 523 U. S. 666,
674 (1998). And that is as true when the content comes
from third parties as when it does not. (Again, think of a
newspaper opinion page or, if you prefer, a parade.) Decid-
ing on the third-party speech that will be included in or ex-
cluded from a compilation—and then organizing and pre-
senting the included items—is expressive activity of its
18                  MOODY v. NETCHOICE, LLC

                         Opinion of the Court

own. And that activity results in a distinctive expressive
product. When the government interferes with such edito-
rial choices—say, by ordering the excluded to be included—
it alters the content of the compilation. (It creates a differ-
ent opinion page or parade, bearing a different message.)
And in so doing—in overriding a private party’s expressive
choices—the government confronts the First Amendment.4
   Second, none of that changes just because a compiler in-
cludes most items and excludes just a few. That was the
situation in Hurley. The St. Patrick’s Day parade at issue
there was “eclectic”: It included a “wide variety of patriotic,
commercial, political, moral, artistic, religious, athletic,
public service, trade union, and eleemosynary themes, as
well as conflicting messages.” 515 U. S., at 562. Or other-
wise said, the organizers were “rather lenient in admitting
participants.” Id., at 569. No matter. A “narrow, succinctly
articulable message is not a condition of constitutional pro-
tection.” Ibid. It “is enough” for a compiler to exclude the
handful of messages it most “disfavor[s].” Id., at 574. Sup-
pose, for example, that the newspaper in Tornillo had
granted a right of reply to all but one candidate. It would
have made no difference; the Florida statute still could not
have altered the paper’s policy. Indeed, that kind of focused
editorial choice packs a peculiarly powerful expressive
punch.
   Third, the government cannot get its way just by assert-
ing an interest in improving, or better balancing, the mar-
ketplace of ideas. Of course, it is critically important to
have a well-functioning sphere of expression, in which citi-
zens have access to information from many sources. That
——————
  4 Of course, an entity engaged in expressive activity when performing

one function may not be when carrying out another. That is one lesson
of FAIR. The Court ruled as it did because the law schools’ recruiting
services were not engaged in expression. See 547 U. S. 47, 64 (2006).
The case could not have been resolved on that ground if the regulation
had affected what happened in law school classes instead.
                  Cite as: 603 U. S. ____ (2024)           19

                      Opinion of the Court

is the whole project of the First Amendment. And the gov-
ernment can take varied measures, like enforcing competi-
tion laws, to protect that access. Cf., e.g., Turner I, 512
U. S., at 647 (protecting local broadcasting); Hurley, 515
U. S., at 577 (discussing Turner I ). But in case after case,
the Court has barred the government from forcing a private
speaker to present views it wished to spurn in order to re-
jigger the expressive realm. The regulations in Tornillo,
PG&E, and Hurley all were thought to promote greater di-
versity of expression. See supra, at 14–16. They also were
thought to counteract advantages some private parties pos-
sessed in controlling “enviable vehicle[s]” for speech. Hur-
ley, 515 U. S., at 577. Indeed, the Tornillo Court devoted
six pages of its opinion to recounting a critique of the then-
current media environment—in particular, the dispropor-
tionate “influen[ce]” of a few speakers—similar to one heard
today (except about different entities). 418 U. S., at 249;
see id., at 248–254; supra, at 14–15. It made no difference.
However imperfect the private marketplace of ideas, here
was a worse proposal—the government itself deciding when
speech was imbalanced, and then coercing speakers to pro-
vide more of some views or less of others.
                              B
  “[W]hatever the challenges of applying the Constitution
to ever-advancing technology, the basic principles” of the
First Amendment “do not vary.” Brown v. Entertainment
Merchants Assn., 564 U. S. 786, 790 (2011). New commu-
nications media differ from old ones in a host of ways: No
one thinks Facebook’s News Feed much resembles an insert
put in a billing envelope. And similarly, today’s social me-
dia pose dangers not seen earlier: No one ever feared the
effects of newspaper opinion pages on adolescents’ mental
health. But analogies to old media, even if imperfect, can
be useful. And better still as guides to decision are settled
principles about freedom of expression, including the ones
20               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

just described. Those principles have served the Nation
well over many years, even as one communications method
has given way to another. And they have much to say about
the laws at issue here. These cases, to be sure, are at an
early stage; the record is incomplete even as to the major
social-media platforms’ main feeds, much less the other ap-
plications that must now be considered. See supra, at 12.
But in reviewing the District Court’s preliminary injunc-
tion, the Fifth Circuit got its likelihood-of-success finding
wrong. Texas is not likely to succeed in enforcing its law
against the platforms’ application of their content-moderation
policies to the feeds that were the focus of the proceedings
below. And that is because of the core teaching elaborated
in the above-summarized decisions: The government may
not, in supposed pursuit of better expressive balance, alter
a private speaker’s own editorial choices about the mix of
speech it wants to convey.
   Most readers are likely familiar with Facebook’s News
Feed or YouTube’s homepage; assuming so, feel free to skip
this paragraph (and maybe a couple more). For the unini-
tiated, though, each of those feeds presents a user with a
continually updating stream of other users’ posts. For Fa-
cebook’s News Feed, any user may upload a message,
whether verbal or visual, with content running the gamut
from “vacation pictures from friends” to “articles from local
or national news outlets.” App. in No. 22–555, at 139a. And
whenever a user signs on, Facebook delivers a personalized
collection of those stories. Similarly for YouTube. Its users
upload all manner of videos. And any person opening the
website or mobile app receives an individualized list of
video recommendations.
   The key to the scheme is prioritization of content,
achieved through the use of algorithms. Of the billions of
posts or videos (plus advertisements) that could wind up on
a user’s customized feed or recommendations list, only the
tiniest fraction do. The selection and ranking is most often
                  Cite as: 603 U. S. ____ (2024)           21

                      Opinion of the Court

based on a user’s expressed interests and past activities.
But it may also be based on more general features of the
communication or its creator. Facebook’s Community
Standards and YouTube’s Community Guidelines detail the
messages and videos that the platforms disfavor. The plat-
forms write algorithms to implement those standards—for
example, to prefer content deemed particularly trustworthy
or to suppress content viewed as deceptive (like videos pro-
moting “conspiracy theor[ies]”). Id., at 113a.
   Beyond rankings lie labels. The platforms may attach
“warning[s], disclaimers, or general commentary”—for ex-
ample, informing users that certain content has “not been
verified by official sources.” Id., at 75a. Likewise, they may
use “information panels” to give users “context on content
relating to topics and news prone to misinformation, as well
as context about who submitted the content.” Id., at 114a.
So, for example, YouTube identifies content submitted by
state-supported media channels, including those funded by
the Russian Government. See id., at 76a.
   But sometimes, the platforms decide, providing more in-
formation is not enough; instead, removing a post is the
right course. The platforms’ content-moderation policies
also say when that is so. Facebook’s Standards, for exam-
ple, proscribe posts—with exceptions for “news-
worth[iness]” and other “public interest value”—in catego-
ries and subcategories including: Violence and Criminal
Behavior (e.g., violence and incitement, coordinating harm
and publicizing crime, fraud and deception); Safety (e.g., su-
icide and self-injury, sexual exploitation, bullying and har-
assment); Objectionable Content (e.g., hate speech, violent
and graphic content); Integrity and Authenticity (e.g., false
news, manipulated media). Id., at 412a–415a, 441a–442a.
YouTube’s Guidelines similarly target videos falling within
categories like: hate speech, violent or graphic content,
child safety, and misinformation (including about elections
and vaccines). See id., at 430a–432a. The platforms thus
22                   MOODY v. NETCHOICE, LLC

                           Opinion of the Court

unabashedly control the content that will appear to users,
exercising authority to remove, label or demote messages
they disfavor.5
  Except that Texas’s law limits their power to do so. As
noted earlier, the law’s central provision prohibits the large
social-media platforms (and maybe other entities 6) from
“censor[ing]” a “user’s expression” based on its “viewpoint.”
§143A.002(a)(2); see supra, at 7. The law defines “expres-
sion” broadly, thus including pretty much anything that
might be posted. See §143A.001(2). And it defines “censor”
to mean “block, ban, remove, deplatform, demonetize, de-
boost, restrict, deny equal access or visibility to, or other-
wise discriminate against expression.” §143A.001(1).7
That is a long list of verbs, but it comes down to this: The
platforms cannot do any of the things they typically do (on
their main feeds) to posts they disapprove—cannot demote,
label, or remove them—whenever the action is based on the
——————
   5 We therefore do not deal here with feeds whose algorithms respond

solely to how users act online—giving them the content they appear to
want, without any regard to independent content standards. See post,
at 2 (BARRETT, J., concurring). Like them or loathe them, the Community
Standards and Community Guidelines make a wealth of user-agnostic
judgments about what kinds of speech, including what viewpoints, are
not worthy of promotion. And those judgments show up in Facebook’s
and YouTube’s main feeds.
   6 The scope of the Texas law, a matter crucial to the facial inquiry, is

unsettled, as previously discussed. See supra, at 10–11. The Texas so-
licitor general at oral argument stated that he understood the law to
cover Facebook and YouTube, but “d[id]n’t know” whether it also covered
other platforms and applications. Tr. of Oral Arg. in No. 22–555, pp. 61–
62.
   7 In addition to barring “censor[ship]” of “expression,” the law bars

“censor[ship]” of people. More specifically, it prohibits taking the desig-
nated “censor[ial]” actions against any “user” based on his “viewpoint,”
regardless of whether that “viewpoint is expressed on a social media plat-
form.” §§143A.002(a)(1), (b); see supra, at 7. Because the Fifth Circuit
did not focus on that provision, instead confining its analysis to the law’s
ban on “censor[ing]” a “user’s expression” on the platform, we do the
same.
                      Cite as: 603 U. S. ____ (2024)                    23

                          Opinion of the Court

post’s viewpoint.8 And what does that “based on viewpoint”
requirement entail? Doubtless some of the platforms’ content-
moderation practices are based on characteristics of speech
other than viewpoint (e.g., on subject matter). But if
Texas’s law is enforced, the platforms could not—as they in
fact do now—disfavor posts because they:
   support Nazi ideology;
   advocate for terrorism;
   espouse racism, Islamophobia, or anti-Semitism;
   glorify rape or other gender-based violence;
   encourage teenage suicide and self-injury;
   discourage the use of vaccines;
   advise phony treatments for diseases;
   advance false claims of election fraud.

The list could continue for a while.9 The point of it is not
that the speech environment created by Texas’s law is
worse than the ones to which the major platforms aspire on
their main feeds. The point is just that Texas’s law pro-
foundly alters the platforms’ choices about the views they
will, and will not, convey.
  And we have time and again held that type of regulation
to interfere with protected speech. Like the editors, cable
——————
   8 The Texas solicitor general explained at oral argument that the Texas

law allows the platforms to remove “categories” of speech, so long as they
are not based on viewpoint. See Tr. of Oral Arg. in No. 22–555, at 69–
70; §120.052 (Acceptable Use Policy). The example he gave was speech
about Al-Qaeda. Under the law, a platform could remove all posts about
Al-Qaeda, regardless of viewpoint. But it could not stop the “pro-
Al-Qaeda” speech alone; it would have to stop the “anti-Al-Qaeda” speech
too. Tr. of Oral Arg. in No. 22–555, at 70. So again, the law, as described
by the solicitor general, prevents the platforms from disfavoring posts
because they express one view of a subject.
   9 Details on both the enumerated examples and similar ones are found

in Facebook’s Community Standards and YouTube’s Community Guide-
lines. See https://transparency.meta.com/policies/community-standards;
https://support.google.com/youtube/answer/9288567.
24               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

operators, and parade organizers this Court has previously
considered, the major social-media platforms are in the
business, when curating their feeds, of combining “multi-
farious voices” to create a distinctive expressive offering.
Hurley, 515 U. S., at 569. The individual messages may
originate with third parties, but the larger offering is the
platform’s. It is the product of a wealth of choices about
whether—and, if so, how—to convey posts having a certain
content or viewpoint. Those choices rest on a set of beliefs
about which messages are appropriate and which are not
(or which are more appropriate and which less so). And in
the aggregate they give the feed a particular expressive
quality. Consider again an opinion page editor, as in
Tornillo, who wants to publish a variety of views, but thinks
some things off-limits (or, to change the facts, worth only a
couple of column inches). “The choice of material,” the “de-
cisions made [as to] content,” the “treatment of public is-
sues”—“whether fair or unfair”—all these “constitute the
exercise of editorial control and judgment.” Tornillo, 418
U. S., at 258. For a paper, and for a platform too. And the
Texas law (like Florida’s earlier right-of-reply statute) tar-
gets those expressive choices—in particular, by forcing the
major platforms to present and promote content on their
feeds that they regard as objectionable.
   That those platforms happily convey the lion’s share of
posts submitted to them makes no significant First Amend-
ment difference. Contra, 49 F. 4th, at 459–461 (arguing
otherwise). To begin with, Facebook and YouTube exclude
(not to mention, label or demote) lots of content from their
News Feed and homepage. The Community Standards and
Community Guidelines set out in copious detail the varied
kinds of speech the platforms want no truck with. And both
platforms appear to put those manuals to work. In a single
quarter of 2021, Facebook removed from its News Feed
more than 25 million pieces of “hate speech content” and
                 Cite as: 603 U. S. ____ (2024)           25

                     Opinion of the Court

almost 9 million pieces of “bullying and harassment con-
tent.” App. in No. 22–555, at 80a. Similarly, YouTube de-
leted in one quarter more than 6 million videos violating its
Guidelines. See id., at 116a. And among those are the re-
movals the Texas law targets. What is more, this Court has
already rightly declined to focus on the ratio of rejected to
accepted content. Recall that in Hurley, the parade organ-
izers welcomed pretty much everyone, excluding only those
who expressed a message of gay pride. See supra, at 18.
The Court held that the organizers’ “lenient” admissions
policy—and their resulting failure to express a “particular-
ized message”—did “not forfeit” their right to reject the few
messages they found harmful or offensive. 515 U. S., at
569, 574. So too here, though the excluded viewpoints dif-
fer. That Facebook and YouTube convey a mass of mes-
sages does not license Texas to prohibit them from deleting
posts with, say, “hate speech” based on “sexual orientation.”
App. in No. 22–555, at 126a, 155a; see id., at 431a. It is as
much an editorial choice to convey all speech except in se-
lect categories as to convey only speech within them.
  Similarly, the major social-media platforms do not lose
their First Amendment protection just because no one will
wrongly attribute to them the views in an individual post.
Contra, 49 F. 4th, at 462 (arguing otherwise). For starters,
users may well attribute to the platforms the messages that
the posts convey in toto. Those messages—communicated
by the feeds as a whole—derive largely from the platforms’
editorial decisions about which posts to remove, label, or
demote. And because that is so, the platforms may indeed
“own” the overall speech environment. In any event, this
Court has never hinged a compiler’s First Amendment pro-
tection on the risk of misattribution. The Court did not
think in Turner—and could not have thought in Tornillo or
PG&E—that anyone would view the entity conveying the
third-party speech at issue as endorsing its content. See
Turner I, 512 U. S., at 655 (“[T]here appears little risk” of
26               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

such misattribution). Yet all those entities, the Court held,
were entitled to First Amendment protection for refusing to
carry the speech. See supra, at 14–16. To be sure, the
Court noted in PruneYard and FAIR, when denying such
protection, that there was little prospect of misattribution.
See 447 U. S., at 87; 547 U. S., at 65. But the key fact in
those cases, as noted above, was that the host of the third-
party speech was not itself engaged in expression. See su-
pra, at 16–17. The current record suggests the opposite as
to Facebook’s News Feed and YouTube’s homepage. When
the platforms use their Standards and Guidelines to decide
which third-party content those feeds will display, or how
the display will be ordered and organized, they are making
expressive choices. And because that is true, they receive
First Amendment protection.
                               C
   And once that much is decided, the interest Texas relies
on cannot sustain its law. In the usual First Amendment
case, we must decide whether to apply strict or intermedi-
ate scrutiny. But here we need not. Even assuming that
the less stringent form of First Amendment review applies,
Texas’s law does not pass. Under that standard, a law must
further a “substantial governmental interest” that is “unre-
lated to the suppression of free expression.” United States
v. O’Brien, 391 U. S. 367, 377 (1968). Many possible inter-
ests relating to social media can meet that test; nothing said
here puts regulation of NetChoice’s members off-limits as
to a whole array of subjects. But the interest Texas has
asserted cannot carry the day: It is very much related to the
suppression of free expression, and it is not valid, let alone
substantial.
   Texas has never been shy, and always been consistent,
about its interest: The objective is to correct the mix of
speech that the major social-media platforms present. In
this Court, Texas described its law as “respond[ing]” to the
                  Cite as: 603 U. S. ____ (2024)           27

                      Opinion of the Court

platforms’ practice of “favoring certain viewpoints.” Brief
for Texas 7; see id., at 27 (explaining that the platforms’
“discrimination” among messages “led to [the law’s] enact-
ment”). The large social-media platforms throw out (or en-
cumber) certain messages; Texas wants them kept in (and
free from encumbrances), because it thinks that would cre-
ate a better speech balance. The current amalgam, the
State explained in earlier briefing, was “skewed” to one
side. 573 F. Supp. 3d, at 1116. And that assessment mir-
rored the stated views of those who enacted the law, save
that the latter had a bit more color. The law’s main sponsor
explained that the “West Coast oligarchs” who ran social-
media companies were “silenc[ing] conservative viewpoints
and ideas.” Ibid. The Governor, in signing the legislation,
echoed the point: The companies were fomenting a “danger-
ous movement” to “silence” conservatives. Id., at 1108;
see id., at 1099 (“[S]ilencing conservative views is un-
American, it’s un-Texan and it’s about to be illegal in
Texas”).
  But a State may not interfere with private actors’ speech
to advance its own vision of ideological balance. States (and
their citizens) are of course right to want an expressive
realm in which the public has access to a wide range of
views. That is, indeed, a fundamental aim of the First
Amendment. But the way the First Amendment achieves
that goal is by preventing the government from “tilt[ing]
public debate in a preferred direction.” Sorrell v. IMS
Health Inc., 564 U. S. 552, 578–579 (2011). It is not by li-
censing the government to stop private actors from speak-
ing as they wish and preferring some views over others.
And that is so even when those actors possess “enviable ve-
hicle[s]” for expression. Hurley, 515 U. S., at 577. In a bet-
ter world, there would be fewer inequities in speech oppor-
tunities; and the government can take many steps to bring
that world closer. But it cannot prohibit speech to improve
or better balance the speech market. On the spectrum of
28                 MOODY v. NETCHOICE, LLC

                        Opinion of the Court

dangers to free expression, there are few greater than al-
lowing the government to change the speech of private ac-
tors in order to achieve its own conception of speech nir-
vana. That is why we have said in so many contexts that
the government may not “restrict the speech of some ele-
ments of our society in order to enhance the relative voice
of others.” Buckley v. Valeo, 424 U. S. 1, 48–49 (1976) (per
curiam). That unadorned interest is not “unrelated to the
suppression of free expression,” and the government may
not pursue it consistent with the First Amendment.
   The Court’s decisions about editorial control, as discussed
earlier, make that point repeatedly. See supra, at 18–19.
Again, the question those cases had in common was
whether the government could force a private speaker, in-
cluding a compiler and curator of third-party speech, to con-
vey views it disapproved. And in most of those cases, the
government defended its regulation as yielding greater bal-
ance in the marketplace of ideas. But the Court—in
Tornillo, in PG&E, and again in Hurley—held that such an
interest could not support the government’s effort to alter
the speaker’s own expression. “Our cases establish,” the
PG&E Court wrote, “that the State cannot advance some
points of view by burdening the expression of others.” 475
U. S., at 20. So the newspaper, the public utility, the pa-
rade organizer—whether acting “fair[ly] or unfair[ly]”—
could exclude the unwanted message, free from government
interference. Tornillo, 418 U. S., at 258; see United States
Telecom Assn. v. FCC, 855 F. 3d 381, 432 (CADC 2017) (Ka-
vanaugh, J., dissenting from denial of rehearing en banc)
(“[E]xcept in rare circumstances, the First Amendment
does not allow the Government to regulate the content
choices of private editors just so that the Government may
enhance certain voices and alter the content available to the
citizenry”).10
——————
 10 Texas claims Turner as a counter-example, but that decision offers
                      Cite as: 603 U. S. ____ (2024)                    29

                          Opinion of the Court

   The case here is no different. The interest Texas asserts
is in changing the balance of speech on the major platforms’
feeds, so that messages now excluded will be included. To
describe that interest, the State borrows language from this
Court’s First Amendment cases, maintaining that it is pre-
venting “viewpoint discrimination.” Brief for Texas 19; see
supra, at 26–27. But the Court uses that language to say
what governments cannot do: They cannot prohibit private
actors from expressing certain views. When Texas uses
that language, it is to say what private actors cannot do:
They cannot decide for themselves what views to convey.
The innocent-sounding phrase does not redeem the prohib-
ited goal. The reason Texas is regulating the content-
moderation policies that the major platforms use for their
feeds is to change the speech that will be displayed there.
Texas does not like the way those platforms are selecting
and moderating content, and wants them to create a differ-
ent expressive product, communicating different values
and priorities. But under the First Amendment, that is a
preference Texas may not impose.


——————
no help to speak of. Turner did indeed hold that the FCC’s must-carry
provisions, requiring cable operators to give some of their channel space
to local broadcast stations, passed First Amendment muster. See supra,
at 15. But the interest there advanced was not to balance expressive
content; rather, the interest was to save the local-broadcast industry, so
that it could continue to serve households without cable. That interest,
the Court explained, was “unrelated to the content of expression” dissem-
inated by either cable or broadcast speakers. Turner I, 512 U. S. 622,
647 (1994). And later, the Hurley Court again noted the difference. It
understood the Government interest in Turner as one relating to compe-
tition policy: The FCC needed to limit the cable operators’ “monopolistic,”
gatekeeping position “in order to allow for the survival of broadcasters.”
515 U. S., at 577. Unlike in regulating the parade—or here in regulating
Facebook’s News Feed or YouTube’s homepage—the Government’s inter-
est was “not the alteration of speech.” Ibid. And when that is so, the
prospects of permissible regulation are entirely different.
30               MOODY v. NETCHOICE, LLC

                      Opinion of the Court

                              IV
   These are facial challenges, and that matters. To succeed
on its First Amendment claim, NetChoice must show that
the law at issue (whether from Texas or from Florida) “pro-
hibits a substantial amount of protected speech relative to
its plainly legitimate sweep.” Hansen, 599 U. S., at 770.
None of the parties below focused on that issue; nor did the
Fifth or Eleventh Circuits. But that choice, unanimous as
it has been, cannot now control. Even in the First Amend-
ment context, facial challenges are disfavored, and neither
parties nor courts can disregard the requisite inquiry into
how a law works in all of its applications. So on remand,
each court must evaluate the full scope of the law’s cover-
age. It must then decide which of the law’s applications are
constitutionally permissible and which are not, and finally
weigh the one against the other. The need for NetChoice to
carry its burden on those issues is the price of its decision
to challenge the laws as a whole.
   But there has been enough litigation already to know
that the Fifth Circuit, if it stayed the course, would get
wrong at least one significant input into the facial analysis.
The parties treated Facebook’s News Feed and YouTube’s
homepage as the heartland applications of the Texas law.
At least on the current record, the editorial judgments in-
fluencing the content of those feeds are, contrary to the
Fifth Circuit’s view, protected expressive activity. And
Texas may not interfere with those judgments simply be-
cause it would prefer a different mix of messages. How that
matters for the requisite facial analysis is for the Fifth Cir-
cuit to decide. But it should conduct that analysis in keep-
ing with two First Amendment precepts. First, presenting
a curated and “edited compilation of [third party] speech” is
itself protected speech. Hurley, 515 U. S., at 570. And sec-
ond, a State “cannot advance some points of view by bur-
dening the expression of others.” PG&E, 475 U. S., at 20.
To give government that power is to enable it to control the
                 Cite as: 603 U. S. ____ (2024)                 31

                     Opinion of the Court

expression of ideas, promoting those it favors and suppress-
ing those it does not. And that is what the First Amend-
ment protects all of us from.
  We accordingly vacate the judgments of the Courts of Ap-
peals for the Fifth and Eleventh Circuits and remand the
cases for further proceedings consistent with this opinion.

                                                  It is so ordered.
                 Cite as: 603 U. S. ____ (2024)            1

                    BARRETT, J., concurring

SUPREME COURT OF THE UNITED STATES
                         _________________

                    Nos. 22–277 and 22–555
                         _________________


     ASHLEY MOODY, ATTORNEY GENERAL OF
         FLORIDA, ET AL., PETITIONERS
22–277                v.
     NETCHOICE, LLC, DBA NETCHOICE, ET AL.
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
          APPEALS FOR THE ELEVENTH CIRCUIT



     NETCHOICE, LLC, DBA NETCHOICE, ET AL.,
                 PETITIONERS
22–555                v.
   KEN PAXTON, ATTORNEY GENERAL OF TEXAS
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
            APPEALS FOR THE FIFTH CIRCUIT
                         [July 1, 2024]

  JUSTICE BARRETT, concurring.
  I join the Court’s opinion, which correctly articulates and
applies our First Amendment precedent. In this respect,
the Eleventh Circuit’s understanding of the First Amend-
ment’s protection of editorial discretion was generally cor-
rect; the Fifth Circuit’s was not.
  But for the reasons the Court gives, these cases illustrate
the dangers of bringing a facial challenge. If NetChoice’s
members are concerned about preserving their editorial dis-
cretion with respect to the services on which they have fo-
cused throughout this litigation—e.g., Facebook’s Newsfeed
and YouTube’s homepage—they would be better served by
bringing a First Amendment challenge as applied to those
functions. Analyzing how the First Amendment bears on
2                MOODY v. NETCHOICE, LLC

                    BARRETT, J., concurring

those functions is complicated enough without simultane-
ously analyzing how it bears on a platform’s other func-
tions—e.g., Facebook Messenger and Google Search—much
less to distinct platforms like Uber and Etsy. In fact, deal-
ing with a broad swath of varied platforms and functions in
a facial challenge strikes me as a daunting, if not impossi-
ble, task. A function qualifies for First Amendment protec-
tion only if it is inherently expressive. Hurley v. Irish-
American Gay, Lesbian and Bisexual Group of Boston, Inc.,
515 U. S. 557, 568 (1995). Even for a prototypical social-
media feed, making this determination involves more than
meets the eye.
   Consider, for instance, how platforms use algorithms to
prioritize and remove content on their feeds. Assume that
human beings decide to remove posts promoting a particu-
lar political candidate or advocating some position on a
public-health issue. If they create an algorithm to help
them identify and delete that content, the First Amend-
ment protects their exercise of editorial judgment—even if
the algorithm does most of the deleting without a person in
the loop. In that event, the algorithm would simply imple-
ment human beings’ inherently expressive choice “to ex-
clude a message [they] did not like from” their speech com-
pilation. Id., at 574.
   But what if a platform’s algorithm just presents automat-
ically to each user whatever the algorithm thinks the user
will like—e.g., content similar to posts with which the user
previously engaged? See ante, at 22, n. 5. The First
Amendment implications of the Florida and Texas laws
might be different for that kind of algorithm. And what
about AI, which is rapidly evolving? What if a platform’s
owners hand the reins to an AI tool and ask it simply to
remove “hateful” content? If the AI relies on large language
models to determine what is “hateful” and should be re-
moved, has a human being with First Amendment rights
made an inherently expressive “choice . . . not to propound
                 Cite as: 603 U. S. ____ (2024)            3

                    BARRETT, J., concurring

a particular point of view”? Hurley, 515 U. S., at 575. In
other words, technology may attenuate the connection be-
tween content-moderation actions (e.g., removing posts)
and human beings’ constitutionally protected right to “de-
cide for [themselves] the ideas and beliefs deserving of ex-
pression, consideration, and adherence.” Turner Broad-
casting System, Inc. v. FCC, 512 U. S. 622, 641 (1994)
(emphasis added). So the way platforms use this sort of
technology might have constitutional significance.
   There can be other complexities too. For example, the
corporate structure and ownership of some platforms may
be relevant to the constitutional analysis. A speaker’s right
to “decide ‘what not to say’ ” is “enjoyed by business corpo-
rations generally.” Hurley, 515 U. S., at 573–574 (quoting
Pacific Gas & Elec. Co. v. Public Util. Comm’n of Cal., 475
U. S. 1, 16 (1986)). Corporations, which are composed of
human beings with First Amendment rights, possess First
Amendment rights themselves. See Citizens United v. Fed-
eral Election Comm’n, 558 U. S. 310, 365 (2010); cf. Burwell
v. Hobby Lobby Stores, Inc., 573 U. S. 682, 706–707 (2014).
But foreign persons and corporations located abroad do not.
Agency for Int’l Development v. Alliance for Open Society
Int’l, Inc., 591 U. S. 430, 433–436 (2020). So a social-media
platform’s foreign ownership and control over its content-
moderation decisions might affect whether laws overriding
those decisions trigger First Amendment scrutiny. What if
the platform’s corporate leadership abroad makes the policy
decisions about the viewpoints and content the platform
will disseminate? Would it matter that the corporation
employs Americans to develop and implement content-
moderation algorithms if they do so at the direction of for-
eign executives? Courts may need to confront such ques-
tions when applying the First Amendment to certain plat-
forms.
   These are just a few examples of questions that might
4                MOODY v. NETCHOICE, LLC

                     BARRETT, J., concurring

arise in litigation that more thoroughly exposes the rele-
vant facts about particular social-media platforms and
functions. The answers in any given case might cast doubt
on—or might vindicate—a social-media company’s invoca-
tion of its First Amendment rights. Regardless, the analy-
sis is bound to be fact intensive, and it will surely vary from
function to function and platform to platform. And in a fa-
cial challenge, answering all of those questions isn’t even
the end of the story: The court must then find a way to
measure the unconstitutional relative to the constitutional
applications to determine whether the law “prohibits a sub-
stantial amount of protected speech relative to its plainly
legitimate sweep.” United States v. Hansen, 599 U. S. 762,
770 (2023) (internal quotation marks omitted).
   A facial challenge to either of these laws likely forces a
court to bite off more than it can chew. An as-applied chal-
lenge, by contrast, would enable courts to home in on
whether and how specific functions—like feeds versus di-
rect messaging—are inherently expressive and answer
platform- and function-specific questions that might bear
on the First Amendment analysis. While the governing
constitutional principles are straightforward, applying
them in one fell swoop to the entire social-media universe
is not.
                 Cite as: 603 U. S. ____ (2024)            1

                    Opinion of JACKSON, J.

SUPREME COURT OF THE UNITED STATES
                         _________________

                   Nos. 22–277 and 22–555
                         _________________


     ASHLEY MOODY, ATTORNEY GENERAL OF
         FLORIDA, ET AL., PETITIONERS
22–277                v.
     NETCHOICE, LLC, DBA NETCHOICE, ET AL.
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
          APPEALS FOR THE ELEVENTH CIRCUIT



     NETCHOICE, LLC, DBA NETCHOICE, ET AL.,
                 PETITIONERS
22–555                v.
   KEN PAXTON, ATTORNEY GENERAL OF TEXAS
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
            APPEALS FOR THE FIFTH CIRCUIT
                         [July 1, 2024]

   JUSTICE JACKSON, concurring in part and concurring in
the judgment.
   These cases present a complex clash between two novel
state laws and the alleged First Amendment rights of sev-
eral of the largest social media platforms. Some things are
already clear. Not every potential action taken by a social
media company will qualify as expression protected under
the First Amendment. But not every hypothesized regula-
tion of such a company’s operations will necessarily be able
to withstand the force of the First Amendment’s protections
either. Beyond those broadest of statements, it is difficult
to say much more at this time. With these records and
lower court decisions, we are not able to adequately evalu-
ate whether the challenged state laws are facially valid.
   That is in no small part because, as all Members of the
2                MOODY v. NETCHOICE, LLC

                     Opinion of JACKSON, J.

Court acknowledge, plaintiffs bringing a facial challenge
must clear a high bar. See ante, at 9–10 (majority opinion);
post, at 13–14 (ALITO, J., concurring in judgment). The
Eleventh Circuit failed to appreciate the nature of this chal-
lenge, and the Fifth Circuit did not adequately evaluate it.
That said, I agree with JUSTICE BARRETT that the Eleventh
Circuit at least fairly stated our First Amendment prece-
dent, whereas the Fifth Circuit did not. See ante, at 1 (con-
curring opinion); see also ante, at 13–19 (majority opinion).
On remand, then, both courts will have to undertake their
legal analyses anew.
   In doing so, the lower courts must address these cases at
the right level of specificity. The question is not whether
an entire category of corporations (like social media compa-
nies) or a particular entity (like Facebook) is generally en-
gaged in expression. Nor is it enough to say that a given
activity (say, content moderation) for a particular service
(the News Feed, for example) seems roughly analogous to a
more familiar example from our precedent. Cf. Red Lion
Broadcasting Co. v. FCC, 395 U. S. 367, 386 (1969) (posit-
ing that “differences in the characteristics of new media jus-
tify differences in the First Amendment standards applied
to them”). Even when evaluating a broad facial challenge,
courts must make sure they carefully parse not only what
entities are regulated, but how the regulated activities ac-
tually function before deciding if the activity in question
constitutes expression and therefore comes within the First
Amendment’s ambit. See Brief for Knight First Amend-
ment Institute at Columbia University as Amicus Curiae
11–12. Thus, further factual development may be neces-
sary before either of today’s challenges can be fully and
fairly addressed.
   In light of the high bar for facial challenges and the state
of these cases as they come to us, I would not go on to treat
either like an as-applied challenge and preview our poten-
tial ruling on the merits. Faced with difficult constitutional
                 Cite as: 603 U. S. ____ (2024)           3

                    Opinion of JACKSON, J.

issues arising in new contexts on undeveloped records, this
Court should strive to avoid deciding more than is neces-
sary. See Ashwander v. TVA, 297 U. S. 288, 346–347 (1936)
(Brandeis, J., concurring). In my view, such restraint is
warranted today.
                 Cite as: 603 U. S. ____ (2024)            1

               THOMAS, J., concurring in judgment

SUPREME COURT OF THE UNITED STATES
                          _________________

                    Nos. 22–277 and 22–555
                          _________________


     ASHLEY MOODY, ATTORNEY GENERAL OF
         FLORIDA, ET AL., PETITIONERS
22–277                v.
     NETCHOICE, LLC, DBA NETCHOICE, ET AL.
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
          APPEALS FOR THE ELEVENTH CIRCUIT



     NETCHOICE, LLC, DBA NETCHOICE, ET AL.,
                 PETITIONERS
22–555                v.
   KEN PAXTON, ATTORNEY GENERAL OF TEXAS
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
            APPEALS FOR THE FIFTH CIRCUIT
                         [July 1, 2024]

  JUSTICE THOMAS, concurring in the judgment.
  I agree with the Court’s decision to vacate and remand
because NetChoice and the Computer and Communications
Industry Association (together, the trade associations) have
not established that Texas’s H. B. 20 and Florida’s S. B.
7072 are facially unconstitutional.
  I cannot agree, however, with the Court’s decision to
opine on certain applications of those statutes. The Court’s
discussion is unnecessary to its holding. See Jama v. Im-
migration and Customs Enforcement, 543 U. S. 335, 351,
n. 12 (2005) (“Dictum settles nothing, even in the court that
utters it”). Moreover, the Court engages in the exact type
of analysis that it chastises the Courts of Appeals for per-
forming. It faults the Courts of Appeals for focusing on only
one subset of applications, rather than determining
2                MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

whether each statute’s “full range of applications” are con-
stitutional. See ante, at 10, 12. But, the Court repeats that
very same error. Out of the sea of “variegated and complex”
functions that platforms perform, ante, at 11, the Court
plucks out two (Facebook’s News Feed and YouTube’s
homepage), and declares that they may be protected by the
First Amendment. See ante, at 26 (opining on what the
“current record suggests”). The Court does so on a record
that it itself describes as “incomplete” and “underdevel-
oped,” ante, at 12, 20, and by sidestepping several pressing
factual and legal questions, see post, at 29–32 (ALITO, J.,
concurring in judgment). As JUSTICE ALITO explains, the
Court’s approach is both unwarranted and mistaken. See
ibid.
   I agree with JUSTICE ALITO’s analysis and join his opin-
ion in full. I write separately to add two observations on
the merits and to highlight a more fundamental jurisdic-
tional problem. The trade associations have brought facial
challenges alleging that H. B. 20 and S. B. 7072 are uncon-
stitutional in many or all of their applications. But, Art-
icle III of the Constitution permits federal courts to exercise
judicial power only over “Cases” and “Controversies.” Ac-
cordingly, federal courts can decide whether a statute is
constitutional only as applied to the parties before them—
they lack authority to deem a statute “facially” unconstitu-
tional.
                              I
  As JUSTICE ALITO explains, the trade associations have
failed to provide many of the basic facts necessary to evalu-
ate their challenges to H. B. 20 and S. B. 7072. See post, at
22–29. I make two additional observations.
  First, with respect to certain provisions of H. B. 20 and
S. B. 7072, the Court assumes that the framework outlined
in Zauderer v. Office of Disciplinary Counsel of Supreme
Court of Ohio, 471 U. S. 626 (1985), applies. See ante, at
                  Cite as: 603 U. S. ____ (2024)            3

               THOMAS, J., concurring in judgment

11. In that case, the Court held that laws requiring the dis-
closure of factual information in commercial advertising
may satisfy the First Amendment if the disclosures are
“reasonably related” to the Government’s interest in pre-
venting consumer deception. 471 U. S., at 651. Because the
trade associations did not contest Zauderer’s applicability
before the Eleventh Circuit and both lower courts applied
its framework, I agree with the Court’s decision to rely upon
Zauderer at this stage. However, I think we should recon-
sider Zauderer and its progeny. “I am skeptical of the prem-
ise on which Zauderer rests—that, in the commercial-
speech context, the First Amendment interests implicated
by disclosure requirements are substantially weaker than
those at stake when speech is actually suppressed.” Mila-
vetz, Gallop & Milavetz, P. A. v. United States, 559 U. S.
229, 255 (2010) (THOMAS, J., concurring in part and concur-
ring in judgment) (internal quotation marks omitted).
   Second, the common-carrier doctrine should continue to
guide the lower courts’ examination of the trade associa-
tions’ claims on remand. See post, at 18, and n. 17, 30 (opin-
ion of ALITO, J.). “[O]ur legal system and its British prede-
cessor have long subjected certain businesses, known as
common carriers, to special regulations, including a general
requirement to serve all comers.” Biden v. Knight First
Amendment Institute at Columbia Univ., 593 U. S. ___, ___
(2021) (THOMAS, J., concurring in grant of certiorari) (slip
op., at 3). Moreover, “there is clear historical precedent for
regulating transportation and communications networks in
a similar manner as traditional common carriers” given
their many similarities. Id., at ___ (slip op., at 5). Though
they reached different conclusions, both the Fifth Circuit
and the Eleventh Circuit appropriately strove to apply the
common-carrier doctrine in assessing the constitutionality
of H. B. 20 and S. B. 7072 respectively. See 49 F. 4th 439,
469–480 (CA5 2022); NetChoice v. Attorney Gen., Fla., 34
F. 4th 1196, 1219–1222 (CA11 2022).
4                MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

   The common-carrier doctrine may have weighty implica-
tions for the trade associations’ claims. But, the same fac-
tual barriers that preclude the Court from assessing the
trade associations’ claims under our First Amendment
precedents also prevent us from applying the common-car-
rier doctrine in this posture. At a minimum, we would need
to pinpoint the regulated parties and specific conduct being
regulated. On remand, however, both lower courts should
continue to consider the common-carrier doctrine.
                              II
   The opinions in these cases detail many of the considera-
ble hurdles that currently preclude resolution of the trade
associations’ claims. See ante, at 9–10; ante, at 1–4
(BARRETT, J., concurring); post, at 22–32 (opinion of ALITO,
J.). The most significant problem of all, however, has yet to
be addressed: Federal courts lack authority to adjudicate
the trade associations’ facial challenges.
   Rather than allege that the statutes impermissibly regu-
late them, the trade associations assert that H. B. 20 and
S. B. 7072 are actually unconstitutional in most or all of
their applications. This type of challenge, called a facial
challenge, is “an attack on a statute itself as opposed to a
particular application.” Los Angeles v. Patel, 576 U. S. 409,
415 (2015).
   Facial challenges are fundamentally at odds with Article
III. Because Article III limits federal courts’ judicial power
to cases or controversies, federal courts “lac[k] the power to
pronounce that [a] statute is unconstitutional” as applied to
nonparties. Americans for Prosperity Foundation v. Bonta,
594 U. S. 595, 621 (2021) (THOMAS, J., concurring in part
and concurring in judgment) (internal quotation marks
omitted). Entertaining facial challenges in spite of that lim-
itation arrogates powers reserved to the political branches
and disturbs the relationship between the Federal Govern-
ment and the States. The practice of adjudicating facial
                  Cite as: 603 U. S. ____ (2024)            5

               THOMAS, J., concurring in judgment

challenges creates practical concerns as well. Facial chal-
lenges’ dubious historical roots further confirm that the
doctrine should have no place in our jurisprudence.
                              A
                              1
    Article III empowers federal courts to exercise “judicial
Power” only over “Cases” and “Controversies.” This Court
has long recognized that those terms impose substantive
constraints on the authority of federal courts. See Muskrat
v. United States, 219 U. S. 346, 356–358 (1911); see also
Steel Co. v. Citizens for Better Environment, 523 U. S. 83,
102 (1998). One corollary of the case-or-controversy re-
quirement is that while federal courts can judge the consti-
tutionality of statutes, they may do so only to the extent
necessary to resolve the case at hand. “It is emphatically
the province and duty of the judicial department to say
what the law is,” but only because “[t]hose who apply the
rule to particular cases, must of necessity expound and in-
terpret that rule.” Marbury v. Madison, 1 Cranch 137, 177
(1803); see Liverpool, New York & Philadelphia S. S. Co. v.
Commissioners of Emigration, 113 U. S. 33, 39 (1885)
(“[The Court] has no jurisdiction to pronounce any statute
. . . irreconcilable with the Constitution, except as it is
called upon to adjudge the legal rights of litigants in actual
controversies”). Accordingly, “[e]xcept when necessary” to
resolve a case or controversy, “courts have no charter to re-
view and revise legislative and executive action.” Summers
v. Earth Island Institute, 555 U. S. 488, 492 (2009); see
United States v. Raines, 362 U. S. 17, 20–21 (1960).
    These limitations on the power of judicial review play an
essential role in preserving our constitutional structure.
Our Constitution sets forth a “tripartite allocation of
power,” separating different types of powers across three co-
equal branches. DaimlerChrysler Corp. v. Cuno, 547 U. S.
332, 341 (2006) (internal quotation marks omitted). “[E]ach
6                MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

branch [is vested] with an exclusive form of power,” and “no
branch can encroach upon the powers confided to the oth-
ers.” Patchak v. Zinke, 583 U. S. 244, 250 (2018) (plurality
opinion) (internal quotation marks omitted). In the Judi-
cial Branch’s case, it is vested with the “ultimate and su-
preme” power of judicial review. Chicago & Grand Trunk
R. Co. v. Wellman, 143 U. S. 339, 345 (1892). That power
includes the authority to refuse to apply a statute enacted
and approved by the other two branches of the Federal Gov-
ernment. But, the power of judicial review can be wielded
only in specific circumstances and to limited ends—to re-
solve cases and controversies. Without that limitation, the
Judiciary would have an unchecked ability to enjoin duly
enacted statutes. Respecting the case-or-controversy re-
quirement is therefore necessary to “preven[t] the Federal
Judiciary from intruding upon the powers given to the other
branches, and confin[e] the federal courts to a properly ju-
dicial role.” Town of Chester v. Laroe Estates, Inc., 581 U. S.
433, 438 (2017) (internal quotation marks and alteration
omitted).
                                2
   Facial challenges conflict with Article III’s case-or-
controversy requirement because they ask a federal court
to decide whether a statute might conflict with the Consti-
tution in cases that are not before the court.
   To bring a facial challenge under our precedents, a plain-
tiff must ordinarily “establish that no set of circumstances
exists under which the Act would be valid.” United States
v. Salerno, 481 U. S. 739, 745 (1987). In the First Amend-
ment context, we have sometimes applied an even looser
standard, called the overbreadth doctrine. The overbreadth
doctrine requires a plaintiff to establish only that a statute
“prohibits a substantial amount of protected speech,” “rela-
tive to [its] plainly legitimate sweep.” United States v. Wil-
liams, 553 U. S. 285, 292 (2008).
                  Cite as: 603 U. S. ____ (2024)             7

               THOMAS, J., concurring in judgment

   Facial challenges ask courts to issue holdings that are
rarely, if ever, required to resolve a single case or contro-
versy. The only way a plaintiff gets into a federal court is
by showing that he “personally has suffered some actual or
threatened injury as a result of the putatively illegal con-
duct of the defendant.” Blum v. Yaretsky, 457 U. S. 991,
999 (1982) (internal quotation marks omitted). And, the
only remedy a plaintiff should leave a federal court with is
one “limited to the inadequacy that produced the injury in
fact that the plaintiff has established.” Lewis v. Casey, 518
U. S. 343, 357 (1996). Accordingly, once a court decides
whether a statute can be validly enforced against the plain-
tiff who challenges it, that case or controversy is resolved.
Either the court remedies the plaintiff ’s injury, or it deter-
mines that the statute may be constitutionally applied to
the plaintiff.
   Proceeding to decide the merits of possible constitutional
challenges that could be brought by other plaintiffs is not
necessary to resolve that case. Instead, any holding with
respect to potential future plaintiffs would be “no more than
an advisory opinion—which a federal court should never is-
sue at all, and especially should not issue with regard to a
constitutional question, as to which we seek to avoid even
nonadvisory opinions.” Chicago v. Morales, 527 U. S. 41, 77
(1999) (Scalia, J., dissenting) (citation omitted).
   Unsurprisingly, facial challenges are at odds with doc-
trines enforcing the case-or-controversy requirement. Pur-
suant to standing doctrine, for example, a plaintiff can
maintain a suit in a federal court—and thus invoke judicial
power—only if he has suffered an “injury” with a “traceable
connection” to the “complained-of conduct of the defendant.”
Steel Co., 523 U. S., at 103. Facial challenges significantly
relax those rules. Start with the injury requirement. Fa-
cial challenges allow a plaintiff to challenge applications of
a statute that have not injured him. But see Acheson Ho-
8                MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

tels, LLC v. Laufer, 601 U. S. 1, 10 (2023) (THOMAS, J., con-
curring in judgment) (“To have standing, a plaintiff must
assert a violation of his [own] rights”). In fact, under our
First Amendment overbreadth doctrine, a plaintiff need not
be injured at all; he can challenge a statute that lawfully
applies to him so long as it would be unlawful to enforce it
against others. See United States v. Hansen, 599 U. S. 762,
769 (2023).
   Facial challenges also distort standing doctrine’s redress-
ability requirement. The Court has held that a plaintiff has
standing to sue only when his “requested relief will redress
the alleged injury.” Steel Co., 523 U. S., at 103. With a fa-
cial challenge, however, a plaintiff seeks to enjoin every ap-
plication of a statute—including ones that have nothing to
do with his injury. A plaintiff can ask, “Do [I] just want [the
court] to say that this statute cannot constitutionally be ap-
plied to [me] in this case, or do [I] want to go for broke and
try to get the statute pronounced void in all its applica-
tions?” Morales, 527 U. S., at 77 (opinion of Scalia, J.). In
this sense, the remedy sought by a facial challenge is akin
to a universal injunction—a practice that is itself “incon-
sistent with longstanding limits on equitable relief and the
power of Article III courts.” Trump v. Hawaii, 585 U. S.
667, 713 (2018) (THOMAS, J., concurring); see Department
of Homeland Security v. New York, 589 U. S. ___, ___–___
(2020) (GORSUCH, J., concurring in grant of stay) (slip op.,
at 2–3); FDA v. Alliance for Hippocratic Medicine, 602 U. S.
367, 402 (2024) (THOMAS, J., concurring).
   Because deciding the constitutionality of a statute as ap-
plied to nonparties is not necessary to resolve a case or con-
troversy, it is beyond a federal court’s constitutional author-
ity. Federal courts have “no power per se to review and
annul acts of Congress on the ground that they are uncon-
stitutional. That question may be considered only when the
justification for some direct injury suffered or threatened,
presenting a justiciable issue, is made to rest upon such an
                      Cite as: 603 U. S. ____ (2024)                        9

                   THOMAS, J., concurring in judgment

act.” Massachusetts v. Mellon, 262 U. S. 447, 488 (1923).
Resolving facial challenges thus violates Article III.1
                               3
  Adjudicating facial challenges also intrudes upon powers
reserved to the Legislative and Executive Branches and the
States. When a federal court decides an issue unnecessary
for resolving a case or controversy, the Judiciary assumes
authority beyond what the Constitution granted. Supra, at
5–6. That necessarily alters the balance of powers: When
one branch exceeds its vested power, it becomes stronger
relative to the other branches. See Free Enterprise Fund v.
Public Company Accounting Oversight Bd., 561 U. S. 477,
500 (2010).
  Moreover, by exceeding their Article III powers, federal
courts risk interfering with the executive and legislative
functions. Facial challenges enable federal courts to review
the constitutionality of a statute in many or all of its appli-
cations—often before the statute has even been enforced.
In practice, this provides federal courts a “general veto
power . . . upon the legislation of Congress.” Muskrat, 219
U. S., at 357. But, the Judicial Branch has no such consti-
tutional role in lawmaking. When courts take on the super-
visory role of judging statutes in the abstract, they thus “as-
sume a position of authority over the governmental acts of
another and co-equal department, an authority which
plainly [they] do not possess.” Mellon, 262 U. S., at 489.
  Comparing the effects of as-applied challenges and facial
——————
   1 This is not to say that federal courts can never adjudicate a constitu-

tional claim if a plaintiff styles it as a facial challenge. Whenever a plain-
tiff alleges a statute is unconstitutional in many or all of its applications,
that argument nearly always includes an allegation that the statute is
unconstitutional as applied to the plaintiff. Federal courts are free to
consider challenged statutes as applied to the plaintiff before them and
limit any relief accordingly. See generally Americans for Prosperity
Foundation v. Bonta, 594 U. S. 595, 618–619 (2021); id., at 621 (THOMAS,
J., concurring in part and concurring in judgment).
10               MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

challenges makes this point clear. With an as-applied chal-
lenge, the Judiciary intrudes only as much as necessary on
the will “ ‘of the elected representatives of the people.’ ”
Washington State Grange v. Washington State Republican
Party, 552 U. S. 442, 451 (2008). Assuming a court adheres
to traditional remedial limits, a successful as-applied chal-
lenge only prevents application of the statute against that
plaintiff. The Executive Branch remains free to enforce the
statute in all of its other applications. And, the court’s de-
cision provides some notice to the political branches, ena-
bling the Executive Branch to tailor future enforcement of
the statute to avoid violating the Constitution or Congress
to amend the statute.
   Facial challenges, however, force the Judiciary to take a
maximalist approach. A single plaintiff can immediately
call upon a federal court to declare an entire statute uncon-
stitutional, even before it has been applied to him. The po-
litical branches have no opportunity to correct course, mak-
ing legislation an all-or-nothing proposition. The end result
is that “the democratic process” is “short circuit[ed]” and
“laws embodying the will of the people [are prevented] from
being implemented in a manner consistent with the Consti-
tution.” Ibid.
   In a similar vein, facial challenges distort the relation-
ship between the Federal Government and the States. The
Constitution “establishes a system of dual sovereignty be-
tween the States and the Federal Government.” Gregory v.
Ashcroft, 501 U. S. 452, 457 (1991). The States retain all
powers “not delegated” to the Federal Government and not
“prohibited by [the Constitution] to the States.” Amdt. 10.
Facial challenges can upset this division by shifting power
from the States to the Federal Judiciary. Most obviously,
when a state law is challenged, a facial challenge prevents
that State from applying its own statute in a constitutional
manner. But, facial challenges can also force federal courts
to appropriate the role of state courts. To analyze whether
                  Cite as: 603 U. S. ____ (2024)             11

                THOMAS, J., concurring in judgment

a statute is valid on its face, a court must determine the
statute’s scope. If a state court has yet to determine the
scope of its statute (a common occurrence with facial chal-
lenges), the federal court must do so in the first instance.
Facial challenges thus increase the likelihood that federal
courts must interpret novel state-law questions—a role typ-
ically and appropriately reserved for state courts.
                                B
   In addition to their constitutional infirmities, facial chal-
lenges also create practical problems. The case-or-controversy
requirement serves as the foundation of our adversarial
system. Rather than “ ‘sit[ting] as self-directed boards of
legal inquiry and research,’ ” federal courts serve as “ ‘arbi-
ters of legal questions presented and argued by the parties
before them.’ ” NASA v. Nelson, 562 U. S. 134, 147, n. 10
(2011) (quoting Carducci v. Regan, 714 F. 2d 171, 177
(CADC 1983) (opinion for the court by Scalia, J.)). This sys-
tem “assure[s] that the legal questions presented to the
court will be resolved . . . in a concrete factual context con-
ducive to a realistic appreciation of the consequences of ju-
dicial action.” Valley Forge Christian College v. Americans
United for Separation of Church and State, Inc., 454 U. S.
464, 472 (1982).
   Facial challenges disrupt the adversarial system and in-
crease the risk of judicial error as a result. A plaintiff rais-
ing a facial challenge need not have any direct knowledge
of how the statute applies to others. In fact, since a facial
challenge may be brought before a statute has been en-
forced against anyone, a plaintiff often can only guess how
the statute operates—even in his own case. For this reason,
“[c]laims of facial invalidity often rest on speculation,”
Washington State Grange, 552 U. S., at 450, and “factually
barebones records,” Sabri v. United States, 541 U. S. 600,
609 (2004). Federal courts are often called to give “prema-
12                   MOODY v. NETCHOICE, LLC

                  THOMAS, J., concurring in judgment

ture interpretations of statutes in areas where their consti-
tutional application might be cloudy.” Raines, 362 U. S., at
22. In short, facial challenges ask courts to resolve poten-
tially thorny constitutional questions with little factual
background and briefing by a party who may not be affected
by the outcome.
                              C
   The problems with facial challenges are particularly evi-
dent in the two cases before us. Even though the trade as-
sociations challenge two state laws, the state actors have
been left out of the picture. State officials had no oppor-
tunity to tailor the laws’ enforcement. Nor could the legis-
latures amend the statutes before they were preliminarily
enjoined. In addition, neither set of state courts had a
chance to interpret their own State’s law or “accord [that]
law a limiting construction to avoid constitutional ques-
tions.” Washington State Grange, 552 U. S., at 450. In-
stead, federal courts construed these novel state laws in the
first instance. And, they did so with little factual record to
assist them. The trade associations’ reliance on our ques-
tionable associational-standing doctrine is partially to
blame.2 But, the fact that the trade associations raise facial
challenges has undeniably played a significant role. With
——————
   2 The trade associations do not allege that they are subject to H. B. 20

and S. B. 7072, but have brought suit to vindicate the rights of their
members. There is thus not a single party in these suits that is actually
regulated by the challenged statutes and can explain how specific provi-
sions will infringe on their First Amendment rights. Instead, the trade
associations assert their understanding of how the challenged statutes
will regulate nonparties.
   As I have recently explained, “[a]ssociational standing raises constitu-
tional concerns.” See FDA v. Alliance for Hippocratic Medicine, 602 U. S.
367, 399 (2024) (concurring opinion). Associational standing appears to
conflict with Article III’s injury and redressability requirements in many
of the same ways as facial challenges. I have serious doubts that either
trade association has standing to vicariously assert a member’s injury.
See id., at 400.
                  Cite as: 603 U. S. ____ (2024)             13

                THOMAS, J., concurring in judgment

even simple fact patterns, a court has little chance of deter-
mining whether a novel, never-before-enforced state law
can be constitutionally enforced against nonparties without
resorting to mere speculation. For cases such as these,
where the constitutional analysis depends on complex, fact-
specific questions, the task becomes impossible.
                                 D
   Facial challenges are particularly suspect given their or-
igins. They appear to be the product of two doctrines that
are themselves constitutionally questionable, vagueness
and overbreadth.
   At the time of the founding, it was well understood that
federal courts could hold a statute unconstitutional only in-
sofar as necessary to resolve a particular case or contro-
versy. See supra, at 5–6. The Founders were certainly fa-
miliar with alternative systems that provided for the free-
floating review of duly enacted statutes. For example, the
New York Constitution of 1777 created a Council of Revi-
sion, composed of the Governor, Chancellor, and New York
Supreme Court. See Hansen, 599 U. S., at 786 (THOMAS, J.,
concurring). The Council of Revision could object to “any
measure of a [prospective] bill” based on “not only [its] con-
stitutionality . . . but also [its] policy.” Id., at 787. If the
Council lodged an objection, the Legislature’s only options
were to “conform to [the Council’s] objections, override them
by a two-thirds vote of both Houses, or simply let the bill
die.” Ibid. (internal quotation marks omitted).
   In our Constitution, the Founders refused to create a
council of revision or involve the Federal Judiciary in the
business of reviewing statutes in the abstract. “Despite the
support of respected delegates . . . the Convention voted
against creating a federal council of revision on four differ-
ent occasions. No other proposal was considered and re-
jected so many times.” Id., at 789 (citation omitted). In-
stead, the Founders created a Judiciary with “only the
14                    MOODY v. NETCHOICE, LLC

                   THOMAS, J., concurring in judgment

authority to resolve private disputes between particular
parties, rather than matters affecting the general public.”
Ibid. (internal quotation marks omitted). They considered
judges “of all men the most unfit to have a veto on laws be-
fore their enactment.” Ibid. (internal quotation marks
omitted). Therefore, they refused to enlist judges in the
business of reviewing statutes other than “as an issue for
decision in a concrete case or controversy.”3 Ibid.
  For more than a century following the founding, the
Court generally adhered to the original understanding of
the narrow scope of judicial review. When the Court first
discussed the concept of judicial review in Marbury v. Mad-
ison, it made clear that such review is limited to what is
necessary for resolving “a particular cas[e]” before a court.
1 Cranch, at 177; see also supra, at 5–6. And, in case after
case that followed Marbury, the Court reiterated that fed-
eral courts have no authority to reach beyond the parties
before them to facially invalidate a statute.4
——————
   3 “The later history of the New York Council of Revision demonstrates

the wisdom of the Framers’ decision.” United States v. Hansen, 599 U. S.
762, 790 (2023) (THOMAS, J., concurring). The Council’s ability to lodge
objections proved significant: “Over the course of its existence, [the Coun-
cil] returned 169 bills to the legislature; the legislature, in turn, overrode
only 51 of those vetoes and reenacted at least 26 bills with modifications.”
Ibid. The Council did not shy away from controversial or weighty mat-
ters either. It vetoed, among other things, “a bill barring those convicted
of adultery from remarrying” and a bill “declar[ing] Loyalists aliens.”
Ibid. In fact, the bill authorizing the Erie Canal’s construction—“one of
the most important measures in the Nation’s history—survived the
Council’s review only because Chancellor James Kent changed his decid-
ing vote at the last minute, seemingly on a whim.” Ibid. Concerns over
the Council’s “intrusive involvement in the legislative process” eventu-
ally led to its abolition in 1820. Ibid.
   4 See, e.g., Austin v. Aldermen, 7 Wall. 694, 699 (1869) (holding that

the Court could “only consider the statute in connection with the case
before” it and thus “our jurisdiction [wa]s at an end” once it “ascertained
that [the case] wrought no effect which the act forbids”); Liverpool, New
York & Philadelphia S. S. Co. v. Commissioners of Emigration, 113 U. S.
33, 39 (1885) (the Court “has no jurisdiction to pronounce any statute . . .
                      Cite as: 603 U. S. ____ (2024)                       15

                   THOMAS, J., concurring in judgment

   As best I can tell, the Court’s first departure from those
principles was the development of the vagueness doctrine.
See Johnson v. United States, 576 U. S. 591, 616–620 (2015)
(THOMAS, J., concurring in judgment) (describing history of
vagueness doctrine). Before and at the time of the found-
ing, American and English courts dealt with vague laws by
“simply refus[ing] to apply them in individual cases.” Id.,
at 615. After the unfortunate rise of “substantive” due pro-
cess, however, American courts began striking down stat-
utes wholesale as “unconstitutionally indefinite.” Id., at
617. This Court first adopted that approach in 1914, see
International Harvester Co. of America v. Kentucky, 234
U. S. 216, and has since repeatedly used the vagueness doc-
trine “to strike down democratically enacted laws” in the
name of substantive due process, Sessions v. Dimaya, 584
U. S. 148, 210 (2018) (THOMAS, J., dissenting); see Johnson,
576 U. S., at 618–621 (opinion of THOMAS, J.). As I have
explained, I doubt that “our practice of striking down stat-


——————
irreconcilable with the Constitution, except as it is called upon to adjudge
the legal rights of litigants in actual controversies”); Chicago & Grand
Trunk R. Co. v. Wellman, 143 U. S. 339, 345 (1892) (explaining that ju-
dicial review of a statute’s constitutionality “is legitimate only in the last
resort, and as a necessity in the determination of real, earnest, and vital
controversy between individuals”); Muskrat v. United States, 219 U. S.
346, 357 (1911) (“[T]here [i]s no general veto power in the court upon the
legislation of Congress”); Yazoo & Mississippi Valley R. Co. v. Jackson
Vinegar Co., 226 U. S. 217, 219 (1912) (rejecting argument that statute
was “void in toto,” because the Court “must deal with the case in hand
and not with imaginary ones”); Dahnke-Walker Milling Co. v. Bondu-
rant, 257 U. S. 282, 289 (1921) (“[A] litigant can be heard to question a
statute’s validity only when and so far as it is being or is about to be
applied to his disadvantage”); Massachusetts v. Mellon, 262 U. S. 447,
488 (1923) (Federal courts “have no power per se to review and annul acts
of Congress on the ground that they are unconstitutional. That question
may be considered only when the justification for some direct injury suf-
fered or threatened, presenting a justiciable issue, is made to rest upon
such an act”).
16                  MOODY v. NETCHOICE, LLC

                  THOMAS, J., concurring in judgment

utes as unconstitutionally vague is consistent with the orig-
inal meaning of the Due Process Clause.” Dimaya, 584
U. S., at 206 (opinion of THOMAS, J.); see Johnson, 576
U. S., at 622 (opinion of THOMAS, J.).
   The vagueness doctrine was the direct ancestor of one
subset of modern facial challenges, the overbreadth doc-
trine. See United States v. Sineneng-Smith, 590 U. S. 371,
385 (2020) (THOMAS, J., concurring) (noting that the over-
breadth doctrine “developed as a result of the vagueness
doctrine’s application in the First Amendment context”). In
Thornhill v. Alabama, 310 U. S. 88 (1940), the Court
deemed an antipicketing statute “invalid on its face” due to
its “sweeping proscription of freedom of discussion.” Id., at
101–106. The Thornhill Court did so “[w]ithout considering
whether the defendant’s actual conduct was entitled to
First Amendment protection,” instead invalidating the law
because it “ ‘swept within its ambit . . . activities that in or-
dinary circumstances constitute an exercise of freedom of
speech or of the press.’ ” Sineneng-Smith, 590 U. S., at 383
(opinion of THOMAS, J.) (quoting Thornhill, 310 U. S., at 97;
alteration omitted).
   Thornhill’s approach quickly gained traction in the First
Amendment context. In the years to follow, the Court “in-
voked [its] rationale to facially invalidate a wide range of
laws” concerning First Amendment rights—a practice that
became known as the overbreadth doctrine. Sineneng-
Smith, 590 U. S., at 383. Under that doctrine, a court can
invalidate a statute if it “prohibits a substantial amount of
protected speech,” “relative to the statute’s plainly legiti-
mate sweep.”5 Williams, 553 U. S., at 292. The Court has
never attempted to ground the overbreadth doctrine “in the
——————
   5 Although the Court’s precedents describe an unconstitutionally over-

broad statute as facially “invalid,” “federal courts have no authority to
erase a duly enacted law from the statute books.” J. Mitchell, The Writ-
of-Erasure Fallacy, 104 Va. L. Rev. 933, 936 (2018); see Sineneng-Smith,
590 U. S., at 387 (opinion of THOMAS, J.).
                     Cite as: 603 U. S. ____ (2024)                    17

                  THOMAS, J., concurring in judgment

text or history of the First Amendment.” Sineneng-Smith,
590 U. S., at 384 (opinion of THOMAS, J.). Instead, the
Court has supplied only “policy considerations and value
judgments.” Ibid.
   The overbreadth and vagueness doctrines’ method of fa-
cial invalidation eventually spread to other areas of law,
setting in motion our modern facial challenge doctrine. For
several decades after Thornhill, the Court continued to re-
sist the broad use of facial challenges. For example, in
Broadrick v. Oklahoma, 413 U. S. 601 (1973), the Court em-
phasized that “[c]onstitutional judgments, as Mr. Chief Jus-
tice Marshall recognized, are justified only out of the neces-
sity of adjudicating rights in particular cases between the
litigants brought before the Court.” Id., at 611. In that
vein, the Court characterized “facial overbreadth adjudica-
tion [as] an exception to our traditional rules of practice.”
Id., at 615. But, the Court eventually entertained facial
challenges more broadly where a plaintiff established that
“no set of circumstances exists under which the Act would
be valid.” 6 Salerno, 481 U. S., at 745. Just as with the over-
breadth doctrine, the Court has yet to explain how facial
challenges are consistent with the Constitution’s text or
history.
   Given how our facial challenge doctrine seems to have de-
veloped—with one doctrinal mistake leading to another—it
is no wonder that facial challenges create a host of consti-
tutional and practical issues. See supra, at 6–13. Rather
than perpetuate our mistakes, the Court should end them.
“No principle is more fundamental to the judiciary’s proper
role in our system of government than the constitutional
——————
   6 Some Members of the Court subsequently sought to apply a more le-

nient standard to all facial challenges. See Washington State Grange v.
Washington State Republican Party, 552 U. S. 442, 449 (2008) (noting
that “some Members of the Court have criticized the Salerno formula-
tion”); United States v. Stevens, 559 U. S. 460, 472 (2010) (reserving the
question of which standard applies to “a typical facial attack”).
18               MOODY v. NETCHOICE, LLC

               THOMAS, J., concurring in judgment

limitation of federal-court jurisdiction to actual cases or
controversies.” Simon v. Eastern Ky. Welfare Rights Organ-
ization, 426 U. S. 26, 37 (1976). Because that requirement
precludes courts from judging and enjoining statutes as ap-
plied to nonparties, the Court should discontinue the prac-
tice of facial challenges.
                         *    *     *
  The Court has recognized the problems that facial chal-
lenges pose, emphasizing that they are “disfavored,” Wash-
ington State Grange, 552 U. S., at 450, and “best when in-
frequent,” Sabri, 541 U. S., at 608. The Court reiterates
those sentiments today. Ante, at 9, 30. But, while sidelin-
ing facial challenges provides some measure of relief, it ig-
nores the real problem. Because federal courts are bound
by Article III’s case-or-controversy requirement, holding a
statute unconstitutional as applied to nonparties is not
simply disfavored—it exceeds the authority granted to fed-
eral courts. It is high time the Court reconsiders its facial
challenge doctrine.
                  Cite as: 603 U. S. ____ (2024)            1

                ALITO, J., concurring in judgment

SUPREME COURT OF THE UNITED STATES
                          _________________

                    Nos. 22–277 and 22–555
                          _________________


     ASHLEY MOODY, ATTORNEY GENERAL OF
         FLORIDA, ET AL., PETITIONERS
22–277                v.
     NETCHOICE, LLC, DBA NETCHOICE, ET AL.
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
          APPEALS FOR THE ELEVENTH CIRCUIT



     NETCHOICE, LLC, DBA NETCHOICE, ET AL.,
                 PETITIONERS
22–555                v.
   KEN PAXTON, ATTORNEY GENERAL OF TEXAS
 ON WRIT OF CERTIORARI TO THE UNITED STATES COURT OF
            APPEALS FOR THE FIFTH CIRCUIT
                          [July 1, 2024]

  JUSTICE ALITO, with whom JUSTICE THOMAS and
JUSTICE GORSUCH join, concurring in the judgment.
  The holding in these cases is narrow: NetChoice failed to
prove that the Florida and Texas laws they challenged are
facially unconstitutional. Everything else in the opinion of
the Court is nonbinding dicta.
  I agree with the bottom line of the majority’s central hold-
ing. But its description of the Florida and Texas laws, as
well as the litigation that shaped the question before us,
leaves much to be desired. Its summary of our legal prece-
dents is incomplete. And its broader ambition of providing
guidance on whether one part of the Texas law is unconsti-
tutional as applied to two features of two of the many plat-
forms that it reaches—namely, Facebook’s News Feed and
YouTube’s homepage—is unnecessary and unjustified.
  But given the incompleteness of this record, there is no
2                  MOODY v. NETCHOICE, LLC

                  ALITO, J., concurring in judgment

need and no good reason to decide anything other than the
facial unconstitutionality question actually before us. After
all, we do not know how the platforms “moderate” their us-
ers’ content, much less whether they do so in an inherently
expressive way under the First Amendment. Nevertheless,
the majority is undeterred. It inexplicably singles out a few
provisions and a couple of platforms for special treatment.
And it unreflectively assumes the truth of NetChoice’s un-
supported assertion that social-media platforms—which
use secret algorithms to review and moderate an almost un-
imaginable quantity of data today—are just as expressive
as the newspaper editors who marked up typescripts in blue
pencil 50 years ago.
   These as-applied issues are important, and we may have
to decide them before too long. But these cases do not pro-
vide the proper occasion to do so. For these reasons, I am
therefore compelled to provide a more complete discussion
of those matters than is customary in an opinion that con-
curs only in the judgment.
                              I
  As the Court has recognized, social-media platforms have
become the “modern public square.” Packingham v. North
Carolina, 582 U. S. 98, 107 (2017). In just a few years, they
have transformed the way in which millions of Americans
communicate with family and friends, perform daily chores,
conduct business, and learn about and comment on current
events. The vast majority of Americans use social media,1
and the average person spends more than two hours a day
on various platforms.2 Young people now turn primarily to
——————
  1 J. Gottfried, Pew Research Center, Americans’ Social Media Use 3

(2024). As platforms incorporate new features and technology, the num-
ber of Americans who use social media is expected to grow. S. Dixon,
Statista, Social Media Users in the United States 2020–2029
(Jan. 30, 2024), https://www.statista.com/statistics/278409/number-of-
social-network-users-in-the-united-states.
  2 V. Filak, Exploring Mass Communication: Connecting With the
                     Cite as: 603 U. S. ____ (2024)                    3

                   ALITO, J., concurring in judgment

social media to get the news,3 and for many of them, life
without social media is unimaginable.4 Social media may
provide many benefits—but not without drawbacks. For
example, some research suggests that social media are hav-
ing a devastating effect on many young people, leading to
depression, isolation, bullying, and intense pressure to en-
dorse the trend or cause of the day.5
  In light of these trends, platforms and governments have
implemented measures to minimize the harms unique to
the social-media context. Social-media companies have cre-
ated user guidelines establishing the kinds of content that
users may post and the consequences of violating those
guidelines, which often include removing nonconforming
posts or restricting noncompliant users’ access to a plat-
form.
  Such enforcement decisions can sometimes have serious
consequences. Restricting access to social media can impair
users’ ability to speak to, learn from, and do business with
others. Deleting the account of an elected official or candi-
date for public office may seriously impair that individual’s
efforts to reach constituents or voters, as well as the ability
of voters to make a fully informed electoral choice. And
what platforms call “content moderation” of the news or
user comments on public affairs can have a substantial ef-
fect on popular views.
——————
World of Media 210 (2024).
   3 Social Media and News Platform Fact Sheet, Pew Research Center

(Nov. 15, 2023), https://www.pewresearch.org/journalism/fact-sheet/
social-media-and-news-fact-sheet.
   4 M. Anderson, M. Faverio, & J. Gottfried, Pew Research Center,

Teens, Social Media and Technology 2023 (Dec. 11, 2023), https://www.
pewresearch.org/internet/2023/12/11/teens-social-media-and-technology
-2023.
   5 Ibid.; see also J. Twenge, J. Haidt, J. Lozano, & K. Cummins, Speci-

fication Curve Analysis Shows That Social Media Use Is Linked to Poor
Mental Health, Especially Among Girls, 224 Acta Psychologica 1, 8–12
(2022).
4                MOODY v. NETCHOICE, LLC

                ALITO, J., concurring in judgment

   Concerned that social-media platforms could abuse their
enormous power, Florida and Texas enacted laws that pro-
hibit them from disfavoring particular viewpoints and
speakers. See S. B. 7072, 2021 Reg. Sess., §1(9) (Fla. 2021)
(finding that “[s]ocial media platforms have unfairly cen-
sored . . . Floridians”); H. B. 20, 87th Leg., Called Sess.
(Tex. 2021) (prohibiting the “censorship of . . . expression on
social media platforms” in Texas). Both statutes have a
broad reach, and it is impossible to determine whether they
are unconstitutional in all their applications without sur-
veying those applications. The majority, however, provides
only a cursory outline of the relevant provisions of these
laws and the litigation challenging their constitutionality.
To remedy this deficiency, I will begin with a more complete
summary.
                               A
                               1
  I start with Florida’s law, S. B. 7072, which regulates any
internet platform that does “business in the state” and has
either “annual gross revenues in excess of $100 million” or
“at least 100 million monthly individual platform partici-
pants globally.” Fla. Stat. §501.2041(1)(g) (2023). This def-
inition is broad. There is no dispute that it covers large
social-networking websites like Facebook, X, YouTube, and
Instagram, but it may also reach e-commerce and other
non-social-networking websites that allow users to leave re-
views, ask and answer questions, or communicate with oth-
ers online. These may include Uber, Etsy, PayPal, Yelp,
Wikipedia, and Gmail. See, e.g., Tr. of Oral Arg. in No. 22–
555, pp. 54–56, 69, 76–79, 155; Brief for Wikimedia Foun-
dation as Amicus Curiae 6; Brief for Yelp Inc. as Amicus
Curiae 4, n. 4.
  To prevent covered platforms from unfairly treating
Floridians, S. B. 7072 imposes the following “content-
moderation” and disclosure requirements:
                     Cite as: 603 U. S. ____ (2024)                     5

                   ALITO, J., concurring in judgment

   Content-moderation provisions. “Content moderation” is
the gentle-sounding term used by internet platforms to de-
note actions they take purportedly to ensure that user-
provided content complies with their terms of service and
“community standards.” The Florida law eschews this ne-
ologism and instead uses the old-fashioned term “censor-
ship.” To prevent platforms from discriminating against
certain views or speakers, that law requires each regulated
platform to enforce its “censorship . . . standards in a con-
sistent manner among its users on the platform.” Fla. Stat.
§501.2041(2)(b). The law defines “censorship” as any action
taken to: “delete, regulate, restrict, edit, alter, [or] inhibit”
users from posting their own content; “post an addendum
to any content or material posted by a user”; or “inhibit the
ability of a user to be viewable by or to interact with another
user.” §501.2041(1)(b).
   To prevent platforms from attempting to evade this re-
striction by regularly modifying their practices, the law pro-
hibits platforms from changing their censorship “rules,
terms, and agreements . . . more than once every 30 days.”
§501.2041(2)(c). And to give Floridians more control over
how they view content on social-media websites, the law re-
quires each platform to give its users the ability to “opt out”
of its content-sorting “algorithms” and instead view posts
sequentially or chronologically. §501.2041(2)(f ).6
   Although some platforms still have employees who mon-
itor and organize social-media feeds, for most platforms,
“the incredible volume of content shared each day makes
human review of each new post impossible.” Brief for De-
velopers Alliance et al. as Amici Curiae 4. Consequently,
platforms rely heavily on algorithms to organize and censor
content. Ibid. And it is likely that they will increasingly
——————
  6 As relevant here, an “algorithm” is a program that platforms use to

automatically “censor” or “moderate” content that violates their terms or
conditions, to organize the results of a search query, or to display posts
in a feed.
6                    MOODY v. NETCHOICE, LLC

                    ALITO, J., concurring in judgment

rely on artificial intelligence (AI), a machine learning tool
that arranges, deletes, and modifies content and learns
from its own choices.
   In addition to barring censorship, the Florida law at-
tempts to prevent platforms from unfairly influencing elec-
tions or distorting public discourse. To do this, it requires
platforms to host candidates for public office and journal-
istic enterprises.7 §§501.2041(2)(h), (j). For the same rea-
sons, the law also prohibits platforms from censoring posts
made by or about candidates for public office.
§501.2041(2)(h).
   Disclosure provisions. S. B. 7072 requires platforms to
make both general and individual disclosures about how
and when they censor the speech of Floridians. The law
requires platforms to publish their content-moderation
standards and to inform users of any changes.
§§501.2041(2)(a), (c). And whenever a platform censors a
user, S. B. 7072 requires it to: (1) notify the user of the cen-
sorship decision in writing within seven days; (2) provide “a
thorough” explanation of the action and how the platform
became aware of the affected content; and (3) allow the user
“to access or retrieve all of the user’s information,
content, material, and data for at least 60 days.”
§§501.2041(2)(d), (i), (3).
   To ensure compliance with these provisions, S. B. 7072
authorizes the Florida attorney general to bring civil and
administrative actions against noncomplying platforms.


——————
   7 A “journalistic enterprise” is defined as any entity doing business in

Florida that: (1) has published more than 100,000 words online and has
at least 50,000 paid subscribers or 100,000 monthly users; (2) has pub-
lished at least 100 hours of audio or video online and has at least 100
million annual viewers; (3) operates a cable channel that produces more
than 40 hours of content per week to at least 100,000 subscribers; or (4)
operates under a Federal Communications Commission broadcast li-
cense. Fla. Stat. §501.2041(1)(d).
                     Cite as: 603 U. S. ____ (2024)                     7

                   ALITO, J., concurring in judgment

§501.2041(5). The law allows the Florida Elections Com-
mission to fine platforms that fail to host candidates for
public office. Fla. Stat. §106.072(3) (2023). And the law
permits aggrieved users to sue and recover up to $100,000
for each violation of the content-moderation and disclosure
provisions, along with actual damages, equitable relief, pu-
nitive damages, and attorney’s fees. §501.2041(6).
  To protect platforms, the law provides that it “may only
be enforced to the extent not inconsistent with federal law,”
including §230 of the Communications Decency Act of 1996.
§501.2041(9). Section 230(c)(2)(A) of that Act shields inter-
net platforms from liability for voluntary, good-faith efforts
to restrict or remove content that is “obscene, lewd, lascivi-
ous, filthy, excessively violent, harassing, or otherwise ob-
jectionable.” 47 U. S. C. §230(c)(2)(A).
                              2
  Days after S. B. 7072’s enactment, NetChoice filed suit in
federal court, alleging that the new law violates the First
Amendment in all its applications.8 As a result, NetChoice
asked the District Court to enter a preliminary injunction
against any enforcement of any of its provisions before the
law took effect.
  Florida defended the constitutionality of S. B. 7072. It
argued that the law’s prohibition of censorship does not vi-
olate the freedom of speech because the First Amendment
permits the regulation of the conduct of entities that do not
express their own views but simply provide the means for
others to communicate. See Record in No. 4:21–CV–00220


——————
  8 NetChoice also argued that S. B. 7072 is preempted by 47 U. S. C.

§230(c) and is unconstitutionally vague. Those arguments are not before
us because the District Court did not rule on the vagueness issue, 546
F. Supp. 3d 1082, 1095 (ND Fla. 2021), and the Eleventh Circuit declined
to reach the preemption issue, NetChoice v. Attorney Gen., Fla., 34 F. 4th
1196, 1209 (2022).
8                    MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

(ND Fla.), Doc. 106, p. 22 (citing Rumsfeld v. Forum for Ac-
ademic and Institutional Rights, Inc., 547 U. S. 47, 64
(2006) (FAIR)). And, in any event, Florida argued that
NetChoice’s facial challenge was likely to fail at the thresh-
old because NetChoice had not identified which of its mem-
bers were required to comply with the new law or how each
of its members’ presentation of third-party speech ex-
pressed that platform’s own message. Record, Doc. 106, at
30, 58–59; id., Doc. 118, pp. 5, 24–25. Without this infor-
mation, Florida said, it could not properly respond to
NetChoice’s facial claim. Id., Doc. 122, pp. 4–5. Florida re-
quested a “meaningful opportunity to take discovery.” Tr.
of Oral Arg. in No. 22–277, p. 154. NetChoice objected.
Record, Doc. 122.
   Despite these arguments, the District Court enjoined
S. B. 7072 in its entirety before the law could go into effect.
Florida appealed, maintaining, among other things, that
NetChoice was “unlikely to prevail on the merits of [its] fa-
cial First Amendment challenge.” Brief for Appellants in
No. 21–12355 (CA11), p. 20; Reply Brief in No. 21–12355
(CA11), p. 15.
   With just one exception, the Eleventh Circuit affirmed.
It first held that all the regulated platforms’ decisions about
“whether, to what extent, and in what manner to dissemi-
nate third-party created content to the public” were consti-
tutionally protected expression. NetChoice v. Attorney
Gen., Fla., 34 F. 4th 1196, 1212 (2022). Under that fram-
ing, the court found that the moderation and individual-
disclosure provisions likely failed intermediate scrutiny,
obviating the need to determine whether strict scrutiny ap-
plied. Id., at 1227.9 But the court held that the general-
——————
  9 See also id., at 1214 (“unless posts and users are removed randomly,

those sorts of actions necessarily convey some sort of message—most ob-
viously, the platforms’ disagreement with . . . certain content”); id., at
1223 (“S.B. 7072’s disclosure provisions implicate the First Amend-
ment”).
                  Cite as: 603 U. S. ____ (2024)            9

                ALITO, J., concurring in judgment

disclosure provisions, which require only that platforms
publish their censorship policies, met the intermediate-
scrutiny standard set forth in Zauderer v. Office of Disci-
plinary Counsel of Supreme Court of Ohio, 471 U. S. 626
(1985). 34 F. 4th, at 1230. The Eleventh Circuit therefore
vacated the portion of the District Court’s order that en-
joined the enforcement of those general-disclosure provi-
sions, while affirming all the rest of the injunction. Id., at
1231.
                               B
                               1
    Around the same time as the enactment of the Florida
law, Texas adopted a similar measure, H. B. 20, which co-
vers “social media platform[s]” with more than 50 million
monthly users in the United States. Tex. Bus. & Com. Code
Ann. §120.002(b) (West 2023). The statute defines a
“ ‘[s]ocial media platform’ ” as an “[i]nternet website or ap-
plication that is open to the public, allows a user to create
an account, and enables users to communicate with other
users for the primary purpose of posting information, com-
ments, messages, or images.” §120.001(l). Unlike Florida’s
broader law, however, Texas’s statute does not cover
internet-service providers, email providers, and websites
that “consis[t] primarily of news, sports, entertainment, or
other information or content that is not user generated but
is preselected by the provider.” §120.001(1)(C)(i).
    To ensure “the free exchange of ideas and information,”
H. B. 20 requires regulated platforms to abide by the fol-
lowing content-moderation and disclosure requirements.
Act of Sept. 2, 2021, 87th Leg., 2d Called Sess., ch. 3.
    Content-moderation provisions. H. B. 20 prevents social-
media companies from “censoring” users—that is, acting to
“block, ban, remove, deplatform, demonetize, de-boost, re-
strict, deny equal access or visibility to, or otherwise dis-
criminate against”—based on their viewpoint or geographic
10                   MOODY v. NETCHOICE, LLC

                    ALITO, J., concurring in judgment

location within Texas.10,11,12 Tex. Civ. Prac. & Rem. Code
Ann. §§143A.001(1), 143A.002(a)(1)–(3) (West Cum. Supp.
2023). However, the law allows platforms to censor speech
that: federal law “specifically authorize[s]” them to censor;
speech that the platform is told sexually exploits children
or survivors of sexual abuse; speech that “directly incites
criminal activity or consists of specific threats of violence
targeted against a person or group because of race, color,
disability, religion, national origin or ancestry, age, sex or
status as peace officer or judge”; and speech that is other-
wise unlawful or has been the subject of a user’s request for
removal from his or her feed or profile. §§143A.006(a)–(b).
   Disclosure provisions. Like the Florida law, H. B. 20 also
requires platforms to make general and individual disclo-
sures about their censorship practices. Specifically, the law
obligates each platform to tell the public how it “targets,”
“promotes,” and “moderates” content. §§120.051(a)(1)–(3).
And whenever a platform censors a user, the law requires
it to inform the user why that was done. §120.103(a)(1).13

——————
  10 In general, to “deplatform” means “to remove and ban a registered

user from a mass communication medium (such as a social networking
or blogging website).” Merriam-Webster’s Collegiate Dictionary (10th
ed. 2024), (defining “deplatform”; some punctuation omitted), https://
unabridged.merriam-webster.com/collegiate/deplatform (unless other-
wise noted, all internet sites last accessed May 22, 2024).
  11 “[D]emonetization” often refers to the act of preventing “online con-

tent from earning revenue (as from advertisements).” Ibid. (defining
“demonetize”; some punctuation omitted), https://unabridged.merriam-
webster.com/collegiate/demonetize.
  12 “Boosting on social media means [paying] a platform to amplify . . .

posts for more reach.” C. Williams, HubSpot, Social Media Definitions:
The Ultimate Glossary of Terms You Should Know (June 23, 2023),
https://blog.hubspot.com/marketing/social-media-terms.          De-boosting
thus usually refers to when platforms refuse to continue increasing a
post’s or user’s visibility to other users.
  13 Texas has represented that a brief computer-generated notification

to an affected user would satisfy the provision’s notification requirement.
Brief for Respondent in No. 22–555, p. 44.
                  Cite as: 603 U. S. ____ (2024)            11

                ALITO, J., concurring in judgment

Platforms must allow users to appeal removal decisions
through “an easily accessible complaint system;” resolve
such appeals within 14 business days (unless an enumer-
ated exception applies); and, if the appeal is successful, pro-
vide “the reason for the reversal.” §§120.101, 120.103(a)(2),
(a)(3)(B)–(b), 120.104.
   Users may sue any platform that violates these provi-
sions, as may the Texas attorney general. §143A.007(d).
But unlike the Florida law, H. B. 20 authorizes only injunc-
tive relief. §§143A.007(a), 143A.008. It contains a strong
severability provision, §8(a), which reaches “every provi-
sion, section, subsection, sentence, clause, phrase, or word
in th[e] Act, and every application of [its] provisions.”
                               2
   As it did in the Florida case, NetChoice sought a prelimi-
nary injunction in federal court, claiming that H. B. 20 vio-
lates the First Amendment in its entirety. In response,
Texas argued that because H. B. 20 regulates NetChoice’s
members “in their operation as publicly accessible conduits
for the speech of others” rather than “as authors or editors”
of their own speech, NetChoice could not prevail. Record in
No. 1:21–CV–00840 (WD Tex.), Doc. 39, p. 23. But even if
the platforms might have the right to use algorithms to cen-
sor their users’ speech, the State argued, the question of
“what these algorithms are doing is a critical, and so far,
unexplained, aspect of this case.” Id., at 24. This deficiency
mattered, Texas contended, because the platforms could
succeed on their facial challenge only by showing that “all
algorithms used by the Platforms are for the purposes of
expressing viewpoints of those Platforms.” Id., at 27. And
because NetChoice had not even explained what its mem-
bers’ algorithms did, much less whether they did so in an
expressive way, Texas argued that NetChoice had not
shown that “all applications of H.B. 20 are unconstitu-
tional.” Ibid.; see also id., Doc. 53, at 13 (arguing that
12               MOODY v. NETCHOICE, LLC

                ALITO, J., concurring in judgment

NetChoice had failed to show that “H. B. 20 is . . . unconsti-
tutional in all its applications” because “a number” of
NetChoice’s members had conceded that the law did “not
burden or chill their speech”).
   To clarify these and other “threshold issues,” Texas
moved for expedited discovery. Id., Doc. 20, at 1. The Dis-
trict Court granted Texas’s motion in part, but after one
month of discovery, it sided with NetChoice and enjoined
H. B. 20 in its entirety before it could go into effect. Texas
appealed, arguing that despite the District Court’s judg-
ment to the contrary, “[l]aws requiring commercial entities
to neutrally host speakers generally do not even implicate
the First Amendment because they do not regulate the
host’s speech at all—they regulate its conduct.” Brief for
Appellant in No. 21–51178 (CA5), p. 16. The State also em-
phasized NetChoice’s alleged failure to show that H. B. 20
was unconstitutional in even a “ ‘substantial number of its
applications,’ ” the “bare minimum” showing that
NetChoice needed to make to prevail on its facial challenge.
E.g., Reply Brief in No. 21–51178 (CA5), p. 8 (quoting Amer-
icans for Prosperity Foundation v. Bonta, 594 U. S. 595, 615
(2021)).
   A divided Fifth Circuit panel reversed, focusing primarily
on NetChoice’s failure to “even try to show that HB 20 is
‘unconstitutional in all of its applications.’ ” 49 F. 4th 439,
449 (2022) (quoting Washington State Grange v. Washing-
ton State Republican Party, 552 U. S. 442, 449 (2008)). The
court also accepted Texas’s argument that H. B. 20 “does
not regulate the Platforms’ speech at all” because “the Plat-
forms are not ‘speaking’ when they host other people’s
speech.” 49 F. 4th, at 448. Finally, the court upheld the
law’s disclosure requirements on the ground that they in-
volve the disclosure of the type of purely factual and uncon-
troversial information that may be compelled under Zau-
derer. 49 F. 4th, at 485.
                  Cite as: 603 U. S. ____ (2024)            13

                ALITO, J., concurring in judgment

                              II
   NetChoice contends that the Florida and Texas statutes
facially violate the First Amendment, meaning that they
cannot be applied to anyone at any time under any circum-
stances without violating the Constitution. Such chal-
lenges are strongly disfavored. See Washington State
Grange, 552 U. S., at 452. They often raise the risk of
“ ‘premature interpretatio[n] of statutes’ on the basis of fac-
tually barebones records.” Sabri v. United States, 541 U. S.
600, 609 (2004). They clash with the principle that courts
should neither “ ‘anticipate a question of constitutional law
in advance of the necessity of deciding it’ ” nor “ ‘formulate
a rule of constitutional law broader than is required by the
precise facts to which it is to be applied.’ ” Ashwander v.
TVA, 297 U. S. 288, 346–347 (1936) (Brandeis, J., concur-
ring). And they “threaten to short circuit the democratic
process by preventing laws embodying the will of the people
from being implemented in a manner consistent with the
Constitution.” Washington State Grange, 552 U. S., at 451.
   Facial challenges also strain the limits of the federal
courts’ constitutional authority to decide only actual
“Cases” and “Controversies.” Art. III, §2. “[L]itigants typi-
cally lack standing to assert the constitutional rights of
third parties.” United States v. Hansen, 599 U. S. 762, 769
(2023). But when a court holds that a law cannot be en-
forced against anyone under any circumstances, it effec-
tively grants relief with respect to unknown parties in dis-
putes that have not yet materialized.
   For these reasons, we have insisted that parties mount-
ing facial attacks satisfy demanding requirements. In
United States v. Salerno, 481 U. S. 739, 745 (1987), we held
that a facial challenger must “establish that no set of cir-
cumstances exists under which the [law] would be valid.”
“While some Members of the Court have criticized the Sa-
lerno formulation,” all have agreed “that a facial challenge
must fail where the statute has a “ ‘plainly legitimate
14                   MOODY v. NETCHOICE, LLC

                    ALITO, J., concurring in judgment

sweep.” ’ ” Washington State Grange, 552 U. S., at 449. In
First Amendment cases, we have sometimes phrased the
requirement as an obligation to show that a law “ ‘prohibits
a substantial amount of protected speech’ ” relative to its
‘ “plainly legitimate sweep.’ ” Hansen, 599 U. S., at 770;
Bonta, 594 U. S., at 615; United States v. Williams, 553
U. S. 285, 292–293 (2008).14
   NetChoice and the Federal Government urge us not to
apply any of these demanding tests because, they say, the
States disputed only the “threshold question” whether their
laws “cover expressive activity at all.” Tr. of Oral Arg. in
No. 22–277, at 76; see also id., at 84, 125; Tr. of Oral Arg.
in No. 22–555, at 92. The Court unanimously rejects that
argument—and for good reason.
   First, the States did not “put all their eggs in [one] bas-
ket.” Tr. of Oral Arg. in No. 22–277, at 76. To be sure, they
argued that their newly enacted laws were valid in all their
applications. Ibid. Both the Federal Government and the
States almost always defend the constitutionality of all pro-
visions of their laws. But Florida and Texas did not stop
there. Rather, as noted above, they went on to argue that
NetChoice had failed to make the showing required for a
facial challenge.15 Therefore, the record does not support
——————
  14 At oral argument, NetChoice represented that “it’s the plainly legit-

imate sweep test, which is not synonymous with overbreadth,” that gov-
erns these cases. See Tr. of Oral Arg. in No. 22–277, p. 70; contra, ante,
at 9 (suggesting that the overbreadth doctrine applies to all facial chal-
lenges brought under the First Amendment, including these cases). This
representation makes sense given that the overbreadth doctrine applies
only when there is “a realistic danger that the statute itself will signifi-
cantly compromise recognized First Amendment protections of parties
not before the Court.” Members of City Council of Los Angeles v. Taxpay-
ers for Vincent, 466 U. S. 789, 801 (1984). And here, NetChoice appears
to represent all—or nearly all—regulated parties.
  15 See Reply Brief in No. 21–12355 (CA11), p. 15 (“Plaintiffs—in their

facial challenge—have failed to demonstrate that even a significant sub-
set of covered social media platforms engages in [expressive] conduct.”
See also Brief for Appellants in No. 21–12355 (CA11), p. 20 (NetChoice
                      Cite as: 603 U. S. ____ (2024)                     15

                    ALITO, J., concurring in judgment

NetChoice’s attempt to use “the party presentation rules”
as grounds for blocking our consideration of the question
whether it satisfied the facial constitutionality test. Tr. of
Oral Arg. in No. 22–555, at 92.
    Second, even if the States had not asked the lower courts
to reject NetChoice’s request for blanket relief, it would
have been improper for those courts to enjoin all applica-
tions of the challenged laws unless that test was met. “It is
one thing to allow parties to forfeit claims, defenses, or lines
of argument; it would be quite another to allow parties to
stipulate or bind [a court] to the application of an incorrect
legal standard.” Gardner v. Galetka, 568 F. 3d 862, 879
(CA10 2009); see also Kairys v. Southern Pines Trucking,
Inc., 75 F. 4th 153, 160 (CA3 2023) (“But parties cannot for-
feit the application of ‘controlling law’ ”); United States v.
Escobar, 866 F. 3d 333, 339, n. 13 (CA5 2017) (per curiam)
(“ ‘A party cannot waive, concede, or abandon the applicable
standard of review’ ” (quoting Ward v. Stephens, 777 F. 3d
250, 257, n. 3 (CA5 2015)).
    Represented by sophisticated counsel, NetChoice made
the deliberate choice to mount a facial challenge to both
laws, and in doing so, it obviously knew what it would have
to show in order to prevail. NetChoice decided to fight these
laws on these terms, and the Court properly holds it to that
decision.

——————
is “unlikely to prevail on the merits of [its] facial First Amendment
challenge”); Record in No. 4:21–CV–00220 (ND Fla.), Doc. 106, p. 30
(“Plaintiffs have not demonstrated that their members actually [express
a message],” so there is “not a basis for sustaining Plaintiffs’ facial con-
stitutional challenge”); Reply Brief in No. 21–51178 (CA5), p. 8 (arguing
that NetChoice failed “to show at a bare minimum that [S. B. 20] is un-
constitutional in a ‘substantial number of its applications’ ” (quoting
Americans for Prosperity Foundation v. Bonta, 594 U. S. 595, 615
(2021))); Record in No. 1:21–CV–00840 (WD Tex.), Doc. 39, p. 27 (because
“not all applications of H.B. 20 are unconstitutional,” “Plaintiffs’ delayed
facial challenge [can]not succeed”).
16               MOODY v. NETCHOICE, LLC

                ALITO, J., concurring in judgment

                              III
   I therefore turn to the question whether NetChoice estab-
lished facial unconstitutionality, and I begin with the
States’ content-moderation requirements. To show that
these provisions are facially invalid, NetChoice had to
demonstrate that they lack a plainly legitimate sweep un-
der the First Amendment. Our precedents interpreting
that Amendment provide the numerator (the number of un-
constitutional applications) and denominator (the total
number of possible applications) that NetChoice was re-
quired to identify in order to make that showing. Estimat-
ing the numerator requires an understanding of the First
Amendment principles that must be applied here, and I
therefore provide a brief review of those principles.
                              A
   The First Amendment protects “the freedom of speech,”
and most of our cases interpreting this right have involved
government efforts to forbid, restrict, or compel a party’s
own oral or written expression. Agency for Int’l Develop-
ment v. Alliance for Open Society Int’l, Inc., 570 U. S. 205,
213 (2013); Wooley v. Maynard, 430 U. S. 705, 714 (1977);
West Virginia Bd. of Ed. v. Barnette, 319 U. S. 624, 642
(1943). Some cases, however, have involved another aspect
of the free speech right, namely, the right to “presen[t] . . .
an edited compilation of speech generated by other persons”
for the purpose of expressing a particular message. See
Hurley v. Irish-American Gay, Lesbian and Bisexual Group
of Boston, Inc., 515 U. S. 557, 570 (1995). As used in this
context, the term “compilation” means any effort to present
the expression of others in some sort of organized package.
See ibid.
   An example such as the famous Oxford Book of English
Poetry illustrates why a compilation may constitute expres-
sion on the part of the compiler. The editors’ selection of
the poems included in this volume expresses their view
                  Cite as: 603 U. S. ____ (2024)            17

                ALITO, J., concurring in judgment

about the poets and poems that most deserve the attention
of their anticipated readers. Forcing the editors to exclude
or include a poem could alter the expression that the editors
wish to convey.
   Not all compilations, however, have this expressive char-
acteristic. Suppose that the head of a neighborhood group
prepares a directory consisting of contact information sub-
mitted by all the residents who want to be listed. This di-
rectory would not include any meaningful expression on the
part of the compiler.
   Because not all compilers express a message of their own,
not all compilations are protected by the First Amendment.
Instead, the First Amendment protects only those compila-
tions that are “inherently expressive” in their own right,
meaning that they select and present speech created by
other persons in order “to spread [the compiler’s] own mes-
sage.” FAIR, 547 U. S., at 66; Pacific Gas & Elec. Co. v.
Public Util. Comm’n of Cal., 475 U. S. 1, 10 (1986) (PG&E)
(plurality opinion). If a compilation is inherently expres-
sive, then the compiler may have the right to refuse to ac-
commodate a particular speaker or message. See Hurley,
515 U. S., at 573. But if a compilation is not inherently ex-
pressive, then the government can require the compiler to
host a message or speaker because the accommodation does
not amount to compelled speech. Id., at 578–581.
   To show that a hosting requirement would compel speech
and thereby trigger First Amendment scrutiny, a claimant
must generally show three things.
                              1
   First, a claimant must establish that its practice is to ex-
ercise “editorial discretion in the selection and presenta-
tion” of the content it hosts. Arkansas Ed. Television
Comm’n v. Forbes, 523 U. S. 666, 674 (1998); Hurley, 515
U. S., at 574; ante, at 14. NetChoice describes this process
18                   MOODY v. NETCHOICE, LLC

                    ALITO, J., concurring in judgment

as content “curation.” But whatever you call it, not all com-
pilers do this, at least in a way that is inherently expressive.
Some may serve as “passive receptacle[s]” of third-party
speech or as “dumb pipes”16 that merely emit what they are
fed. Such entities communicate no message of their own,
and accordingly, their conduct does not merit First Amend-
ment protection.17        Miami Herald Publishing Co. v.
Tornillo, 418 U. S. 241, 258 (1974).
   Determining whether an entity should be viewed as a “cu-
rator” or a “dumb pipe” may not always be easy because dif-
ferent aspects of an entity’s operations may take different
approaches with respect to hosting third-party speech. The
typical newspaper regulates the content and presentation
of articles authored by its employees or others, PG&E, 475
U. S., at 8, but that same paper might also run nearly all
the classified advertisements it receives, regardless of their
content and without adding any expression of its own.
Compare Tornillo, 418 U. S. 241, with Pittsburgh Press Co.
v. Pittsburgh Comm’n on Human Relations, 413 U. S. 376
(1973). These differences may be significant for First
Amendment purposes.
   The same may be true for a parade organizer. For exam-
ple, the practice of a parade organizer may be to select the

——————
   16 American Broadcasting Cos. v. Aereo, Inc., 573 U. S. 431, 458 (2014)

(Scalia, J., dissenting).
   17 The majority states that it is irrelevant whether “a compiler includes

most items and excludes just a few.” Ante, at 18. That may be true if the
compiler carefully reviews, edits, and selects a large proportion of the
items it receives. But if an entity, like some “sort of community billboard,
regularly carr[ies] the messages of third parties” instead of selecting only
those that contribute to a common theme, then this information becomes
highly relevant. PG&E, 475 U. S. 1, 23 (1986) (Marshall, J., concurring
in judgment). Entities that have assumed the role of common carriers
fall into this category, for example. And the States defend portions of
their laws on the ground that at least some social-media platforms have
taken on that role. The majority brushes aside that argument without
adequate consideration.
                  Cite as: 603 U. S. ____ (2024)           19

                ALITO, J., concurring in judgment

groups that are admitted, but not the individuals who are
allowed to march as members of admitted groups. Hurley,
515 U. S., at 572–574. In such a case, each of these prac-
tices would have to be analyzed separately.
                                2
   Second, the host must use the compilation of speech to
express “some sort of collective point”—even if only at a
fairly abstract level. Id., at 568. Thus, a parade organizer
who claims a First Amendment right to exclude certain
groups or individuals would need to show at least that the
message conveyed by the groups or individuals who are al-
lowed to march comport with the parade’s theme. Id., at
560, 574. A parade comprising “unrelated segments” that
lumber along together willy-nilly would likely not express
anything at all. Id., at 576. And although “a narrow, suc-
cinctly articulable message is not a condition of constitu-
tional protection,” compilations that organize the speech of
others in a non-expressive way (e.g., chronologically) fall
“beyond the realm of expressi[on].” Id., at 569; contra, ante,
at 17–18.
   Our decision in PruneYard illustrates this point. In that
case, the Court held that a mall could be required to host
third-party speech (i.e., to admit individuals who wanted to
distribute handbills or solicit signatures on petitions) be-
cause the mall’s admission policy did not express any mes-
sage, and because the mall was “open to the public at large.”
PruneYard Shopping Center v. Robins, 447 U. S. 74, 83, 87–
88 (1980); 303 Creative LLC v. Elenis, 600 U. S. 570, 590
(2023). In such circumstances, we held that the First
Amendment is not implicated merely because a host objects
to a particular message or viewpoint. See PG&E, 475 U. S.,
at 12.
                            3
  Finally, a compiler must show that its “own message [is]
20                  MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

affected by the speech it [is] forced to accommodate.” FAIR,
547 U. S., at 63. In core examples of expressive compila-
tions, such as a book containing selected articles, chapters,
stories, or poems, this requirement is easily satisfied. But
in other situations, it may be hard to identify any message
that would be affected by the inclusion of particular third-
party speech.
   Two precedents that the majority tries to downplay, if not
forget, are illustrative. The first is PruneYard, which I
have already discussed. The PruneYard Court rejected the
mall’s First Amendment claim because “[t]he views ex-
pressed by members of the public in passing out pamphlets
or seeking signatures for a petition [were] not likely [to] be
identified with those of the owner.” 447 U. S., at 87. And if
those who perused the handbills or petitions were not likely
to make that connection, any message that the mall owner
intended to convey would not be affected.
   The decision in FAIR rested on similar reasoning. In that
case, the Court did not dispute the proposition that the law
schools’ refusal to host military recruiters expressed the
message that the military should admit and retain gays and
lesbians. But the Court found no First Amendment viola-
tion because, as in PruneYard, it was unlikely that the
views of the military recruiters “would be identified with”
those of the schools themselves, and consequently, hosting
the military recruiters did not “sufficiently interfere with
any message of the school.” 547 U. S., at 64–65; contra,
ante, at 25 (“[T]his Court has never hinged a compiler’s
First Amendment protection on the risk of misattribu-
tion.”).18

——————
  18 To be sure, in Turner Broadcasting System, Inc. v. FCC, 512 U. S.

622, 655 (1994), we held that the First Amendment applied even though
there was “little risk” of misattribution in that case. But that is only
because the claimants in that case had already shown that the Cable Act
affected the quantity or reach of the messages that they communicated
                      Cite as: 603 U. S. ____ (2024)                      21

                    ALITO, J., concurring in judgment

                              B
  A party that challenges government interference with its
curation of content cannot win without making the three-
part showing just outlined, but such a showing does not
guarantee victory. To prevail, the party must go on and
show that the challenged regulation of its curation practices
violates the applicable level of First Amendment scrutiny.
  Our decision in Turner makes that clear. Although the
television cable operators in that case made the showing
needed to trigger First Amendment scrutiny, they did not
ultimately prevail on their facial challenge to the Cable Act.
After a remand and more than 18 months of additional fac-
tual development, the Court held that the law was ade-
quately tailored to serve legitimate and important govern-
ment interests, including “promoting the widespread
dissemination of information from a multiplicity of
sources.” Turner Broadcasting System, Inc. v. FCC, 520
U. S. 180, 189 (1997). Here, the States assert a similar in-
terest in fostering a free and open marketplace of ideas.19
                           C
  With these standards in mind, I proceed to the question
——————
through “original programming” or television programs produced by oth-
ers. Id., at 636 (internal quotation marks omitted). In cases not involv-
ing core examples of expressive compilations, such as in PruneYard and
FAIR, a compiler’s First Amendment protection has very much turned
on the risk of misattribution.
  19 Contrary to the majority’s suggestion, ante, at 27, this is not the only

interest that Texas asserted. Texas has also invoked its interest in pre-
venting platforms from discriminating against speakers who reside in
Texas or engage in certain forms of off-platform speech. Brief for Re-
spondent in No. 22–555, at 15. The majority opinion does not mention
these features, much less the interests that Texas claims they serve.
Texas also asserts an interest in preventing common carriers from en-
gaging in “ ‘invidious discrimination in the distribution of publicly avail-
able goods, services, and other advantages.’ ” Id., at 18. These are “com-
pelling state interests of the highest order” too. Roberts v. United States
Jaycees, 468 U. S. 609, 624 (1984).
22                  MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

whether the content-moderation provisions are facially
valid. For the following three reasons, NetChoice failed to
meet its burden.
                              1
  First, NetChoice did not establish which entities the stat-
utes cover. This failure is critical because it is “impossible
to determine whether a statute reaches too far without first
knowing what the statute covers.” Williams, 553 U. S., at
293. When it sued Florida, NetChoice was reluctant to dis-
close which of its members were covered by S. B. 7072. In-
stead, it filed declarations revealing only that the law
reached “Etsy, Facebook, and YouTube.” Tr. of Oral Arg. in
No. 22–277, at 32. In this Court, NetChoice was a bit more
forthcoming, representing that S. B. 7072 also covers In-
stagram, X, Pinterest, Reddit, Gmail, Uber, and other
e-commerce websites. Id., at 69, 76; Brief for Respondents
in No. 22–277, at 7, 38, 49.20 But NetChoice has still not
provided a complete list.
  NetChoice was similarly reluctant to identify its affected
members in the Texas case. At first, NetChoice “repre-
sented . . . that only Facebook, YouTube, and [X] are af-
fected by the Texas law.” Brief for Appellant in No. 21–
51178 (CA5), at 1, n. 1. But in its brief in this Court,
NetChoice told us that H. B. 20 also regulates “some of the
Internet’s most popular websites, including Facebook, In-
stagram, Pinterest, TikTok, Vimeo, X (formerly known as
Twitter), and YouTube.” Brief for Petitioners in No. 22–




——————
  20 This concession suggests that S. B. 7072 may “cover websites that

engage in primarily non-expressive conduct.” Tr. of Oral Arg. in No. 22–
277, at 34.
                      Cite as: 603 U. S. ____ (2024)                    23

                    ALITO, J., concurring in judgment

555, p. 1. And websites such as Discord,21 Reddit,22 Wik-
ipedia,23 and Yelp24 have filed amicus briefs claiming that
they may be covered by both the Texas and Florida laws.
   It is a mystery how NetChoice could expect to prevail on
a facial challenge without candidly disclosing the platforms
that it thinks the challenged laws reach or the nature of the
content moderation they practice. Without such infor-
mation, we have no way of knowing whether the laws at
issue here “cover websites that engage in primarily non-
expressive conduct.” Tr. of Oral Arg. in No. 22–277, at 34;
see also id., at 126. For example, among other things,
NetChoice has not stated whether the challenged laws
reach websites like WhatsApp25 and Gmail,26 which carry
messages instead of curating them to create an independ-
ent speech product. Both laws also appear to cover Reddit27




——————
   21 Brief for Discord Inc. as Amicus Curiae 2, 21–27. “Discord is a real

time messaging service with over 150 million active monthly users who
communicate within a huge variety of interest-based communities, or
‘servers.’ ” Id., at 1.
   22 Brief for Reddit, Inc., as Amicus Curiae 2. Reddit is an online forum

that allows its “users to establish and enforce their own rules governing
what topics are acceptable and how those topics may be discussed . . . .
The display of content on Reddit is thus primarily driven by humans—
not by centralized algorithms.” Ibid.
   23 Brief for Wikimedia Foundation as Amicus Curiae 2.
   24 Brief for Yelp Inc. as Amicus Curiae 3–4.
   25 About WhatsApp, WhatsApp, https://whatsapp.com/about (last ac-

cessed Apr. 23, 2024).
   26 Secure, Smart, and Easy To Use Email, Gmail, https://google.com/

gmail/about (last accessed Apr. 23, 2024).
   27 Reddit Content Policy, Reddit, https://www.redditinc.com/policies

/content-policy (last accessed Apr. 23, 2024) (describing Reddit as a plat-
form that is run and moderated by its users).
24                  MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

and BeReal,28 and websites like Parler,29 which claim to en-
gage in little or no content moderation at all. And Florida’s
law, which is even broader than Texas’s, plainly applies to
e-commerce platforms like Etsy that make clear in their
terms of service that they are “not a curated marketplace.”30
  In First Amendment terms, this means that these laws—
in at least some of their applications—appear to regulate
the kind of “passive receptacle[s]” of third-party speech that
receive no First Amendment protection. Tornillo, 418 U. S.,
at 258. Given such uncertainty, it is impossible for us to
determine whether these laws have a “plainly legitimate
sweep.” Williams, 553 U. S., at 292; Washington State
Grange, 552 U. S., at 449.
                              2
  Second, NetChoice has not established what kinds of con-
tent appear on all the regulated platforms, and we cannot
determine whether these platforms create an “inherently
expressive” compilation of third-party speech until we know
what is being compiled.
  We know that social-media platforms generally allow
their users to create accounts; send direct messages
——————
   28 BeReal, which appears to have enough monthly users to be covered

by the Texas law, allows users to share a photo with their friends once
during a randomly selected 2-minute window each day. Time To BeReal,
https://help.bereal.com/hc/en-us/articles/7350386715165--Time-to-BeReal
(last accessed Apr. 23, 2024). Twenty-four hours later, those photos dis-
appear. Because BeReal posts thus appear and disappear “randomly,”
even the Eleventh Circuit would agree that BeReal likely is not an ex-
pressive compilation. 34 F. 4th, at 1214.
   29 Community Guidelines, Parler, https://www.parler.com/community-

guidelines (May 31, 2024) (“We honor the ability of all users to freely
express themselves without interference from oppressive censorship or
manipulation”). Parler probably does not have a sufficient number of
monthly users to be covered by these statutes. But it is possible that
other covered websites use a similar business model.
   30 Our House Rules, Etsy, https://etsy.com/legal/prohibited (last ac-

cessed Apr. 23, 2024).
                      Cite as: 603 U. S. ____ (2024)                    25

                    ALITO, J., concurring in judgment

through private inboxes; post written messages, photos,
and videos; and comment on, repost, or otherwise interact
with other users’ posts. And NetChoice acknowledges in
fairly general terms that its members engage in most—
though not all—of these functions. But such generalities
are insufficient.
   For one thing, the ways in which users post, send direct
messages, or interact with content may differ in meaningful
ways from platform to platform. And NetChoice’s failure to
account for these differences may be decisive. To see how,
consider X and Yelp. Both platforms allow users to post
comments and photos, but they differ in other respects.31 X
permits users to post (or “Tweet”) on a broad range of topics
because its “purpose is to serve the public conversation,”32
and as a result, many elected officials use X to communicate
with constituents. Yelp, by contrast, allows users to post
comments and pictures only for the purpose of advertising
local businesses or providing “firsthand accounts” that re-
flect their “consumer experience” with businesses.33 It does
not permit “rants about political ideologies, a business’s em-
ployment practices, extraordinary circumstances, or other
matters that don’t address the core of the consumer experi-
ence.”34
   As this example shows, X’s content is more political than
Yelp’s, and Yelp’s content is more commercial than X’s.
That difference may be significant for First Amendment
purposes. See Pittsburgh Press, 413 U. S. 376. But
NetChoice has not developed the record on that front. Nor


——————
  31 Yelp and X are both covered by S. B. 7072 and H. B. 20. See Brief

for Yelp Inc. as Amicus Curiae 4, n. 4.
  32 The X Rules, X, https://help.x.com/en/rules-and-policies/x-rules (last

accessed Apr. 23, 2024).
  33 Content Guidelines, Yelp, https://www.yelp.com/guidelines (last ac-

cessed Apr. 23, 2024).
  34 Ibid.
26                 MOODY v. NETCHOICE, LLC

                  ALITO, J., concurring in judgment

has it shown what kinds of content appear across the di-
verse array of regulated platforms.
   Social-media platforms are diverse, and each may be
unique in potentially significant ways. On the present rec-
ord, we are ill-equipped to account for the many platform-
specific features that allow users to do things like sell or
purchase goods,35 live-stream events,36 request a ride,37 ar-
range a date,38 create a discussion forum,39 wire money to
friends,40 play a video game,41 hire an employee,42 log a
run,43 or agree to watch a dog.44 The challenged laws may
apply differently to these different functions, which may
present different First Amendment issues. A court cannot
invalidate the challenged laws if it has to speculate about
their applications.
                              3
  Third, NetChoice has not established how websites mod-
erate content. NetChoice alleges that “[c]overed websites”
generally use algorithms to organize and censor content ap-
pearing in “search results, comments, or in feeds.” Brief for
Petitioners in No. 22–555, at 4, 6. But at this stage and on
this record, we have no way of confirming whether all of the
regulated platforms use algorithms to organize all of their
content, much less whether these algorithms are expres-
sive. See Hurley, 515 U. S., at 568. Facebook and Reddit,
for instance, both allow their users to post about a wide

——————
 35 E.g., Facebook Marketplace, Etsy.
 36 E.g., X Live, Twitch.
 37 E.g., Uber, Lyft.
 38 E.g., Facebook Dating, Tinder.
 39 E.g., Reddit, Quora.
 40 E.g., Meta Pay, Venmo, PayPal.
 41 E.g., Metaverse, Discord.
 42 E.g., Indeed, LinkedIn.
 43 E.g., Strava.
 44 E.g., Rover.
                      Cite as: 603 U. S. ____ (2024)                     27

                    ALITO, J., concurring in judgment

range of topics.45 But while Facebook uses algorithms to
arrange and moderate its users’ posts, Reddit asserts that
its content is moderated by Reddit users, “not by central-
ized algorithms.” Brief for Reddit, Inc., as Amicus Curiae
2. If Reddit and other platforms entirely outsource curation
to others, they can hardly claim that their compilations ex-
press their own views.
   Perhaps recognizing this, NetChoice argues in passing
that it cannot tell us how its members moderate content be-
cause doing so would embolden “malicious actors” and di-
vulge “proprietary and closely held” information. E.g., Brief
for Petitioners in No. 22–555, at 11. But these harms are
far from inevitable. Various platforms already make simi-
lar disclosures—both voluntarily and to comply with the
European Union’s Digital Services Act46—yet the sky has
not fallen. And on remand, NetChoice will have the oppor-
tunity to contest whether particular disclosures are neces-
sary and whether any relevant materials should be filed un-
der seal.
   Various NetChoice members already disclose in broad
strokes how they use algorithms to curate content. Many
platforms claim to use algorithms to identify and remove
——————
  45 Community Standards, Facebook, https://transparency.meta.com/

policies/community-standards (“[Facebook] wants people to be able to
talk openly about the issues that matter to them, whether through writ-
ten comments, photos, music, or other artistic mediums”); Brief for Red-
dit, Inc., as Amicus Curiae 12 (“[T]he Reddit platform as a whole accom-
modates a wide range of communities and modes of discourse”).
  46 Comm’n Reg. 2022/2065, Art. 17, 2022 O. J. (L. 277) 51–52.

NetChoice does not dispute the States’ assertion that the regulated plat-
forms are required to comply with this law. Compare Brief for Petition-
ers in No. 22–277, p. 49, with Reply Brief in No. 22–277, p. 24; Tr. of Oral
Arg. in No. 22–555, pp. 20–21. If, on remand, the States show that the
platforms have been able to comply with this law in Europe without hav-
ing to forgo “exercising editorial discretion at all,” Brief for Respondents
in No. 22–277, p. 40, then that might help them prove that their disclo-
sure laws are not “unduly burdensome” under Zauderer v. Office of Dis-
ciplinary Counsel of Supreme Court of Ohio, 471 U. S. 626 (1985).
28                  MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

violent, obscene, sexually explicit, and false posts that vio-
late their community guidelines. Brief for Developers Alli-
ance et al. as Amici Curiae 11. Some platforms—like X, for
instance—say they use algorithms, not for the purpose of
removing all nonconforming speech, but to “promot[e] coun-
terspeech” that “presents facts to correct misstatements” or
“denounces hateful or dangerous speech.”47 Still others,
like Parler,48 Reddit,49 and Signal Messenger,50 say they en-
gage in little or no content moderation.
   Some platforms have also disclosed that they use algo-
rithms to help their users find relevant content. The e-com-
merce platform Etsy, for instance, uses an algorithm that
matches a user’s search terms to the “attributes” that a
seller ascribes to its wares.51 Etsy’s algorithm also accounts
for things like the date of the seller’s listing, the proximity
of the seller and buyer, and the quality of the seller’s cus-
tomer-service ratings. Ibid.
   YouTube says it answers search queries based on “rele-
vance, engagement and quality”—taking into account how
well a search query matches a video title, the kinds of vid-
eos a particular user viewed in the past, and each creator’s
“expertise, authoritativeness, and trustworthiness on a
given topic.”52
——————
   47 Our Approach to Policy Development and Enforcement Philosophy,

X, http://www.help.x.com/en/rules-and-policies/enforcement-philosophy.
   48 Community Guidelines, Parler, https://www.parler.com/community-

guidelines.
   49 Reddit Content Policy, Reddit, https://www.redditinc.com/policies

/content-policy.
   50 Signal Terms & Privacy Policy, Signal Messenger (May 25, 2018),

https://www.signal.org/legal.
   51 How Etsy Search Works, Etsy Help Center, https://help.etsy.com/hc/

en-us/articles/115015745428–How-Etsy-Search-Works?segment=selling
(visited Apr. 9, 2024).
   52 YouTube     Search,   https://www.youtube.com/howyoutubeworks/
product-features/search (last accessed Apr. 23, 2024). Unlike many other
platforms, YouTube does not accept payment for better placement within
organic search
                   Cite as: 603 U. S. ____ (2024)                29

                  ALITO, J., concurring in judgment

  These disclosures suggest that platforms can say some-
thing about their content-moderation practices without en-
abling malicious actors or disclosing proprietary infor-
mation. They also suggest that not all platforms curate all
third-party content in an inherently expressive way. With-
out more information about how regulated platforms mod-
erate content, it is not possible to determine whether these
laws lack “a ‘ “plainly legitimate sweep.” ’ ” Washington
State Grange, 552 U. S., at 449.
  For all these reasons, NetChoice failed to establish
whether the content-moderation provisions violate the
First Amendment on their face.
                               D
   Although the only question the Court must decide today
is whether NetChoice showed that the Florida and Texas
laws are facially unconstitutional, much of the majority
opinion addresses a different question: whether the Texas
law’s content-moderation provisions are constitutional as
applied to two features of two platforms—Facebook’s News
Feed and YouTube’s homepage. The opinion justifies this
discussion on the ground that the Fifth Circuit cannot apply
the facial constitutionality test without resolving that ques-
tion, see, e.g., ante, at 13, 30, but that is not necessarily
true. Especially in light of the wide reach of the Texas law,
NetChoice may still fall far short of establishing facial un-
constitutionality—even if it is assumed for the sake of ar-
gument that the Texas law is unconstitutional as applied to
Facebook’s News Feed and YouTube’s homepage.53
   For this reason, the majority’s “guidance” on this issue
may well be superfluous. Yet superfluity is not its most
egregious flaw. The majority’s discussion also rests on
wholly conclusory assumptions that lack record support.

——————
  53 This problem is even more pronounced for the Florida law, which

covers more platforms and conduct than the Texas law.
30                 MOODY v. NETCHOICE, LLC

                  ALITO, J., concurring in judgment

For example, the majority paints an attractive, though sim-
plistic, picture of what Facebook’s News Feed and
YouTube’s homepage do behind the scenes.             Taking
NetChoice at its word, the majority says that the platforms’
use of algorithms to enforce their community standards is
per se expressive. But the platforms have refused to dis-
close how these algorithms were created and how they ac-
tually work. And the majority fails to give any serious con-
sideration to key arguments pressed by the States. Most
notable is the majority’s conspicuous failure to address the
States’ contention that platforms like YouTube and Face-
book—which constitute the 21st century equivalent of the
old “public square”—should be viewed as common carriers.
See Biden v. Knight First Amendment Institute at Columbia
University, 593 U. S. ___, ___ (2021) (Thomas, J., concur-
ring) (slip op., at 6). Whether or not the Court ultimately
accepts that argument, it deserves serious treatment.
  Instead of seriously engaging with this and other argu-
ments, the majority rests on NetChoice’s dubious assertion
that there is no constitutionally significant difference be-
tween what newspaper editors did more than a half-century
ago at the time of Tornillo and what Facebook and YouTube
do today.
  Maybe that is right—but maybe it is not. Before mechan-
ically accepting this analogy, perhaps we should take a
closer look.
  Let’s start with size. Currently, Facebook and YouTube
each produced—on a daily basis—more than four petabytes
(4,000,000,000,000,000 bytes) of data.54 By my calculation,
that is roughly 1.3 billion times as many bytes as there are
in an issue of the New York Times.55

——————
  54 Breaking Down the Numbers: How Much Data Does the World Cre-

ate Daily in 2024? Edge Delta (Mar. 11, 2024), https://www.
edgedelta.com/company/blog/how-much-data-is-created-per-day.
  55 The average issue of the New York Times, excluding ads, contains
                      Cite as: 603 U. S. ____ (2024)                     31

                    ALITO, J., concurring in judgment

   No human being could possibly review even a tiny frac-
tion of this gigantic outpouring of speech, and it is therefore
hard to see how any shared message could be discerned.
And even if someone could view all this data and find such
a message, how likely is it that the addition of a small
amount of discordant speech would change the overall mes-
sage?
   Now consider how newspapers and social-media plat-
forms edit content. Newspaper editors are real human be-
ings, and when the Court decided Tornillo (the case that the
majority finds most instructive), editors assigned articles to
particular reporters, and copyeditors went over typescript
with a blue pencil. The platforms, by contrast, play no role
in selecting the billions of texts and videos that users try to
convey to each other. And the vast bulk of the “curation”
and “content moderation” carried out by platforms is not
done by human beings. Instead, algorithms remove a small
fraction of nonconforming posts post hoc and prioritize con-
tent based on factors that the platforms have not revealed
and may not even know. After all, many of the biggest plat-
forms are beginning to use AI algorithms to help them mod-
erate content. And when AI algorithms make a decision,
“even the researchers and programmers creating them
don’t really understand why the models they have built
make the decisions they make.”56 Are such decisions
equally expressive as the decisions made by humans?
Should we at least think about this?
   Other questions abound. Maybe we should think about
the enormous power exercised by platforms like Facebook
and YouTube as a result of “network effects.” Cf. Ohio v.
——————
about 150,000 words. A typical word consists of 10 to 20 bytes. There-
fore, the average issue of the New York Times contains around 3 million
bytes.
  56 T. Xu, AI Makes Decisions We Don’t Understand—That’s a Pro-

blem, (Jul. 19, 2021), https://builtin.com/artificial-intelligence/ai-right-
explanation.
32                  MOODY v. NETCHOICE, LLC

                   ALITO, J., concurring in judgment

American Express Co., 585 U. S. 529 (2018). And maybe we
should think about the unique ways in which social-media
platforms influence public thought. To be sure, I do not
suggest that we should decide at this time whether the Flor-
ida and Texas laws are constitutional as applied to Face-
book’s News Feed or YouTube’s homepage. My argument
is just the opposite. Such questions should be resolved in
the context of an as-applied challenge. But no as-applied
question is before us, and we do not have all the facts that
we need to tackle the extraneous matters reached by the
majority.
   Instead, when confronted with the application of a consti-
tutional requirement to new technology, we should proceed
with caution. While the meaning of the Constitution re-
mains constant, the application of enduring principles to
new technology requires an understanding of that technol-
ogy and its effects. Premature resolution of such questions
creates the risk of decisions that will quickly turn into em-
barrassments.
                             IV
  Just as NetChoice failed to make the showing necessary
to demonstrate that the States’ content-moderation provi-
sions are facially unconstitutional, NetChoice’s facial at-
tacks on the individual-disclosure provisions also fell short.
Those provisions require platforms to explain to affected us-
ers the basis of each content-censorship decision. Because
these regulations provide for the disclosure of “purely fac-
tual and uncontroversial information,” they must be re-
viewed under Zauderer’s framework, which requires only
that such laws be “reasonably related to the State’s interest
in preventing deception of consumers” and not “unduly
burde[n]” speech. 471 U. S., at 651.57

——————
 57 Both lower courts reviewed these provisions under the Zauderer test.

And in the Florida case in particular, NetChoice did not contest—and
                    Cite as: 603 U. S. ____ (2024)                 33

                  ALITO, J., concurring in judgment

   For Zauderer purposes, a law is “unduly burdensome” if
it threatens to “chil[l] protected commercial speech.” Ibid.
Here, NetChoice claims that these disclosures have that ef-
fect and lead platforms to “conclude that the safe course is
to . . . not exercis[e] editorial discretion at all” rather than
explain why they remove “millions of posts per day.” Brief
for Respondents in No. 22–277, at 39–40 (internal quotation
marks omitted).
   Our unanimous agreement regarding NetChoice’s failure
to show that a sufficient number of its members engage in
constitutionally protected expression prevents us from ac-
cepting NetChoice’s argument regarding these provisions.
In the lower courts, NetChoice did not even try to show how
these disclosure provisions chill each platform’s speech. In-
stead, NetChoice merely identified one subset of one plat-
form’s content that would be affected by these laws: billions
of nonconforming comments that YouTube removes each
year. 49 F. 4th, at 487; see also Brief for Appellees in
No. 21–12355 (CA11), p. 13. But if YouTube uses auto-
mated processes to flag and remove these comments, it is
not clear why having to disclose the bases of those processes
would chill YouTube’s speech. And even if having to explain
each removal decision would unduly burden YouTube’s
First Amendment rights, the same does not necessarily fol-
low with regard to all of NetChoice’s members.
   NetChoice’s failure to make this broader showing is espe-
cially problematic since NetChoice does not dispute the
States’ assertion that many platforms already provide a
notice-and-appeal process for their removal decisions. In
fact, some have even advocated for such disclosure require-
ments. Before its change in ownership, the previous Chief
Executive Officer of the platform now known as X went as

——————
accordingly forfeited—whether Zauderer applies here. See Brief for Ap-
pellants in No. 21–12355 (CA11), at 21; Brief for Appellees in No. 21–
12355 (CA11), p. 44.
34                 MOODY v. NETCHOICE, LLC

                  ALITO, J., concurring in judgment

far as to say that “all companies” should be required to ex-
plain censorship decisions and “provide a straightforward
process to appeal decisions made by humans or algo-
rithms.”58 Moreover, as mentioned, many platforms are al-
ready providing similar disclosures pursuant to the Euro-
pean Union’s Digital Services Act. Yet complying with that
law does not appear to have unduly burdened each plat-
form’s speech in those countries. On remand, the courts
might consider whether compliance with EU law chilled the
platforms’ speech.
                         *     *   *
  The only binding holding in these decisions is that
NetChoice has yet to prove that the Florida and Texas laws
they challenged are facially unconstitutional. Because the
majority opinion ventures far beyond the question we must
decide, I concur only in the judgment.




——————
  58 Does Section 230’s Sweeping Immunity Enable Big Tech Bad Behav-

ior? Hearing before the Senate Committee on Commerce, Science, and
Transportation, 116th Cong., 2d Sess., 2 (2020) (statement of Jack
Dorsey, CEO, Twitter, Inc.).