{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Initializing session. Solve CAPTCHA manually if prompted.\n",
      "2. Fetching API Case List...\n",
      "[1/20] Scraping: R. v. M.T.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj671/2025oncj671.html\n",
      "[2/20] Scraping: R. v. J.G.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj700/2025oncj700.html\n",
      "[3/20] Scraping: R. v. Laguerre\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj694/2025oncj694.html\n",
      "[4/20] Scraping: R. v. Khosa\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj693/2025oncj693.html\n",
      "[5/20] Scraping: R. v. Lachance\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj690/2025oncj690.html\n",
      "[6/20] Scraping: R. v. Eagen\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj687/2025oncj687.html\n",
      "[7/20] Scraping: R. v. Burnett\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj686/2025oncj686.html\n",
      "[8/20] Scraping: R. v. Nguyen\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj685/2025oncj685.html\n",
      "[9/20] Scraping: R. v. P.G.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj683/2025oncj683.html\n",
      "[10/20] Scraping: R. v. Cheema\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj736/2025oncj736.html\n",
      "[11/20] Scraping: R. v. R.G.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj682/2025oncj682.html\n",
      "[12/20] Scraping: R. v. I-B.(W.)\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj681/2025oncj681.html\n",
      "[13/20] Scraping: R. v. Walker\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj679/2025oncj679.html\n",
      "[14/20] Scraping: R. v. J.M.-F.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj678/2025oncj678.html\n",
      "[15/20] Scraping: R. v. Yousaf\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj676/2025oncj676.html\n",
      "[16/20] Scraping: R. v. McLeish\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj675/2025oncj675.html\n",
      "[17/20] Scraping: R. v. S.P.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj674/2025oncj674.html\n",
      "[18/20] Scraping: R. v. Hashimi\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj673/2025oncj673.html\n",
      "[19/20] Scraping: R. v. M.R.\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj672/2025oncj672.html\n",
      "[20/20] Scraping: R. v. Sahota\n",
      "    ⚠️ Page loading slow: https://www.canlii.org/en/on/oncj/doc/2025/2025oncj670/2025oncj670.html\n",
      "\n",
      "✅ Success! Data saved to 'canlii_final_report_20.csv'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# --- [Core Functions] ---\n",
    "\n",
    "def parse_case_details(driver, url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the main document content to load\n",
    "        try:\n",
    "            WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.ID, \"documentContent\")))\n",
    "        except:\n",
    "            print(f\"    ⚠️ Page loading slow: {url}\")\n",
    "            time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        judge_name = \"Unknown\"\n",
    "        heard_date = \"Unknown\"\n",
    "        released_date = \"Unknown\"\n",
    "\n",
    "        # 1. Parse Judge Name\n",
    "        judge_target = soup.find(lambda tag: tag.name == \"p\" and re.search(r'Before\\s+Justice', tag.get_text()))\n",
    "        if judge_target:\n",
    "            full_text = judge_target.get_text(separator=\" \", strip=True)\n",
    "            clean_text = \" \".join(full_text.split()) \n",
    "            if \"Justice\" in clean_text:\n",
    "                judge_name = clean_text.split(\"Justice\")[-1].strip()\n",
    "\n",
    "        # 2. Parse Heard Date\n",
    "        heard_pattern = re.compile(r\"(Heard\\s+on|Heard:|Date\\s+of\\s+hearing:)\", re.I)\n",
    "        heard_tag = soup.find(lambda tag: tag.name == \"p\" and heard_pattern.search(tag.get_text()))\n",
    "        if heard_tag:\n",
    "            full_text = heard_tag.get_text(separator=\" \", strip=True)\n",
    "            clean_text = \" \".join(full_text.split())\n",
    "            if \"on\" in clean_text.lower():\n",
    "                heard_date = clean_text.split(\"on\")[-1].strip()\n",
    "            elif \":\" in clean_text:\n",
    "                heard_date = clean_text.split(\":\")[-1].strip()\n",
    "\n",
    "        # 3. Parse Released Date (Specific Target)\n",
    "        date_label_div = soup.find(\"div\", class_=\"col-3\", string=re.compile(r\"Date:\", re.I))\n",
    "        if date_label_div:\n",
    "            date_value_div = date_label_div.find_next_sibling(\"div\", class_=\"col\")\n",
    "            if date_value_div:\n",
    "                released_date = date_value_div.get_text(strip=True)\n",
    "\n",
    "        return {\n",
    "            \"Judge\": judge_name,\n",
    "            \"Heard_Date\": heard_date,\n",
    "            \"Released_Date\": released_date\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error parsing {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main_process(limit=20):\n",
    "    options = uc.ChromeOptions()\n",
    "    # Adding stability arguments to prevent the 'target window closed' error\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-popup-blocking')\n",
    "    options.add_argument('--start-maximized')\n",
    "    \n",
    "    # Initialize driver with subprocess mode for better stability on MacOS/Windows\n",
    "    driver = uc.Chrome(options=options, version_main=144, use_subprocess=True)\n",
    "\n",
    "    try:\n",
    "        print(\"1. Initializing session. Solve CAPTCHA manually if prompted.\")\n",
    "        driver.get(\"https://www.canlii.org/en/on/oncj/nav/date/2025/\")\n",
    "        time.sleep(15) # Extra time for manual verification\n",
    "\n",
    "        print(\"2. Fetching API Case List...\")\n",
    "        api_url = \"https://www.canlii.org/on/oncj/nav/date/2025/items\"\n",
    "        driver.get(api_url)\n",
    "        time.sleep(7)\n",
    "        \n",
    "        raw_json = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        data = json.loads(raw_json)\n",
    "        cases_df = pd.DataFrame(data)\n",
    "        \n",
    "        criminal_cases = cases_df[cases_df['styleOfCause'].str.startswith(\"R. v.\", na=False)]\n",
    "        \n",
    "        final_results = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        for i, row in criminal_cases.iterrows():\n",
    "            if processed_count >= limit: break\n",
    "            \n",
    "            case_url = \"https://www.canlii.org\" + row['url']\n",
    "            print(f\"[{processed_count+1}/{limit}] Scraping: {row['styleOfCause']}\")\n",
    "            \n",
    "            details = parse_case_details(driver, case_url)\n",
    "            if details:\n",
    "                details['Case_Title'] = row['styleOfCause']\n",
    "                details['URL'] = case_url\n",
    "                final_results.append(details)\n",
    "                processed_count += 1\n",
    "            \n",
    "            # Anti-bot delay\n",
    "            time.sleep(random.uniform(8, 14))\n",
    "\n",
    "        if final_results:\n",
    "            result_df = pd.DataFrame(final_results)\n",
    "            result_df.to_csv(\"canlii_final_report_20.csv\", index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\n✅ Success! Data saved to 'canlii_final_report_20.csv'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Critical System Error: {e}\")\n",
    "    finally:\n",
    "        # Quit ensures all ghost processes are killed\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_process(limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
