{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a956f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ed05d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded: 510 rows\n",
      "Found 509 txt files on GitHub\n",
      "Matched texts : 509\n",
      "Missing texts : 1\n"
     ]
    }
   ],
   "source": [
    "# CSV file load\n",
    "csv_url = \"https://raw.githubusercontent.com/romane-lg/Ontario-Court-Cases/main/data/canlii_final_report_20.csv\"\n",
    "df = pd.read_csv(csv_url)\n",
    "print(f\"CSV loaded: {len(df)} rows\")\n",
    "\n",
    "\n",
    "# Reading txt files from GitHub\n",
    "api_url = \"https://api.github.com/repos/romane-lg/Ontario-Court-Cases/contents/data/data_clean\"\n",
    "response = requests.get(api_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "files = response.json()\n",
    "txt_files = [f for f in files if f[\"name\"].endswith(\".txt\")]\n",
    "print(f\"Found {len(txt_files)} txt files on GitHub\")\n",
    "\n",
    "\n",
    "# URL → txt mapping\n",
    "url_to_text = {}\n",
    "\n",
    "for file_info in txt_files:\n",
    "    raw_url = file_info[\"download_url\"]\n",
    "    text = requests.get(raw_url).text\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        if line.lower().startswith(\"source url:\"):\n",
    "            url = line.split(\":\", 1)[1].strip()\n",
    "            url_to_text[url] = text\n",
    "            break\n",
    "\n",
    "# Alignment with csv\n",
    "texts = []\n",
    "missing_urls = []\n",
    "\n",
    "for url in df[\"URL\"]:\n",
    "    if url in url_to_text:\n",
    "        texts.append(url_to_text[url])\n",
    "    else:\n",
    "        texts.append(\"\")\n",
    "        missing_urls.append(url)\n",
    "\n",
    "df[\"full_text\"] = texts\n",
    "\n",
    "print(f\"Matched texts : {len(df) - len(missing_urls)}\")\n",
    "print(f\"Missing texts : {len(missing_urls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01effb50",
   "metadata": {},
   "source": [
    "### Sentence-BERT embeddings - Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c9765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "import umap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6255b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25507d523634acdb9558382d1b25bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f6e55f9d8846f18d274e4d6a2202bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight, fast for 500+ cases\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466c75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "#Dimensionality reduction\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15, n_components=2, metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(umap_embeddings[:,0], umap_embeddings[:,1], s=10)\n",
    "plt.title(\"UMAP projection of legal case embeddings\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926214a",
   "metadata": {},
   "source": [
    "The BERT sentence embedding approach seperated the cases into 3-4 groups. There is one larger cluster on the right, a medium one, a smaller one and one that seems to relate to outliers. However, since our sample is small to represent all possible criminal offense, we will chose to go with 4 clusters to represent the different cases complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom')\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Number of clusters found: {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)}\")\n",
    "print(df[['Case_Title', 'Cluster']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(umap_embeddings[:,0], umap_embeddings[:,1], c=cluster_labels, cmap='tab20', s=20)\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.title(\"HDBSCAN clusters of legal cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bf126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "#Extact the top key words per cluster\n",
    "def get_top_keywords(texts, top_n=10):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=2)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Sum TF-IDF scores per term across all documents\n",
    "    tfidf_sums = X.sum(axis=0).A1\n",
    "    top_indices = tfidf_sums.argsort()[::-1][:top_n]\n",
    "    \n",
    "    return feature_names[top_indices]\n",
    "\n",
    "# Group texts by cluster\n",
    "clusters = df['Cluster'].unique()\n",
    "for cluster in clusters:\n",
    "    if cluster == -1:\n",
    "        continue  # -1 is noise in HDBSCAN\n",
    "    cluster_texts = [text for text, lbl in zip(texts, cluster_labels) if lbl == cluster]\n",
    "    top_words = get_top_keywords(cluster_texts, top_n=10)\n",
    "    print(f\"Cluster {cluster}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb4e7d4",
   "metadata": {},
   "source": [
    "**Cluster Analysis**:\n",
    "- Cluster 4 (Sexual Offensses possibly involving minors): \n",
    "    * This cluster seems to involve sexual offenses, likely sexual assault cases, potentially involving minors (with words like mother, complainant) or family / household context\n",
    "    * Evidence often comes from testimony, messages, or phone activity\n",
    "\n",
    "- Cluster 1 (Violent crimes / firearm offenses): \n",
    "    * Keywords like forearm and officer suggest weapon-related iffenses or violent crimes\n",
    "    * sentence, years, delay -> procedural / sentencimg context, probably serious criminal offenses \n",
    "\n",
    "- Cluster 5 (General criminal offenses / mixed cases): \n",
    "    * Generic crimial law terms (offender, accused, testified)\n",
    "    * Seems like general sentencing cases, maybe property crimes or minor assaults\n",
    "\n",
    "- Cluster 2 (Youth criminal offenses): \n",
    "    * YCJA refers to Youth Criminal Justice Act, so this cluster refers to youth criminal cases \n",
    "    * custody, probabtion, search seems to also refer to sentencing and procedural aspects of youth criminal cases \n",
    "\n",
    "- Cluster 0 (groupping of file): \n",
    "    * seems to be a groupping of boilerplate / numeric references \n",
    "    * needs to be investigated manually \n",
    "\n",
    "- Cluster 3 (sexual / assault offenses): \n",
    "    * Mentions of victims, mother, video, party → sexual or assault-related cases, possibly domestic or youth sexual offenses.\n",
    "    * Overlaps somewhat with Cluster 4, but maybe more procedural focus or different type of sexual/assault cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List cases in Cluster 0\n",
    "cluster_0_cases = df[df['Cluster'] == 0]\n",
    "\n",
    "print(f\"Total cases in Cluster 0: {len(cluster_0_cases)}\\n\")\n",
    "\n",
    "# Show relevant info: Case Title + URL\n",
    "for idx, row in cluster_0_cases.iterrows():\n",
    "    print(f\"Row {idx}: {row['Case_Title']} -> {row['URL']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807fd81",
   "metadata": {},
   "source": [
    "The cases in cluster 0 refer to cases that have not been resolved yet, thus follows the same case content. It make sense they have been groupped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of cases per cluster\n",
    "cluster_counts = df['Cluster'].value_counts().sort_index()\n",
    "\n",
    "print(\"Number of cases per cluster:\\n\")\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"Cluster {cluster}: {count} cases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c686f4",
   "metadata": {},
   "source": [
    "Cluster 1 is the most populated, containing 336 cases. Other clusters, such as 3 and 4, have fewer cases, which aligns with our interpretation that Clusters 3 and 4 are related to sexual offenses — with Cluster 4 likely focusing more on youth cases and Cluster 3 on general assaults.\n",
    "\n",
    "Now, we aim to sub-cluster cluster -1, 1 and 5 to identify more precise offense groups within each.\n",
    "\n",
    "Regarding Cluster -1, these are the noise points identified by HDBSCAN. They represent cases that the algorithm could not confidently assign to any cluster, often because they are outliers or have ambiguous content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135daf",
   "metadata": {},
   "source": [
    "### Topic Modeling 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c393fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight & fast\n",
    "\n",
    "# Only sub-cluster these main clusters\n",
    "clusters_to_process = [-1, 1, 5]\n",
    "\n",
    "# Dictionary to store subcluster labels and top words\n",
    "subcluster_results = {}\n",
    "subcluster_keywords = {}\n",
    "\n",
    "# Function to get top TF-IDF words for a list of texts\n",
    "def get_top_keywords(texts, top_n=10):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=2)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    tfidf_sums = X.sum(axis=0).A1\n",
    "    top_indices = tfidf_sums.argsort()[::-1][:top_n]\n",
    "    return feature_names[top_indices]\n",
    "\n",
    "# Loop through selected clusters and sub-cluster\n",
    "for cluster in clusters_to_process:\n",
    "    cluster_mask = df['Cluster'] == cluster\n",
    "    cluster_texts = [text for text, mask in zip(texts, cluster_mask) if mask]\n",
    "    \n",
    "    if len(cluster_texts) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nProcessing Cluster {cluster} ({len(cluster_texts)} cases)\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(cluster_texts, show_progress_bar=True)\n",
    "    \n",
    "    # HDBSCAN sub-clustering\n",
    "    subclusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=3, \n",
    "        metric='euclidean', \n",
    "        cluster_selection_method='eom'\n",
    "    )\n",
    "    subcluster_labels = subclusterer.fit_predict(embeddings)\n",
    "    \n",
    "    # Store subcluster labels\n",
    "    subcluster_results[cluster] = subcluster_labels\n",
    "    \n",
    "    # Store top keywords per subcluster\n",
    "    subcluster_keywords[cluster] = {}\n",
    "    unique_subclusters = np.unique(subcluster_labels)\n",
    "    \n",
    "    for sc in unique_subclusters:\n",
    "        if sc == -1:\n",
    "            continue  # skip noise\n",
    "        sc_texts = [text for text, lbl in zip(cluster_texts, subcluster_labels) if lbl == sc]\n",
    "        top_words = get_top_keywords(sc_texts, top_n=10)\n",
    "        subcluster_keywords[cluster][sc] = top_words\n",
    "        print(f\"  Subcluster {sc}: {len(sc_texts)} cases | Top words: {', '.join(top_words)}\")\n",
    "    \n",
    "    # Optional: UMAP visualization\n",
    "    umap_embeddings = umap.UMAP(\n",
    "        n_neighbors=15, \n",
    "        n_components=2, \n",
    "        metric='cosine'\n",
    "    ).fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(\n",
    "        umap_embeddings[:,0], \n",
    "        umap_embeddings[:,1], \n",
    "        c=subcluster_labels, \n",
    "        cmap='tab20', \n",
    "        s=20\n",
    "    )\n",
    "    plt.title(f\"Cluster {cluster} subclusters\")\n",
    "    plt.show()\n",
    "\n",
    "# Add subcluster labels to df\n",
    "for cluster, labels in subcluster_results.items():\n",
    "    mask = df['Cluster'] == cluster\n",
    "    df.loc[mask, f'Subcluster_{cluster}'] = labels\n",
    "\n",
    "print(\"\\nSub-clustering complete! Selected clusters now have subcluster labels and top keywords.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the top keywords per sub-cluster\n",
    "\n",
    "print(\"Top keywords per subcluster:\\n\")\n",
    "\n",
    "for cluster in subcluster_keywords:\n",
    "    print(f\"Main Cluster {cluster}:\")\n",
    "    for sc, words in subcluster_keywords[cluster].items():\n",
    "        print(f\"  Subcluster {sc} ({len([text for text, lbl in zip(texts, df['Cluster']) if lbl == cluster])} cases): {', '.join(words)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d97f9c",
   "metadata": {},
   "source": [
    "**Sub-Cluster Analysis**\n",
    "\n",
    "- Cluster -1:\n",
    "    * Subcluster 0: Likely procedural or traffic/Charter-related cases, including vehicle offenses, driving under influence, or other legal procedural matters.\n",
    "     * Subcluster 1: Probably general criminal cases, possibly minor assaults, property crimes, or mixed offenses; broadly procedural with no strong thematic signal.\n",
    "     * Subcluster 2: Likely sexual offenses or threats, some involving minors, possibly online/technology-facilitated offenses.\n",
    "     * Subcluster 3: ikely assault or sexual consent-related cases, procedural context emphasized (delay, records, consent), overlaps with sexual/offense context.\n",
    "\n",
    "- Cluster 5:\n",
    "    * Subcluster 0: Likely child-related general criminal cases, maybe minor abuse or family-related criminal offenses. Procedural and sentencing context is strong.\n",
    "     * Subcluster 1:Likely sexual offenses in social contexts, possibly assaults at parties or social gatherings, involving victims and witnesses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ec059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clustered.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
